{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNDTvSXVorij"
      },
      "source": [
        "## 모델링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoWfwIDqnYZl"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/user/AppData/Local/Programs/Python/Python37/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# from lightgbm import LGBMRegressor\n",
        "# from catboost import CatBoostRegressor\n",
        "# from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.metrics import *\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,LSTM\n",
        "from keras.backend import clear_session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install ipykernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54qh_tHrG88g"
      },
      "source": [
        "#### 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B1PEjYm1XZqF"
      },
      "outputs": [],
      "source": [
        "path='../../data/preprocessed data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NomSlNLkXZnQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(191994, 175)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=pd.read_csv(path+'dong_service_data.csv')\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUZpxSKVX7nG",
        "outputId": "2d18646f-4cf0-471f-9f47-bde290737b90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(191994, 128)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 추정매출 데이터 -> 당월_매출_금액만 남기고 모두 드랍.\n",
        "drop_cols = ['당월_매출_건수', '주중_매출_금액', '주말_매출_금액',\n",
        "       '월요일_매출_금액', '화요일_매출_금액', '수요일_매출_금액', '목요일_매출_금액', '금요일_매출_금액',\n",
        "       '토요일_매출_금액', '일요일_매출_금액', '시간대_00~06_매출_금액', '시간대_06~11_매출_금액',\n",
        "       '시간대_11~14_매출_금액', '시간대_14~17_매출_금액', '시간대_17~21_매출_금액',\n",
        "       '시간대_21~24_매출_금액', '남성_매출_금액', '여성_매출_금액', '연령대_10_매출_금액',\n",
        "       '연령대_20_매출_금액', '연령대_30_매출_금액', '연령대_40_매출_금액', '연령대_50_매출_금액',\n",
        "       '연령대_60_이상_매출_금액', '주중_매출_건수', '주말_매출_건수', '월요일_매출_건수', '화요일_매출_건수',\n",
        "       '수요일_매출_건수', '목요일_매출_건수', '금요일_매출_건수', '토요일_매출_건수', '일요일_매출_건수',\n",
        "       '시간대_건수~06_매출_건수', '시간대_건수~11_매출_건수', '시간대_건수~14_매출_건수',\n",
        "       '시간대_건수~17_매출_건수', '시간대_건수~21_매출_건수', '시간대_건수~24_매출_건수', '남성_매출_건수',\n",
        "       '여성_매출_건수', '연령대_10_매출_건수', '연령대_20_매출_건수', '연령대_30_매출_건수',\n",
        "       '연령대_40_매출_건수', '연령대_50_매출_건수', '연령대_60_이상_매출_건수']\n",
        "data=data.drop(columns=drop_cols,axis=1)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dczU3OP_XZim",
        "outputId": "7c252392-5779-404c-daa3-f0c9addb4ca1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([20221, 20222, 20223, 20224, 20231, 20232, 20201, 20202, 20203,\n",
              "       20204, 20211, 20212, 20213, 20214], dtype=int64)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 19년도 데이터 제거\n",
        "data = data[~data['기준_년분기_코드'].isin([20191, 20192, 20193, 20194])]\n",
        "data['기준_년분기_코드'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qELqagZFXZgH",
        "outputId": "2939b023-0c37-43bb-e77c-07255e8aa717"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbo1O0QqQZh-",
        "outputId": "30b9f6eb-b2c5-454e-ce13-fb3045ed72ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(166920, 126)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 행정동 이름, 업종 이름 컬럼 제거\n",
        "data=data.drop(['행정동_코드_명','서비스_업종_코드_명'],axis=1)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1T8V2KkoXyOO"
      },
      "outputs": [],
      "source": [
        "# 데이터프레임 추출 함수\n",
        "# def data_filter_split(dataframe,행정동코드, 업종코드):\n",
        "#     return dataframe[(dataframe['행정동_코드'] == 행정동코드) & (dataframe['서비스_업종_코드'] == 업종코드)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9GdLIm3RKVs",
        "outputId": "588dafd9-4846-4485-9718-ccc0baae5801"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "기준_년분기_코드       int64\n",
              "행정동_코드         object\n",
              "서비스_업종_코드      object\n",
              "당월_매출_금액        int64\n",
              "집객시설_수        float64\n",
              "               ...   \n",
              "수요일_유동인구_수      int64\n",
              "목요일_유동인구_수      int64\n",
              "금요일_유동인구_수      int64\n",
              "토요일_유동인구_수      int64\n",
              "일요일_유동인구_수      int64\n",
              "Length: 126, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # 업종코드 object형 데이터 int형 변환\n",
        "# data['서비스_업종_코드']=data['서비스_업종_코드'].str[2:].astype(int)\n",
        "# data['서비스_업종_코드'].dtype\n",
        "\n",
        "# 행정동_코드 int형 -> string 변환\n",
        "data['행정동_코드']=data['행정동_코드'].astype(str)\n",
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qRLzU1CmSTSL"
      },
      "outputs": [],
      "source": [
        "# 11110515: 청운효자동 , 한식음식점: CS100001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yNEpqrA3ScC8"
      },
      "outputs": [],
      "source": [
        "# x,y 분리 , target: 당월_매출_금액\n",
        "target='당월_매출_금액'\n",
        "x = data.drop(target, axis = 1)\n",
        "y = data.loc[:,target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRWuQDfO1NXA"
      },
      "source": [
        "## Auto ML : pycaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "v6la4OjCTOWm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycaret in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.2.0)\n",
            "Requirement already satisfied: category-encoders>=2.4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (2.6.3)\n",
            "Requirement already satisfied: cloudpickle in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (3.0.0)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (2.1.0)\n",
            "Requirement already satisfied: imbalanced-learn>=0.8.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (0.11.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (6.8.0)\n",
            "Requirement already satisfied: ipython>=5.5.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (8.14.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (8.1.1)\n",
            "Requirement already satisfied: jinja2>=1.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (3.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (1.3.1)\n",
            "Requirement already satisfied: kaleido>=0.2.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (0.2.1)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (4.1.0)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (2.1.3)\n",
            "Requirement already satisfied: matplotlib<=3.6,>=3.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (5.9.2)\n",
            "Requirement already satisfied: numba>=0.55.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (0.57.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.21 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (1.24.3)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (1.5.3)\n",
            "Requirement already satisfied: plotly-resampler>=0.8.3.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (0.9.1)\n",
            "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (5.16.1)\n",
            "Requirement already satisfied: pmdarima!=1.8.1,<3.0.0,>=1.8.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (2.0.4)\n",
            "Requirement already satisfied: psutil>=5.9.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (5.9.5)\n",
            "Requirement already satisfied: pyod>=1.0.8 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (1.1.2)\n",
            "Requirement already satisfied: requests>=2.27.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (2.31.0)\n",
            "Requirement already satisfied: schemdraw==0.15 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (0.15)\n",
            "Requirement already satisfied: scikit-learn<1.3.0,>=1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (1.2.2)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: scipy~=1.10.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (1.10.1)\n",
            "Requirement already satisfied: sktime!=0.17.1,!=0.17.2,!=0.18.0,<0.22.0,>=0.16.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (0.21.1)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (0.14.1)\n",
            "Requirement already satisfied: tbats>=1.1.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (1.1.3)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (4.66.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (3.4.1)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycaret) (1.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from category-encoders>=2.4.0->pycaret) (0.5.5)\n",
            "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from deprecation>=2.1.0->pycaret) (23.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn>=0.8.1->pycaret) (3.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib-metadata>=4.12.0->pycaret) (3.16.2)\n",
            "Requirement already satisfied: backcall in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
            "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=5.5.0->pycaret) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=5.5.0->pycaret) (0.19.0)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=5.5.0->pycaret) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=5.5.0->pycaret) (3.0.39)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=5.5.0->pycaret) (2.15.1)\n",
            "Requirement already satisfied: stack-data in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=5.5.0->pycaret) (0.6.2)\n",
            "Requirement already satisfied: traitlets>=5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=5.5.0->pycaret) (5.9.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=5.5.0->pycaret) (0.4.6)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets>=7.6.5->pycaret) (0.1.4)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.9 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets>=7.6.5->pycaret) (4.0.9)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets>=7.6.5->pycaret) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib<=3.6,>=3.3.0->pycaret) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib<=3.6,>=3.3.0->pycaret) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib<=3.6,>=3.3.0->pycaret) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib<=3.6,>=3.3.0->pycaret) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib<=3.6,>=3.3.0->pycaret) (9.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib<=3.6,>=3.3.0->pycaret) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib<=3.6,>=3.3.0->pycaret) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nbformat>=4.2.0->pycaret) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nbformat>=4.2.0->pycaret) (4.20.0)\n",
            "Requirement already satisfied: jupyter-core in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nbformat>=4.2.0->pycaret) (5.3.1)\n",
            "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from numba>=0.55.0->pycaret) (0.40.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas<2.0.0,>=1.3.0->pycaret) (2023.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly>=5.0.0->pycaret) (8.2.3)\n",
            "Requirement already satisfied: dash<3.0.0,>=2.11.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly-resampler>=0.8.3.1->pycaret) (2.14.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.8.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.9.10)\n",
            "Requirement already satisfied: trace-updater>=0.0.8 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly-resampler>=0.8.3.1->pycaret) (0.0.9.1)\n",
            "Requirement already satisfied: tsdownsample==0.1.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly-resampler>=0.8.3.1->pycaret) (0.1.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret) (3.0.7)\n",
            "Requirement already satisfied: urllib3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret) (1.26.16)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret) (65.5.0)\n",
            "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyod>=1.0.8->pycaret) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.27.1->pycaret) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.27.1->pycaret) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.27.1->pycaret) (2023.7.22)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sktime!=0.17.1,!=0.17.2,!=0.18.0,<0.22.0,>=0.16.1->pycaret) (1.2.14)\n",
            "Requirement already satisfied: scikit-base<0.6.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sktime!=0.17.1,!=0.17.2,!=0.18.0,<0.22.0,>=0.16.1->pycaret) (0.5.2)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.0)\n",
            "Requirement already satisfied: Werkzeug<3.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.1)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (4.8.0)\n",
            "Requirement already satisfied: retrying in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (1.3.4)\n",
            "Requirement already satisfied: ansi2html in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (1.9.1)\n",
            "Requirement already satisfied: nest-asyncio in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (1.5.7)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from deprecated>=1.2.13->sktime!=0.17.1,!=0.17.2,!=0.18.0,<0.22.0,>=0.16.1->pycaret) (1.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.10.2)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.5.0->pycaret) (0.2.6)\n",
            "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jupyter-core->nbformat>=4.2.0->pycaret) (3.10.0)\n",
            "Requirement already satisfied: pywin32>=300 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jupyter-core->nbformat>=4.2.0->pycaret) (306)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack-data->ipython>=5.5.0->pycaret) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack-data->ipython>=5.5.0->pycaret) (2.2.1)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack-data->ipython>=5.5.0->pycaret) (0.2.2)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (2.1.2)\n",
            "Requirement already satisfied: click>=8.1.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.11.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'DOSKEY'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U --pre pycaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wDiJzc3U7bUd"
      },
      "outputs": [],
      "source": [
        "from pycaret.regression import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# string 타입 제외하고 스케일링 후 합치기\n",
        "exc=['행정동_코드', '서비스_업종_코드']\n",
        "tmp_x = x.drop(exc, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SrcXn2GBT4aw"
      },
      "outputs": [],
      "source": [
        "# data scaling : min-max\n",
        "# 전체 데이터를 직접 스케일링 해주지 않으면 너무 큰값들이라서 pycaret 동작하지 않음\n",
        "scaler=MinMaxScaler()\n",
        "x_s_tmp=scaler.fit_transform(tmp_x)\n",
        "x_s_tmp=pd.DataFrame(x_s_tmp)\n",
        "x_s=pd.concat([x[exc],x_s_tmp],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldCewor_S4jG",
        "outputId": "b6818274-a713-4380-a903-68949ca8e800"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(191994, 126)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_s.reset_index(drop=True, inplace=True)\n",
        "y.reset_index(drop=True, inplace=True)\n",
        "data_s=pd.concat([x_s,y],axis=1)\n",
        "data_s.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "행정동_코드       25074\n",
              "서비스_업종_코드    25074\n",
              "0            25074\n",
              "1            25074\n",
              "2            25074\n",
              "             ...  \n",
              "119          25074\n",
              "120          25074\n",
              "121          25074\n",
              "122          25074\n",
              "당월_매출_금액     25074\n",
              "Length: 126, dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_s.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zySkix1rXZVG",
        "outputId": "d3f82015-6cf0-4206-a6f0-85b5dde173cb"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "25074 missing values found in the target column: 당월_매출_금액. To proceed, remove the respective rows from the data. ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 매출 컬럼 제외하지 않은 데이터의 결과들\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# normalize_method = 'minmax', # default는 zscore\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransformation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 전처리 기능 설정\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransform_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# default는 10\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfold_shuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# ignore_features = ign_cols, # 제외할 컬럼\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# categorical_features = [], # one-hot encoding\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# date_features = [], # 날짜 feature를 년월일시 로 바꿔서 onehotencoding 해준다.\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# random state number 지정\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# gpu 사용 옵션\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 특징선택 자동\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_selection_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#‘univariate’: Uses sklearn’s SelectKBest.\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#‘classic’: Uses sklearn’s SelectFromModel.\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#‘sequential’: Uses sklearn’s SequentialFeatureSelector.\u001b[39;49;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# fix_imbalance = True, # 클래스 불균형 문제 자동으로 해결. default는 False\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# fix_imbalance_method = imblearn.OverSampling.RandomOverSampler() # 오버샘플링 예시\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# 기본은 SMOTE\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# custom_pipeline = pipe, preprocess =False\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# 두 개는 세트, 사용자가 원하는 파이프라인을 구성할 수 있다.\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pycaret\\regression\\functional.py:593\u001b[0m, in \u001b[0;36msetup\u001b[1;34m(data, data_func, target, index, train_size, test_data, ordinal_features, numeric_features, categorical_features, date_features, text_features, ignore_features, keep_features, preprocess, create_date_columns, imputation_type, numeric_imputation, categorical_imputation, iterative_imputation_iters, numeric_iterative_imputer, categorical_iterative_imputer, text_features_method, max_encoding_ohe, encoding_method, rare_to_value, rare_value, polynomial_features, polynomial_degree, low_variance_threshold, group_features, drop_groups, remove_multicollinearity, multicollinearity_threshold, bin_numeric_features, remove_outliers, outliers_method, outliers_threshold, transformation, transformation_method, normalize, normalize_method, pca, pca_method, pca_components, feature_selection, feature_selection_method, feature_selection_estimator, n_features_to_select, transform_target, transform_target_method, custom_pipeline, custom_pipeline_position, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, html, session_id, system_log, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, verbose, memory, profile, profile_kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m exp \u001b[38;5;241m=\u001b[39m _EXPERIMENT_CLASS()\n\u001b[0;32m    592\u001b[0m set_current_experiment(exp)\n\u001b[1;32m--> 593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mordinal_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordinal_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_date_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_date_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimputation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimputation_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_imputation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_imputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_imputation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_imputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterative_imputation_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterative_imputation_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_iterative_imputer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_iterative_imputer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_iterative_imputer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_iterative_imputer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_features_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_features_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_encoding_ohe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_encoding_ohe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrare_to_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrare_to_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrare_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrare_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolynomial_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolynomial_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolynomial_degree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolynomial_degree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_variance_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_variance_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_multicollinearity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_multicollinearity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulticollinearity_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulticollinearity_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbin_numeric_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbin_numeric_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_outliers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_outliers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutliers_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutliers_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutliers_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutliers_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformation_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformation_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpca\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpca\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpca_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpca_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpca_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpca_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_selection_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_selection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_selection_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_selection_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_features_to_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_features_to_select\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_target_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_target_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_pipeline_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_pipeline_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_split_shuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_shuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_split_stratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_stratify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_shuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_shuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhtml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhtml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_experiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_experiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_plots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_plots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_profile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_profile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprofile_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pycaret\\regression\\oop.py:711\u001b[0m, in \u001b[0;36mRegressionExperiment.setup\u001b[1;34m(self, data, data_func, target, index, train_size, test_data, ordinal_features, numeric_features, categorical_features, date_features, text_features, ignore_features, keep_features, preprocess, create_date_columns, imputation_type, numeric_imputation, categorical_imputation, iterative_imputation_iters, numeric_iterative_imputer, categorical_iterative_imputer, text_features_method, max_encoding_ohe, encoding_method, rare_to_value, rare_value, polynomial_features, polynomial_degree, low_variance_threshold, group_features, drop_groups, remove_multicollinearity, multicollinearity_threshold, bin_numeric_features, remove_outliers, outliers_method, outliers_threshold, transformation, transformation_method, normalize, normalize_method, pca, pca_method, pca_components, feature_selection, feature_selection_method, feature_selection_estimator, n_features_to_select, transform_target, transform_target_method, custom_pipeline, custom_pipeline_position, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, html, session_id, system_log, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, engine, verbose, memory, profile, profile_kwargs)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     data \u001b[38;5;241m=\u001b[39m data_func()\n\u001b[1;32m--> 711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m index\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pycaret\\internal\\preprocess\\preprocessor.py:165\u001b[0m, in \u001b[0;36mPreprocessor._prepare_dataset\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# Check that y has no missing values\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m missing values found in the target column: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. To proceed, remove the respective rows from the data. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_shrink_dtypes(\n\u001b[0;32m    171\u001b[0m     X\u001b[38;5;241m.\u001b[39mmerge(y\u001b[38;5;241m.\u001b[39mto_frame(), left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    172\u001b[0m )\n",
            "\u001b[1;31mValueError\u001b[0m: 25074 missing values found in the target column: 당월_매출_금액. To proceed, remove the respective rows from the data. "
          ]
        }
      ],
      "source": [
        "# 매출 컬럼 제외하지 않은 데이터의 결과들\n",
        "exp = setup(data = data_s,\n",
        "            target = target,\n",
        "            normalize = True,\n",
        "            # normalize_method = 'minmax', # default는 zscore\n",
        "            transformation = True,  # 전처리 기능 설정\n",
        "            transform_target=True,\n",
        "            fold = 5, # default는 10\n",
        "            fold_shuffle=True,\n",
        "            # ignore_features = ign_cols, # 제외할 컬럼\n",
        "            # categorical_features = [], # one-hot encoding\n",
        "            # date_features = [], # 날짜 feature를 년월일시 로 바꿔서 onehotencoding 해준다.\n",
        "            session_id = 123, # random state number 지정\n",
        "            use_gpu = True, # gpu 사용 옵션\n",
        "            feature_selection = True, # 특징선택 자동\n",
        "            feature_selection_method ='classic',\n",
        "            #‘univariate’: Uses sklearn’s SelectKBest.\n",
        "            #‘classic’: Uses sklearn’s SelectFromModel.\n",
        "            #‘sequential’: Uses sklearn’s SequentialFeatureSelector.\n",
        "\n",
        "            # fix_imbalance = True, # 클래스 불균형 문제 자동으로 해결. default는 False\n",
        "            # fix_imbalance_method = imblearn.OverSampling.RandomOverSampler() # 오버샘플링 예시\n",
        "            # 기본은 SMOTE\n",
        "\n",
        "            # custom_pipeline = pipe, preprocess =False\n",
        "            # 두 개는 세트, 사용자가 원하는 파이프라인을 구성할 수 있다.\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612,
          "referenced_widgets": [
            "5575764a9fd24be2bb84037b95b04670",
            "a18baee9dc7b49848a385956da445cd6",
            "09f49d04d88347cd9297eeeafcd00687",
            "75b2dfd6950b443898b84faa030ac8d3",
            "dc9bf07414964a7b8abb9a9fd952918a",
            "66610ccb34a4432a8a43bb2e0c0eb836",
            "ed68143f295442fb859dd4ad02713f86",
            "7a5727a9a3ba4bb68e0ce46c09c13b53",
            "23d950e677744ab29c59b889ef8bff43",
            "757943bf78704515a2f2f3ce04ea2861",
            "ecd9d017be5e4524a11f6aa6383e6b68"
          ]
        },
        "id": "hfyufFEN7_Oy",
        "outputId": "1a59a721-2db6-450a-e3b9-056e1f233510"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc372244-21a1-4793-8944-2aa6325f76ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Initiated</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>02:04:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Status</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>Fitting 5 Folds</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Estimator</th>\n",
              "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
              "      <td>Extra Trees Regressor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc372244-21a1-4793-8944-2aa6325f76ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc372244-21a1-4793-8944-2aa6325f76ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc372244-21a1-4793-8944-2aa6325f76ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-439560ed-4367-4913-96e8-2293e3c62c1f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-439560ed-4367-4913-96e8-2293e3c62c1f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-439560ed-4367-4913-96e8-2293e3c62c1f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                                     \n",
              "                                                                     \n",
              "Initiated  . . . . . . . . . . . . . . . . . .               02:04:23\n",
              "Status     . . . . . . . . . . . . . . . . . .        Fitting 5 Folds\n",
              "Estimator  . . . . . . . . . . . . . . . . . .  Extra Trees Regressor"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_5b063 th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_5b063_row0_col0, #T_5b063_row0_col1, #T_5b063_row0_col2, #T_5b063_row0_col3, #T_5b063_row0_col4, #T_5b063_row0_col5, #T_5b063_row0_col6, #T_5b063_row0_col7, #T_5b063_row1_col0, #T_5b063_row1_col1, #T_5b063_row1_col2, #T_5b063_row1_col3, #T_5b063_row1_col4, #T_5b063_row1_col5, #T_5b063_row1_col6, #T_5b063_row1_col7, #T_5b063_row2_col0, #T_5b063_row2_col1, #T_5b063_row2_col2, #T_5b063_row2_col3, #T_5b063_row2_col4, #T_5b063_row2_col5, #T_5b063_row2_col6, #T_5b063_row2_col7, #T_5b063_row3_col0, #T_5b063_row3_col1, #T_5b063_row3_col2, #T_5b063_row3_col3, #T_5b063_row3_col4, #T_5b063_row3_col5, #T_5b063_row3_col6, #T_5b063_row3_col7, #T_5b063_row4_col0, #T_5b063_row4_col1, #T_5b063_row4_col2, #T_5b063_row4_col3, #T_5b063_row4_col4, #T_5b063_row4_col5, #T_5b063_row4_col6, #T_5b063_row4_col7, #T_5b063_row5_col0, #T_5b063_row5_col1, #T_5b063_row5_col2, #T_5b063_row5_col3, #T_5b063_row5_col4, #T_5b063_row5_col5, #T_5b063_row5_col6, #T_5b063_row5_col7, #T_5b063_row6_col0, #T_5b063_row6_col1, #T_5b063_row6_col2, #T_5b063_row6_col3, #T_5b063_row6_col4, #T_5b063_row6_col5, #T_5b063_row6_col6, #T_5b063_row6_col7, #T_5b063_row7_col0, #T_5b063_row7_col1, #T_5b063_row7_col2, #T_5b063_row7_col3, #T_5b063_row7_col4, #T_5b063_row7_col5, #T_5b063_row7_col6, #T_5b063_row7_col7, #T_5b063_row8_col0, #T_5b063_row8_col1, #T_5b063_row8_col2, #T_5b063_row8_col3, #T_5b063_row8_col4, #T_5b063_row8_col5, #T_5b063_row8_col6, #T_5b063_row8_col7, #T_5b063_row9_col0, #T_5b063_row9_col1, #T_5b063_row9_col2, #T_5b063_row9_col3, #T_5b063_row9_col4, #T_5b063_row9_col5, #T_5b063_row9_col6, #T_5b063_row9_col7, #T_5b063_row10_col0, #T_5b063_row10_col1, #T_5b063_row10_col2, #T_5b063_row10_col3, #T_5b063_row10_col4, #T_5b063_row10_col5, #T_5b063_row10_col6, #T_5b063_row10_col7, #T_5b063_row11_col0, #T_5b063_row11_col1, #T_5b063_row11_col2, #T_5b063_row11_col3, #T_5b063_row11_col4, #T_5b063_row11_col5, #T_5b063_row11_col6, #T_5b063_row11_col7, #T_5b063_row12_col0, #T_5b063_row12_col1, #T_5b063_row12_col2, #T_5b063_row12_col3, #T_5b063_row12_col4, #T_5b063_row12_col5, #T_5b063_row12_col6, #T_5b063_row12_col7 {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_5b063\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_5b063_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_5b063_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
              "      <th id=\"T_5b063_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
              "      <th id=\"T_5b063_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
              "      <th id=\"T_5b063_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
              "      <th id=\"T_5b063_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
              "      <th id=\"T_5b063_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
              "      <th id=\"T_5b063_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
              "      <td id=\"T_5b063_row0_col0\" class=\"data row0 col0\" >Random Forest Regressor</td>\n",
              "      <td id=\"T_5b063_row0_col1\" class=\"data row0 col1\" >140407962.2046</td>\n",
              "      <td id=\"T_5b063_row0_col2\" class=\"data row0 col2\" >1030607718235282944.0000</td>\n",
              "      <td id=\"T_5b063_row0_col3\" class=\"data row0 col3\" >981273650.2579</td>\n",
              "      <td id=\"T_5b063_row0_col4\" class=\"data row0 col4\" >0.9850</td>\n",
              "      <td id=\"T_5b063_row0_col5\" class=\"data row0 col5\" >0.2806</td>\n",
              "      <td id=\"T_5b063_row0_col6\" class=\"data row0 col6\" >0.2986</td>\n",
              "      <td id=\"T_5b063_row0_col7\" class=\"data row0 col7\" >147.9240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row1\" class=\"row_heading level0 row1\" >dt</th>\n",
              "      <td id=\"T_5b063_row1_col0\" class=\"data row1 col0\" >Decision Tree Regressor</td>\n",
              "      <td id=\"T_5b063_row1_col1\" class=\"data row1 col1\" >151208185.8104</td>\n",
              "      <td id=\"T_5b063_row1_col2\" class=\"data row1 col2\" >4808076094811257856.0000</td>\n",
              "      <td id=\"T_5b063_row1_col3\" class=\"data row1 col3\" >1776397975.0722</td>\n",
              "      <td id=\"T_5b063_row1_col4\" class=\"data row1 col4\" >0.9385</td>\n",
              "      <td id=\"T_5b063_row1_col5\" class=\"data row1 col5\" >0.4199</td>\n",
              "      <td id=\"T_5b063_row1_col6\" class=\"data row1 col6\" >0.6079</td>\n",
              "      <td id=\"T_5b063_row1_col7\" class=\"data row1 col7\" >25.3160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row2\" class=\"row_heading level0 row2\" >knn</th>\n",
              "      <td id=\"T_5b063_row2_col0\" class=\"data row2 col0\" >K Neighbors Regressor</td>\n",
              "      <td id=\"T_5b063_row2_col1\" class=\"data row2 col1\" >551901155.7918</td>\n",
              "      <td id=\"T_5b063_row2_col2\" class=\"data row2 col2\" >20187806002171809792.0000</td>\n",
              "      <td id=\"T_5b063_row2_col3\" class=\"data row2 col3\" >4360234357.5566</td>\n",
              "      <td id=\"T_5b063_row2_col4\" class=\"data row2 col4\" >0.7530</td>\n",
              "      <td id=\"T_5b063_row2_col5\" class=\"data row2 col5\" >0.7391</td>\n",
              "      <td id=\"T_5b063_row2_col6\" class=\"data row2 col6\" >1.1985</td>\n",
              "      <td id=\"T_5b063_row2_col7\" class=\"data row2 col7\" >36.9740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row3\" class=\"row_heading level0 row3\" >br</th>\n",
              "      <td id=\"T_5b063_row3_col0\" class=\"data row3 col0\" >Bayesian Ridge</td>\n",
              "      <td id=\"T_5b063_row3_col1\" class=\"data row3 col1\" >1332205517.0363</td>\n",
              "      <td id=\"T_5b063_row3_col2\" class=\"data row3 col2\" >69465461711376785408.0000</td>\n",
              "      <td id=\"T_5b063_row3_col3\" class=\"data row3 col3\" >8276210059.1308</td>\n",
              "      <td id=\"T_5b063_row3_col4\" class=\"data row3 col4\" >0.1060</td>\n",
              "      <td id=\"T_5b063_row3_col5\" class=\"data row3 col5\" >1.2736</td>\n",
              "      <td id=\"T_5b063_row3_col6\" class=\"data row3 col6\" >6.9308</td>\n",
              "      <td id=\"T_5b063_row3_col7\" class=\"data row3 col7\" >23.6380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row4\" class=\"row_heading level0 row4\" >lr</th>\n",
              "      <td id=\"T_5b063_row4_col0\" class=\"data row4 col0\" >Linear Regression</td>\n",
              "      <td id=\"T_5b063_row4_col1\" class=\"data row4 col1\" >1332728938.3143</td>\n",
              "      <td id=\"T_5b063_row4_col2\" class=\"data row4 col2\" >69476778195720732672.0000</td>\n",
              "      <td id=\"T_5b063_row4_col3\" class=\"data row4 col3\" >8276907724.6921</td>\n",
              "      <td id=\"T_5b063_row4_col4\" class=\"data row4 col4\" >0.1059</td>\n",
              "      <td id=\"T_5b063_row4_col5\" class=\"data row4 col5\" >1.2736</td>\n",
              "      <td id=\"T_5b063_row4_col6\" class=\"data row4 col6\" >6.9260</td>\n",
              "      <td id=\"T_5b063_row4_col7\" class=\"data row4 col7\" >24.9020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row5\" class=\"row_heading level0 row5\" >ridge</th>\n",
              "      <td id=\"T_5b063_row5_col0\" class=\"data row5 col0\" >Ridge Regression</td>\n",
              "      <td id=\"T_5b063_row5_col1\" class=\"data row5 col1\" >1332696988.1934</td>\n",
              "      <td id=\"T_5b063_row5_col2\" class=\"data row5 col2\" >69476084562053349376.0000</td>\n",
              "      <td id=\"T_5b063_row5_col3\" class=\"data row5 col3\" >8276865027.4513</td>\n",
              "      <td id=\"T_5b063_row5_col4\" class=\"data row5 col4\" >0.1059</td>\n",
              "      <td id=\"T_5b063_row5_col5\" class=\"data row5 col5\" >1.2736</td>\n",
              "      <td id=\"T_5b063_row5_col6\" class=\"data row5 col6\" >6.9263</td>\n",
              "      <td id=\"T_5b063_row5_col7\" class=\"data row5 col7\" >25.4220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row6\" class=\"row_heading level0 row6\" >lar</th>\n",
              "      <td id=\"T_5b063_row6_col0\" class=\"data row6 col0\" >Least Angle Regression</td>\n",
              "      <td id=\"T_5b063_row6_col1\" class=\"data row6 col1\" >1332729052.6993</td>\n",
              "      <td id=\"T_5b063_row6_col2\" class=\"data row6 col2\" >69476783866596188160.0000</td>\n",
              "      <td id=\"T_5b063_row6_col3\" class=\"data row6 col3\" >8276908104.6796</td>\n",
              "      <td id=\"T_5b063_row6_col4\" class=\"data row6 col4\" >0.1059</td>\n",
              "      <td id=\"T_5b063_row6_col5\" class=\"data row6 col5\" >1.2736</td>\n",
              "      <td id=\"T_5b063_row6_col6\" class=\"data row6 col6\" >6.9260</td>\n",
              "      <td id=\"T_5b063_row6_col7\" class=\"data row6 col7\" >23.2900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row7\" class=\"row_heading level0 row7\" >huber</th>\n",
              "      <td id=\"T_5b063_row7_col0\" class=\"data row7 col0\" >Huber Regressor</td>\n",
              "      <td id=\"T_5b063_row7_col1\" class=\"data row7 col1\" >1333682295.9172</td>\n",
              "      <td id=\"T_5b063_row7_col2\" class=\"data row7 col2\" >69796119191780024320.0000</td>\n",
              "      <td id=\"T_5b063_row7_col3\" class=\"data row7 col3\" >8296157260.6960</td>\n",
              "      <td id=\"T_5b063_row7_col4\" class=\"data row7 col4\" >0.1017</td>\n",
              "      <td id=\"T_5b063_row7_col5\" class=\"data row7 col5\" >1.2753</td>\n",
              "      <td id=\"T_5b063_row7_col6\" class=\"data row7 col6\" >6.7591</td>\n",
              "      <td id=\"T_5b063_row7_col7\" class=\"data row7 col7\" >25.5500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row8\" class=\"row_heading level0 row8\" >omp</th>\n",
              "      <td id=\"T_5b063_row8_col0\" class=\"data row8 col0\" >Orthogonal Matching Pursuit</td>\n",
              "      <td id=\"T_5b063_row8_col1\" class=\"data row8 col1\" >1358334147.3816</td>\n",
              "      <td id=\"T_5b063_row8_col2\" class=\"data row8 col2\" >70852769216788946944.0000</td>\n",
              "      <td id=\"T_5b063_row8_col3\" class=\"data row8 col3\" >8359872695.5611</td>\n",
              "      <td id=\"T_5b063_row8_col4\" class=\"data row8 col4\" >0.0876</td>\n",
              "      <td id=\"T_5b063_row8_col5\" class=\"data row8 col5\" >1.3149</td>\n",
              "      <td id=\"T_5b063_row8_col6\" class=\"data row8 col6\" >5.7769</td>\n",
              "      <td id=\"T_5b063_row8_col7\" class=\"data row8 col7\" >23.3760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row9\" class=\"row_heading level0 row9\" >en</th>\n",
              "      <td id=\"T_5b063_row9_col0\" class=\"data row9 col0\" >Elastic Net</td>\n",
              "      <td id=\"T_5b063_row9_col1\" class=\"data row9 col1\" >1530656176.8598</td>\n",
              "      <td id=\"T_5b063_row9_col2\" class=\"data row9 col2\" >75535586985564504064.0000</td>\n",
              "      <td id=\"T_5b063_row9_col3\" class=\"data row9 col3\" >8637691973.1506</td>\n",
              "      <td id=\"T_5b063_row9_col4\" class=\"data row9 col4\" >0.0248</td>\n",
              "      <td id=\"T_5b063_row9_col5\" class=\"data row9 col5\" >1.3869</td>\n",
              "      <td id=\"T_5b063_row9_col6\" class=\"data row9 col6\" >7.7082</td>\n",
              "      <td id=\"T_5b063_row9_col7\" class=\"data row9 col7\" >23.9120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row10\" class=\"row_heading level0 row10\" >lasso</th>\n",
              "      <td id=\"T_5b063_row10_col0\" class=\"data row10 col0\" >Lasso Regression</td>\n",
              "      <td id=\"T_5b063_row10_col1\" class=\"data row10 col1\" >1569314764.3265</td>\n",
              "      <td id=\"T_5b063_row10_col2\" class=\"data row10 col2\" >76323341839905914880.0000</td>\n",
              "      <td id=\"T_5b063_row10_col3\" class=\"data row10 col3\" >8683640718.2594</td>\n",
              "      <td id=\"T_5b063_row10_col4\" class=\"data row10 col4\" >0.0142</td>\n",
              "      <td id=\"T_5b063_row10_col5\" class=\"data row10 col5\" >1.4312</td>\n",
              "      <td id=\"T_5b063_row10_col6\" class=\"data row10 col6\" >8.0929</td>\n",
              "      <td id=\"T_5b063_row10_col7\" class=\"data row10 col7\" >25.0980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row11\" class=\"row_heading level0 row11\" >llar</th>\n",
              "      <td id=\"T_5b063_row11_col0\" class=\"data row11 col0\" >Lasso Least Angle Regression</td>\n",
              "      <td id=\"T_5b063_row11_col1\" class=\"data row11 col1\" >1569311923.9915</td>\n",
              "      <td id=\"T_5b063_row11_col2\" class=\"data row11 col2\" >76323263470466236416.0000</td>\n",
              "      <td id=\"T_5b063_row11_col3\" class=\"data row11 col3\" >8683636177.2291</td>\n",
              "      <td id=\"T_5b063_row11_col4\" class=\"data row11 col4\" >0.0142</td>\n",
              "      <td id=\"T_5b063_row11_col5\" class=\"data row11 col5\" >1.4312</td>\n",
              "      <td id=\"T_5b063_row11_col6\" class=\"data row11 col6\" >8.0929</td>\n",
              "      <td id=\"T_5b063_row11_col7\" class=\"data row11 col7\" >23.5380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5b063_level0_row12\" class=\"row_heading level0 row12\" >par</th>\n",
              "      <td id=\"T_5b063_row12_col0\" class=\"data row12 col0\" >Passive Aggressive Regressor</td>\n",
              "      <td id=\"T_5b063_row12_col1\" class=\"data row12 col1\" >2319851569.0248</td>\n",
              "      <td id=\"T_5b063_row12_col2\" class=\"data row12 col2\" >215689104472831524864.0000</td>\n",
              "      <td id=\"T_5b063_row12_col3\" class=\"data row12 col3\" >13045198792.8643</td>\n",
              "      <td id=\"T_5b063_row12_col4\" class=\"data row12 col4\" >-1.7515</td>\n",
              "      <td id=\"T_5b063_row12_col5\" class=\"data row12 col5\" >1.7679</td>\n",
              "      <td id=\"T_5b063_row12_col6\" class=\"data row12 col6\" >9.3759</td>\n",
              "      <td id=\"T_5b063_row12_col7\" class=\"data row12 col7\" >24.8200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ebeac013d00>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5575764a9fd24be2bb84037b95b04670",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing:   0%|          | 0/81 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# best model\n",
        "best_model = compare_models()\n",
        "\n",
        "# tune\n",
        "tuned_model = tune_model(best_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595,
          "referenced_widgets": [
            "5078f5c8d5694c48b11902a0c66cc8db",
            "93f191ca756a40d28d0f8bcec8976631",
            "cba07bcd89aa44549c476a68de3c6d89",
            "dd6309930d0944ce92166d7e4e5d8065",
            "ef2c416e9b9841ee837e1e3e45ebe4fb",
            "6cc7f5a337674a7db85551679861853a",
            "c89b99542d1d44a3ad69dd9ec3355b76"
          ]
        },
        "id": "i3Rbe9zE7_M4",
        "outputId": "4f27af2c-8281-47c3-9022-8c5b165b1144"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5078f5c8d5694c48b11902a0c66cc8db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_26e84\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_26e84_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_26e84_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
              "      <th id=\"T_26e84_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
              "      <th id=\"T_26e84_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
              "      <th id=\"T_26e84_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
              "      <th id=\"T_26e84_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
              "      <th id=\"T_26e84_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_26e84_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_26e84_row0_col0\" class=\"data row0 col0\" >Linear Regression</td>\n",
              "      <td id=\"T_26e84_row0_col1\" class=\"data row0 col1\" >1515718.6154</td>\n",
              "      <td id=\"T_26e84_row0_col2\" class=\"data row0 col2\" >50636844887777.9219</td>\n",
              "      <td id=\"T_26e84_row0_col3\" class=\"data row0 col3\" >7115957.0606</td>\n",
              "      <td id=\"T_26e84_row0_col4\" class=\"data row0 col4\" >0.9999</td>\n",
              "      <td id=\"T_26e84_row0_col5\" class=\"data row0 col5\" >0.0018</td>\n",
              "      <td id=\"T_26e84_row0_col6\" class=\"data row0 col6\" >0.0004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f13c317e260>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformation Pipeline and Model Successfully Saved\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(Pipeline(memory=Memory(location=None),\n",
              "          steps=[('target_transformation',\n",
              "                  TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),\n",
              "                 ('numerical_imputer',\n",
              "                  TransformerWrapper(include=['0', '1', '2', '3', '4', '5', '6',\n",
              "                                              '7', '8', '9', '10', '11', '12',\n",
              "                                              '13', '14', '15', '16', '17', '18',\n",
              "                                              '19', '20', '21', '22', '23', '24',\n",
              "                                              '25', '2...\n",
              "                  TransformerWrapper(transformer=PowerTransformer(standardize=False))),\n",
              "                 ('normalize', TransformerWrapper(transformer=StandardScaler())),\n",
              "                 ('feature_selection',\n",
              "                  TransformerWrapper(exclude=[],\n",
              "                                     transformer=SelectFromModel(estimator=LGBMRegressor(),\n",
              "                                                                 max_features=34,\n",
              "                                                                 threshold=-inf))),\n",
              "                 ('clean_column_names',\n",
              "                  TransformerWrapper(transformer=CleanColumnNames())),\n",
              "                 ('trained_model', LinearRegression(n_jobs=-1))]),\n",
              " 'best_model_28d.pkl')"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate\n",
        "evaluate_model(tuned_model)\n",
        "# predict\n",
        "predictions = predict_model(tuned_model, data=data_s)\n",
        "# save\n",
        "save_model(tuned_model, 'best_model_29d_v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkYDe1YudG-V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964,
          "referenced_widgets": [
            "784e575c15a74be1bec4801f65110ab7",
            "3074de101c614e9c8fb576120b2e6d67",
            "c707f96d495d434486ffc56179a5ecd8",
            "40257c54402c4ab3867a45ddffe4a349",
            "ff6fb52136e24583947dafa62fd1590b",
            "df3ad2dd8db943c288b40fb8bb29e86d",
            "76652bcde8db4ea28d85315e75c011c5",
            "c1bb185690bc435596d26c56ed17aa1b",
            "9340748afdd942e2a84fc2bd1163572f",
            "b8a65f37b409454c823f5bfdf02c81fb",
            "4a60fe64a3cb45059b10dd4e238079ef",
            "4a5e380649c54c71a461da0b3c2e8d53",
            "913fde915feb46169bde3c290428d22a",
            "eb1e94f3cb3b4b58bcb3d6abc9867616",
            "24d70321d3f84f97a878e3bd5bd7457c",
            "553100ff610c4109b7d2751aac93b011",
            "03562d27eb8542ab9cb810277e5a4516",
            "62809e3e46604107bcd447fafa81557a",
            "f4552d587b2d4bca8e4c1753d1684dda",
            "047bdea5222a48c2a6293b074678f0b5",
            "0dc626ae7491472eb692789e56f7139c",
            "11455b43a98042719ffacb77912baf29"
          ]
        },
        "id": "gYTWgbNz7_GP",
        "outputId": "3e550448-cb02-4f2a-9477-5aa4f98a9ba6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_c73d8 th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_c73d8_row0_col0, #T_c73d8_row0_col1, #T_c73d8_row0_col2, #T_c73d8_row0_col3, #T_c73d8_row0_col5, #T_c73d8_row0_col6, #T_c73d8_row1_col0, #T_c73d8_row1_col1, #T_c73d8_row1_col2, #T_c73d8_row1_col3, #T_c73d8_row1_col4, #T_c73d8_row1_col5, #T_c73d8_row1_col6, #T_c73d8_row2_col0, #T_c73d8_row2_col1, #T_c73d8_row2_col2, #T_c73d8_row2_col3, #T_c73d8_row2_col4, #T_c73d8_row2_col5, #T_c73d8_row2_col6, #T_c73d8_row3_col0, #T_c73d8_row3_col1, #T_c73d8_row3_col2, #T_c73d8_row3_col3, #T_c73d8_row3_col4, #T_c73d8_row3_col5, #T_c73d8_row3_col6, #T_c73d8_row4_col0, #T_c73d8_row4_col4, #T_c73d8_row5_col0, #T_c73d8_row5_col1, #T_c73d8_row5_col2, #T_c73d8_row5_col3, #T_c73d8_row5_col4, #T_c73d8_row5_col5, #T_c73d8_row5_col6, #T_c73d8_row6_col0, #T_c73d8_row6_col1, #T_c73d8_row6_col2, #T_c73d8_row6_col3, #T_c73d8_row6_col4, #T_c73d8_row6_col5, #T_c73d8_row6_col6, #T_c73d8_row7_col0, #T_c73d8_row7_col1, #T_c73d8_row7_col2, #T_c73d8_row7_col3, #T_c73d8_row7_col4, #T_c73d8_row7_col5, #T_c73d8_row7_col6, #T_c73d8_row8_col0, #T_c73d8_row8_col1, #T_c73d8_row8_col2, #T_c73d8_row8_col3, #T_c73d8_row8_col4, #T_c73d8_row8_col5, #T_c73d8_row8_col6, #T_c73d8_row9_col0, #T_c73d8_row9_col1, #T_c73d8_row9_col2, #T_c73d8_row9_col3, #T_c73d8_row9_col4, #T_c73d8_row9_col5, #T_c73d8_row9_col6, #T_c73d8_row10_col0, #T_c73d8_row10_col1, #T_c73d8_row10_col2, #T_c73d8_row10_col3, #T_c73d8_row10_col4, #T_c73d8_row10_col5, #T_c73d8_row10_col6, #T_c73d8_row11_col0, #T_c73d8_row11_col1, #T_c73d8_row11_col2, #T_c73d8_row11_col3, #T_c73d8_row11_col4, #T_c73d8_row11_col5, #T_c73d8_row11_col6, #T_c73d8_row12_col0, #T_c73d8_row12_col1, #T_c73d8_row12_col2, #T_c73d8_row12_col3, #T_c73d8_row12_col4, #T_c73d8_row12_col5, #T_c73d8_row12_col6, #T_c73d8_row13_col0, #T_c73d8_row13_col1, #T_c73d8_row13_col2, #T_c73d8_row13_col3, #T_c73d8_row13_col4, #T_c73d8_row13_col5, #T_c73d8_row13_col6, #T_c73d8_row14_col0, #T_c73d8_row14_col1, #T_c73d8_row14_col2, #T_c73d8_row14_col3, #T_c73d8_row14_col4, #T_c73d8_row14_col5, #T_c73d8_row14_col6, #T_c73d8_row15_col0, #T_c73d8_row15_col1, #T_c73d8_row15_col2, #T_c73d8_row15_col3, #T_c73d8_row15_col4, #T_c73d8_row15_col5, #T_c73d8_row15_col6, #T_c73d8_row16_col0, #T_c73d8_row16_col1, #T_c73d8_row16_col2, #T_c73d8_row16_col3, #T_c73d8_row16_col4, #T_c73d8_row16_col5, #T_c73d8_row16_col6, #T_c73d8_row17_col0, #T_c73d8_row17_col1, #T_c73d8_row17_col2, #T_c73d8_row17_col3, #T_c73d8_row17_col4, #T_c73d8_row17_col5, #T_c73d8_row17_col6, #T_c73d8_row18_col0, #T_c73d8_row18_col1, #T_c73d8_row18_col2, #T_c73d8_row18_col3, #T_c73d8_row18_col4, #T_c73d8_row18_col5, #T_c73d8_row18_col6 {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_c73d8_row0_col4, #T_c73d8_row4_col1, #T_c73d8_row4_col2, #T_c73d8_row4_col3, #T_c73d8_row4_col5, #T_c73d8_row4_col6 {\n",
              "  text-align: left;\n",
              "  background-color: yellow;\n",
              "}\n",
              "#T_c73d8_row0_col7, #T_c73d8_row2_col7, #T_c73d8_row3_col7, #T_c73d8_row4_col7, #T_c73d8_row5_col7, #T_c73d8_row6_col7, #T_c73d8_row7_col7, #T_c73d8_row8_col7, #T_c73d8_row9_col7, #T_c73d8_row10_col7, #T_c73d8_row11_col7, #T_c73d8_row12_col7, #T_c73d8_row13_col7, #T_c73d8_row14_col7, #T_c73d8_row15_col7, #T_c73d8_row16_col7, #T_c73d8_row17_col7, #T_c73d8_row18_col7 {\n",
              "  text-align: left;\n",
              "  background-color: lightgrey;\n",
              "}\n",
              "#T_c73d8_row1_col7 {\n",
              "  text-align: left;\n",
              "  background-color: yellow;\n",
              "  background-color: lightgrey;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_c73d8\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_c73d8_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_c73d8_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
              "      <th id=\"T_c73d8_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
              "      <th id=\"T_c73d8_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
              "      <th id=\"T_c73d8_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
              "      <th id=\"T_c73d8_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
              "      <th id=\"T_c73d8_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
              "      <th id=\"T_c73d8_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
              "      <td id=\"T_c73d8_row0_col0\" class=\"data row0 col0\" >Extra Trees Regressor</td>\n",
              "      <td id=\"T_c73d8_row0_col1\" class=\"data row0 col1\" >204208922.6940</td>\n",
              "      <td id=\"T_c73d8_row0_col2\" class=\"data row0 col2\" >159983455784566016.0000</td>\n",
              "      <td id=\"T_c73d8_row0_col3\" class=\"data row0 col3\" >284229832.9318</td>\n",
              "      <td id=\"T_c73d8_row0_col4\" class=\"data row0 col4\" >0.0747</td>\n",
              "      <td id=\"T_c73d8_row0_col5\" class=\"data row0 col5\" >0.0989</td>\n",
              "      <td id=\"T_c73d8_row0_col6\" class=\"data row0 col6\" >0.0679</td>\n",
              "      <td id=\"T_c73d8_row0_col7\" class=\"data row0 col7\" >0.7060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row1\" class=\"row_heading level0 row1\" >dt</th>\n",
              "      <td id=\"T_c73d8_row1_col0\" class=\"data row1 col0\" >Decision Tree Regressor</td>\n",
              "      <td id=\"T_c73d8_row1_col1\" class=\"data row1 col1\" >264415125.3167</td>\n",
              "      <td id=\"T_c73d8_row1_col2\" class=\"data row1 col2\" >240211610476643520.0000</td>\n",
              "      <td id=\"T_c73d8_row1_col3\" class=\"data row1 col3\" >365257397.3254</td>\n",
              "      <td id=\"T_c73d8_row1_col4\" class=\"data row1 col4\" >-0.0856</td>\n",
              "      <td id=\"T_c73d8_row1_col5\" class=\"data row1 col5\" >0.1271</td>\n",
              "      <td id=\"T_c73d8_row1_col6\" class=\"data row1 col6\" >0.0912</td>\n",
              "      <td id=\"T_c73d8_row1_col7\" class=\"data row1 col7\" >0.4960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row2\" class=\"row_heading level0 row2\" >gbr</th>\n",
              "      <td id=\"T_c73d8_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Regressor</td>\n",
              "      <td id=\"T_c73d8_row2_col1\" class=\"data row2 col1\" >265412763.9172</td>\n",
              "      <td id=\"T_c73d8_row2_col2\" class=\"data row2 col2\" >240108541038375200.0000</td>\n",
              "      <td id=\"T_c73d8_row2_col3\" class=\"data row2 col3\" >365971969.7633</td>\n",
              "      <td id=\"T_c73d8_row2_col4\" class=\"data row2 col4\" >-0.0893</td>\n",
              "      <td id=\"T_c73d8_row2_col5\" class=\"data row2 col5\" >0.1272</td>\n",
              "      <td id=\"T_c73d8_row2_col6\" class=\"data row2 col6\" >0.0914</td>\n",
              "      <td id=\"T_c73d8_row2_col7\" class=\"data row2 col7\" >0.5580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row3\" class=\"row_heading level0 row3\" >ada</th>\n",
              "      <td id=\"T_c73d8_row3_col0\" class=\"data row3 col0\" >AdaBoost Regressor</td>\n",
              "      <td id=\"T_c73d8_row3_col1\" class=\"data row3 col1\" >260545558.7442</td>\n",
              "      <td id=\"T_c73d8_row3_col2\" class=\"data row3 col2\" >239634032656679744.0000</td>\n",
              "      <td id=\"T_c73d8_row3_col3\" class=\"data row3 col3\" >360607057.6470</td>\n",
              "      <td id=\"T_c73d8_row3_col4\" class=\"data row3 col4\" >-0.1103</td>\n",
              "      <td id=\"T_c73d8_row3_col5\" class=\"data row3 col5\" >0.1241</td>\n",
              "      <td id=\"T_c73d8_row3_col6\" class=\"data row3 col6\" >0.0890</td>\n",
              "      <td id=\"T_c73d8_row3_col7\" class=\"data row3 col7\" >0.5900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row4\" class=\"row_heading level0 row4\" >xgboost</th>\n",
              "      <td id=\"T_c73d8_row4_col0\" class=\"data row4 col0\" >Extreme Gradient Boosting</td>\n",
              "      <td id=\"T_c73d8_row4_col1\" class=\"data row4 col1\" >201178660.4833</td>\n",
              "      <td id=\"T_c73d8_row4_col2\" class=\"data row4 col2\" >155498464986255200.0000</td>\n",
              "      <td id=\"T_c73d8_row4_col3\" class=\"data row4 col3\" >260860367.2326</td>\n",
              "      <td id=\"T_c73d8_row4_col4\" class=\"data row4 col4\" >-0.7757</td>\n",
              "      <td id=\"T_c73d8_row4_col5\" class=\"data row4 col5\" >0.0896</td>\n",
              "      <td id=\"T_c73d8_row4_col6\" class=\"data row4 col6\" >0.0610</td>\n",
              "      <td id=\"T_c73d8_row4_col7\" class=\"data row4 col7\" >0.8360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row5\" class=\"row_heading level0 row5\" >rf</th>\n",
              "      <td id=\"T_c73d8_row5_col0\" class=\"data row5 col0\" >Random Forest Regressor</td>\n",
              "      <td id=\"T_c73d8_row5_col1\" class=\"data row5 col1\" >378250643.1360</td>\n",
              "      <td id=\"T_c73d8_row5_col2\" class=\"data row5 col2\" >254749824412364192.0000</td>\n",
              "      <td id=\"T_c73d8_row5_col3\" class=\"data row5 col3\" >473038247.7881</td>\n",
              "      <td id=\"T_c73d8_row5_col4\" class=\"data row5 col4\" >-41.9497</td>\n",
              "      <td id=\"T_c73d8_row5_col5\" class=\"data row5 col5\" >0.1474</td>\n",
              "      <td id=\"T_c73d8_row5_col6\" class=\"data row5 col6\" >0.1152</td>\n",
              "      <td id=\"T_c73d8_row5_col7\" class=\"data row5 col7\" >0.8420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row6\" class=\"row_heading level0 row6\" >par</th>\n",
              "      <td id=\"T_c73d8_row6_col0\" class=\"data row6 col0\" >Passive Aggressive Regressor</td>\n",
              "      <td id=\"T_c73d8_row6_col1\" class=\"data row6 col1\" >2661316949.2193</td>\n",
              "      <td id=\"T_c73d8_row6_col2\" class=\"data row6 col2\" >9149717899675844608.0000</td>\n",
              "      <td id=\"T_c73d8_row6_col3\" class=\"data row6 col3\" >2771754105.4979</td>\n",
              "      <td id=\"T_c73d8_row6_col4\" class=\"data row6 col4\" >-47.5376</td>\n",
              "      <td id=\"T_c73d8_row6_col5\" class=\"data row6 col5\" >8.3594</td>\n",
              "      <td id=\"T_c73d8_row6_col6\" class=\"data row6 col6\" >0.8130</td>\n",
              "      <td id=\"T_c73d8_row6_col7\" class=\"data row6 col7\" >0.6240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row7\" class=\"row_heading level0 row7\" >omp</th>\n",
              "      <td id=\"T_c73d8_row7_col0\" class=\"data row7 col0\" >Orthogonal Matching Pursuit</td>\n",
              "      <td id=\"T_c73d8_row7_col1\" class=\"data row7 col1\" >669337465.3833</td>\n",
              "      <td id=\"T_c73d8_row7_col2\" class=\"data row7 col2\" >949076486626257664.0000</td>\n",
              "      <td id=\"T_c73d8_row7_col3\" class=\"data row7 col3\" >859915379.6495</td>\n",
              "      <td id=\"T_c73d8_row7_col4\" class=\"data row7 col4\" >-162.4277</td>\n",
              "      <td id=\"T_c73d8_row7_col5\" class=\"data row7 col5\" >0.2020</td>\n",
              "      <td id=\"T_c73d8_row7_col6\" class=\"data row7 col6\" >0.1778</td>\n",
              "      <td id=\"T_c73d8_row7_col7\" class=\"data row7 col7\" >0.5180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row8\" class=\"row_heading level0 row8\" >lr</th>\n",
              "      <td id=\"T_c73d8_row8_col0\" class=\"data row8 col0\" >Linear Regression</td>\n",
              "      <td id=\"T_c73d8_row8_col1\" class=\"data row8 col1\" >669337418.4500</td>\n",
              "      <td id=\"T_c73d8_row8_col2\" class=\"data row8 col2\" >949076746406054656.0000</td>\n",
              "      <td id=\"T_c73d8_row8_col3\" class=\"data row8 col3\" >859915415.0936</td>\n",
              "      <td id=\"T_c73d8_row8_col4\" class=\"data row8 col4\" >-162.4277</td>\n",
              "      <td id=\"T_c73d8_row8_col5\" class=\"data row8 col5\" >0.2020</td>\n",
              "      <td id=\"T_c73d8_row8_col6\" class=\"data row8 col6\" >0.1778</td>\n",
              "      <td id=\"T_c73d8_row8_col7\" class=\"data row8 col7\" >0.5440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row9\" class=\"row_heading level0 row9\" >lar</th>\n",
              "      <td id=\"T_c73d8_row9_col0\" class=\"data row9 col0\" >Least Angle Regression</td>\n",
              "      <td id=\"T_c73d8_row9_col1\" class=\"data row9 col1\" >669337465.3833</td>\n",
              "      <td id=\"T_c73d8_row9_col2\" class=\"data row9 col2\" >949076486626257664.0000</td>\n",
              "      <td id=\"T_c73d8_row9_col3\" class=\"data row9 col3\" >859915379.6495</td>\n",
              "      <td id=\"T_c73d8_row9_col4\" class=\"data row9 col4\" >-162.4277</td>\n",
              "      <td id=\"T_c73d8_row9_col5\" class=\"data row9 col5\" >0.2020</td>\n",
              "      <td id=\"T_c73d8_row9_col6\" class=\"data row9 col6\" >0.1778</td>\n",
              "      <td id=\"T_c73d8_row9_col7\" class=\"data row9 col7\" >0.5060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row10\" class=\"row_heading level0 row10\" >br</th>\n",
              "      <td id=\"T_c73d8_row10_col0\" class=\"data row10 col0\" >Bayesian Ridge</td>\n",
              "      <td id=\"T_c73d8_row10_col1\" class=\"data row10 col1\" >936650175.7167</td>\n",
              "      <td id=\"T_c73d8_row10_col2\" class=\"data row10 col2\" >1035484320957608704.0000</td>\n",
              "      <td id=\"T_c73d8_row10_col3\" class=\"data row10 col3\" >968829674.2362</td>\n",
              "      <td id=\"T_c73d8_row10_col4\" class=\"data row10 col4\" >-167.2572</td>\n",
              "      <td id=\"T_c73d8_row10_col5\" class=\"data row10 col5\" >0.2970</td>\n",
              "      <td id=\"T_c73d8_row10_col6\" class=\"data row10 col6\" >0.3115</td>\n",
              "      <td id=\"T_c73d8_row10_col7\" class=\"data row10 col7\" >0.6000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row11\" class=\"row_heading level0 row11\" >ridge</th>\n",
              "      <td id=\"T_c73d8_row11_col0\" class=\"data row11 col0\" >Ridge Regression</td>\n",
              "      <td id=\"T_c73d8_row11_col1\" class=\"data row11 col1\" >683252883.1167</td>\n",
              "      <td id=\"T_c73d8_row11_col2\" class=\"data row11 col2\" >865267497434534784.0000</td>\n",
              "      <td id=\"T_c73d8_row11_col3\" class=\"data row11 col3\" >839985053.6044</td>\n",
              "      <td id=\"T_c73d8_row11_col4\" class=\"data row11 col4\" >-177.6363</td>\n",
              "      <td id=\"T_c73d8_row11_col5\" class=\"data row11 col5\" >0.2033</td>\n",
              "      <td id=\"T_c73d8_row11_col6\" class=\"data row11 col6\" >0.1857</td>\n",
              "      <td id=\"T_c73d8_row11_col7\" class=\"data row11 col7\" >0.6120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row12\" class=\"row_heading level0 row12\" >huber</th>\n",
              "      <td id=\"T_c73d8_row12_col0\" class=\"data row12 col0\" >Huber Regressor</td>\n",
              "      <td id=\"T_c73d8_row12_col1\" class=\"data row12 col1\" >1738342784.4862</td>\n",
              "      <td id=\"T_c73d8_row12_col2\" class=\"data row12 col2\" >4670148089893505024.0000</td>\n",
              "      <td id=\"T_c73d8_row12_col3\" class=\"data row12 col3\" >1820954128.9855</td>\n",
              "      <td id=\"T_c73d8_row12_col4\" class=\"data row12 col4\" >-184.8372</td>\n",
              "      <td id=\"T_c73d8_row12_col5\" class=\"data row12 col5\" >7.6697</td>\n",
              "      <td id=\"T_c73d8_row12_col6\" class=\"data row12 col6\" >0.5523</td>\n",
              "      <td id=\"T_c73d8_row12_col7\" class=\"data row12 col7\" >0.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row13\" class=\"row_heading level0 row13\" >knn</th>\n",
              "      <td id=\"T_c73d8_row13_col0\" class=\"data row13 col0\" >K Neighbors Regressor</td>\n",
              "      <td id=\"T_c73d8_row13_col1\" class=\"data row13 col1\" >628832774.3420</td>\n",
              "      <td id=\"T_c73d8_row13_col2\" class=\"data row13 col2\" >563647179225556544.0000</td>\n",
              "      <td id=\"T_c73d8_row13_col3\" class=\"data row13 col3\" >687586183.0031</td>\n",
              "      <td id=\"T_c73d8_row13_col4\" class=\"data row13 col4\" >-196.0254</td>\n",
              "      <td id=\"T_c73d8_row13_col5\" class=\"data row13 col5\" >0.2059</td>\n",
              "      <td id=\"T_c73d8_row13_col6\" class=\"data row13 col6\" >0.1880</td>\n",
              "      <td id=\"T_c73d8_row13_col7\" class=\"data row13 col7\" >0.5280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row14\" class=\"row_heading level0 row14\" >en</th>\n",
              "      <td id=\"T_c73d8_row14_col0\" class=\"data row14 col0\" >Elastic Net</td>\n",
              "      <td id=\"T_c73d8_row14_col1\" class=\"data row14 col1\" >838685270.1833</td>\n",
              "      <td id=\"T_c73d8_row14_col2\" class=\"data row14 col2\" >940522695197598976.0000</td>\n",
              "      <td id=\"T_c73d8_row14_col3\" class=\"data row14 col3\" >885015742.4000</td>\n",
              "      <td id=\"T_c73d8_row14_col4\" class=\"data row14 col4\" >-460.4980</td>\n",
              "      <td id=\"T_c73d8_row14_col5\" class=\"data row14 col5\" >0.2492</td>\n",
              "      <td id=\"T_c73d8_row14_col6\" class=\"data row14 col6\" >0.2395</td>\n",
              "      <td id=\"T_c73d8_row14_col7\" class=\"data row14 col7\" >0.5700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row15\" class=\"row_heading level0 row15\" >dummy</th>\n",
              "      <td id=\"T_c73d8_row15_col0\" class=\"data row15 col0\" >Dummy Regressor</td>\n",
              "      <td id=\"T_c73d8_row15_col1\" class=\"data row15 col1\" >1065724495.5126</td>\n",
              "      <td id=\"T_c73d8_row15_col2\" class=\"data row15 col2\" >1358613603279411456.0000</td>\n",
              "      <td id=\"T_c73d8_row15_col3\" class=\"data row15 col3\" >1095441711.6440</td>\n",
              "      <td id=\"T_c73d8_row15_col4\" class=\"data row15 col4\" >-460.8168</td>\n",
              "      <td id=\"T_c73d8_row15_col5\" class=\"data row15 col5\" >0.3344</td>\n",
              "      <td id=\"T_c73d8_row15_col6\" class=\"data row15 col6\" >0.3393</td>\n",
              "      <td id=\"T_c73d8_row15_col7\" class=\"data row15 col7\" >0.6540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row16\" class=\"row_heading level0 row16\" >lightgbm</th>\n",
              "      <td id=\"T_c73d8_row16_col0\" class=\"data row16 col0\" >Light Gradient Boosting Machine</td>\n",
              "      <td id=\"T_c73d8_row16_col1\" class=\"data row16 col1\" >1065724779.8379</td>\n",
              "      <td id=\"T_c73d8_row16_col2\" class=\"data row16 col2\" >1358614493782137600.0000</td>\n",
              "      <td id=\"T_c73d8_row16_col3\" class=\"data row16 col3\" >1095441992.2676</td>\n",
              "      <td id=\"T_c73d8_row16_col4\" class=\"data row16 col4\" >-460.8177</td>\n",
              "      <td id=\"T_c73d8_row16_col5\" class=\"data row16 col5\" >0.3344</td>\n",
              "      <td id=\"T_c73d8_row16_col6\" class=\"data row16 col6\" >0.3393</td>\n",
              "      <td id=\"T_c73d8_row16_col7\" class=\"data row16 col7\" >0.6500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row17\" class=\"row_heading level0 row17\" >lasso</th>\n",
              "      <td id=\"T_c73d8_row17_col0\" class=\"data row17 col0\" >Lasso Regression</td>\n",
              "      <td id=\"T_c73d8_row17_col1\" class=\"data row17 col1\" >801356475.5167</td>\n",
              "      <td id=\"T_c73d8_row17_col2\" class=\"data row17 col2\" >1277551586811149568.0000</td>\n",
              "      <td id=\"T_c73d8_row17_col3\" class=\"data row17 col3\" >989331580.1471</td>\n",
              "      <td id=\"T_c73d8_row17_col4\" class=\"data row17 col4\" >-460.8487</td>\n",
              "      <td id=\"T_c73d8_row17_col5\" class=\"data row17 col5\" >0.2402</td>\n",
              "      <td id=\"T_c73d8_row17_col6\" class=\"data row17 col6\" >0.2061</td>\n",
              "      <td id=\"T_c73d8_row17_col7\" class=\"data row17 col7\" >0.5380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c73d8_level0_row18\" class=\"row_heading level0 row18\" >llar</th>\n",
              "      <td id=\"T_c73d8_row18_col0\" class=\"data row18 col0\" >Lasso Least Angle Regression</td>\n",
              "      <td id=\"T_c73d8_row18_col1\" class=\"data row18 col1\" >801356520.3167</td>\n",
              "      <td id=\"T_c73d8_row18_col2\" class=\"data row18 col2\" >1277551640233339648.0000</td>\n",
              "      <td id=\"T_c73d8_row18_col3\" class=\"data row18 col3\" >989331629.1067</td>\n",
              "      <td id=\"T_c73d8_row18_col4\" class=\"data row18 col4\" >-460.8487</td>\n",
              "      <td id=\"T_c73d8_row18_col5\" class=\"data row18 col5\" >0.2402</td>\n",
              "      <td id=\"T_c73d8_row18_col6\" class=\"data row18 col6\" >0.2061</td>\n",
              "      <td id=\"T_c73d8_row18_col7\" class=\"data row18 col7\" >0.5020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f148da0ce20>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "784e575c15a74be1bec4801f65110ab7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing:   0%|          | 0/81 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_844ad_row5_col0, #T_844ad_row5_col1, #T_844ad_row5_col2, #T_844ad_row5_col3, #T_844ad_row5_col4, #T_844ad_row5_col5 {\n",
              "  background: yellow;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_844ad\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_844ad_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
              "      <th id=\"T_844ad_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
              "      <th id=\"T_844ad_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
              "      <th id=\"T_844ad_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
              "      <th id=\"T_844ad_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
              "      <th id=\"T_844ad_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >Fold</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "      <th class=\"blank col2\" >&nbsp;</th>\n",
              "      <th class=\"blank col3\" >&nbsp;</th>\n",
              "      <th class=\"blank col4\" >&nbsp;</th>\n",
              "      <th class=\"blank col5\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_844ad_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_844ad_row0_col0\" class=\"data row0 col0\" >702587699.2284</td>\n",
              "      <td id=\"T_844ad_row0_col1\" class=\"data row0 col1\" >527356951404342592.0000</td>\n",
              "      <td id=\"T_844ad_row0_col2\" class=\"data row0 col2\" >726193466.9249</td>\n",
              "      <td id=\"T_844ad_row0_col3\" class=\"data row0 col3\" >0.4615</td>\n",
              "      <td id=\"T_844ad_row0_col4\" class=\"data row0 col4\" >0.2577</td>\n",
              "      <td id=\"T_844ad_row0_col5\" class=\"data row0 col5\" >0.2715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_844ad_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_844ad_row1_col0\" class=\"data row1 col0\" >273389096.2898</td>\n",
              "      <td id=\"T_844ad_row1_col1\" class=\"data row1 col1\" >94870116923508512.0000</td>\n",
              "      <td id=\"T_844ad_row1_col2\" class=\"data row1 col2\" >308009929.9106</td>\n",
              "      <td id=\"T_844ad_row1_col3\" class=\"data row1 col3\" >0.9393</td>\n",
              "      <td id=\"T_844ad_row1_col4\" class=\"data row1 col4\" >0.1252</td>\n",
              "      <td id=\"T_844ad_row1_col5\" class=\"data row1 col5\" >0.1098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_844ad_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_844ad_row2_col0\" class=\"data row2 col0\" >766400893.9033</td>\n",
              "      <td id=\"T_844ad_row2_col1\" class=\"data row2 col1\" >594745254493849856.0000</td>\n",
              "      <td id=\"T_844ad_row2_col2\" class=\"data row2 col2\" >771197286.3631</td>\n",
              "      <td id=\"T_844ad_row2_col3\" class=\"data row2 col3\" >0.3197</td>\n",
              "      <td id=\"T_844ad_row2_col4\" class=\"data row2 col4\" >0.2358</td>\n",
              "      <td id=\"T_844ad_row2_col5\" class=\"data row2 col5\" >0.2558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_844ad_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_844ad_row3_col0\" class=\"data row3 col0\" >1110558418.1665</td>\n",
              "      <td id=\"T_844ad_row3_col1\" class=\"data row3 col1\" >1243576967820303616.0000</td>\n",
              "      <td id=\"T_844ad_row3_col2\" class=\"data row3 col2\" >1115157821.9339</td>\n",
              "      <td id=\"T_844ad_row3_col3\" class=\"data row3 col3\" >-1128.7769</td>\n",
              "      <td id=\"T_844ad_row3_col4\" class=\"data row3 col4\" >0.2736</td>\n",
              "      <td id=\"T_844ad_row3_col5\" class=\"data row3 col5\" >0.2382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_844ad_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_844ad_row4_col0\" class=\"data row4 col0\" >357411795.4585</td>\n",
              "      <td id=\"T_844ad_row4_col1\" class=\"data row4 col1\" >190645125665619808.0000</td>\n",
              "      <td id=\"T_844ad_row4_col2\" class=\"data row4 col2\" >436629277.1512</td>\n",
              "      <td id=\"T_844ad_row4_col3\" class=\"data row4 col3\" >-0.3960</td>\n",
              "      <td id=\"T_844ad_row4_col4\" class=\"data row4 col4\" >0.1335</td>\n",
              "      <td id=\"T_844ad_row4_col5\" class=\"data row4 col5\" >0.1086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_844ad_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
              "      <td id=\"T_844ad_row5_col0\" class=\"data row5 col0\" >642069580.6093</td>\n",
              "      <td id=\"T_844ad_row5_col1\" class=\"data row5 col1\" >530238883261524864.0000</td>\n",
              "      <td id=\"T_844ad_row5_col2\" class=\"data row5 col2\" >671437556.4567</td>\n",
              "      <td id=\"T_844ad_row5_col3\" class=\"data row5 col3\" >-225.4905</td>\n",
              "      <td id=\"T_844ad_row5_col4\" class=\"data row5 col4\" >0.2052</td>\n",
              "      <td id=\"T_844ad_row5_col5\" class=\"data row5 col5\" >0.1968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_844ad_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
              "      <td id=\"T_844ad_row6_col0\" class=\"data row6 col0\" >301846935.7894</td>\n",
              "      <td id=\"T_844ad_row6_col1\" class=\"data row6 col1\" >404447891141385984.0000</td>\n",
              "      <td id=\"T_844ad_row6_col2\" class=\"data row6 col2\" >281798671.1128</td>\n",
              "      <td id=\"T_844ad_row6_col3\" class=\"data row6 col3\" >451.6434</td>\n",
              "      <td id=\"T_844ad_row6_col4\" class=\"data row6 col4\" >0.0631</td>\n",
              "      <td id=\"T_844ad_row6_col5\" class=\"data row6 col5\" >0.0723</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f13c2591d20>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11455b43a98042719ffacb77912baf29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
          ]
        }
      ],
      "source": [
        "# best model\n",
        "best_model = compare_models()\n",
        "\n",
        "# tune\n",
        "tuned_model = tune_model(best_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/user/AppData/Local/Programs/Python/Python37/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "c:/Users/user/AppData/Local/Programs/Python/Python37/python.exe -m pip install ipykernel -U --user --force-reinstall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Auto ML : AutoGluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.core==1.0.0 (from autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading autogluon.core-1.0.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.features==1.0.0 (from autogluon)\n",
            "  Downloading autogluon.features-1.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.tabular==1.0.0 (from autogluon.tabular[all]==1.0.0->autogluon)\n",
            "  Downloading autogluon.tabular-1.0.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting autogluon.multimodal==1.0.0 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.0.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting autogluon.timeseries==1.0.0 (from autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading autogluon.timeseries-1.0.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<1.29,>=1.21 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (1.24.3)\n",
            "Requirement already satisfied: scipy<1.13,>=1.5.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (1.10.1)\n",
            "Collecting scikit-learn<1.5,>=1.3.0 (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Using cached scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (3.1)\n",
            "Collecting pandas<2.2.0,>=2.0.0 (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading pandas-2.1.4-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (4.66.1)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (3.6.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading boto3-1.34.10-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.0.0 (from autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading autogluon.common-1.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting ray<2.7,>=2.6.3 (from ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading ray-2.6.3-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: async-timeout in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.core[all]==1.0.0->autogluon) (4.0.3)\n",
            "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
            "     -------------- ------------------------- 0.6/1.6 MB 12.5 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 1.3/1.6 MB 13.7 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.6/1.6 MB 14.4 MB/s eta 0:00:00\n",
            "Collecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Using cached Pillow-10.1.0-cp311-cp311-win_amd64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: torch<2.1,>=2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.multimodal==1.0.0->autogluon) (2.0.1)\n",
            "Collecting lightning<2.1,>=2.0.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lightning-2.0.9.post0-py3-none-any.whl.metadata (41 kB)\n",
            "     ---------------------------------------- 0.0/41.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 41.2/41.2 kB 1.9 MB/s eta 0:00:00\n",
            "Collecting jsonschema<4.18,>=4.14 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "     ---------------------------------------- 0.0/90.4 kB ? eta -:--:--\n",
            "     ---------------------------------------- 90.4/90.4 kB 5.3 MB/s eta 0:00:00\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 43.6/43.6 kB 2.2 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting transformers<4.32.0,>=4.31.0 (from transformers[sentencepiece]<4.32.0,>=4.31.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "     ---------------------------------------- 0.0/116.9 kB ? eta -:--:--\n",
            "     ---------------------------------------- 116.9/116.9 kB ? eta 0:00:00\n",
            "Collecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
            "     ---------------------------------------- 0.0/60.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 60.6/60.6 kB ? eta 0:00:00\n",
            "Collecting torchvision<0.16.0,>=0.14.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading torchvision-0.15.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
            "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "     ------------------------ --------------- 0.7/1.2 MB 23.1 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.2/1.2 MB 18.8 MB/s eta 0:00:00\n",
            "Collecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading scikit_image-0.20.0-cp311-cp311-win_amd64.whl (23.7 MB)\n",
            "     ---------------------------------------- 0.0/23.7 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.8/23.7 MB 25.0 MB/s eta 0:00:01\n",
            "     --- ------------------------------------ 1.9/23.7 MB 23.3 MB/s eta 0:00:01\n",
            "     ---- ----------------------------------- 2.8/23.7 MB 22.3 MB/s eta 0:00:01\n",
            "     ------ --------------------------------- 3.9/23.7 MB 22.6 MB/s eta 0:00:01\n",
            "     -------- ------------------------------- 5.0/23.7 MB 22.6 MB/s eta 0:00:01\n",
            "     ---------- ----------------------------- 6.3/23.7 MB 23.8 MB/s eta 0:00:01\n",
            "     ------------ --------------------------- 7.6/23.7 MB 25.4 MB/s eta 0:00:01\n",
            "     -------------- ------------------------- 8.5/23.7 MB 24.6 MB/s eta 0:00:01\n",
            "     ---------------- ----------------------- 9.7/23.7 MB 24.7 MB/s eta 0:00:01\n",
            "     ----------------- --------------------- 10.4/23.7 MB 23.4 MB/s eta 0:00:01\n",
            "     ------------------- ------------------- 11.6/23.7 MB 23.4 MB/s eta 0:00:01\n",
            "     --------------------- ----------------- 13.1/23.7 MB 25.1 MB/s eta 0:00:01\n",
            "     ---------------------- ---------------- 13.6/23.7 MB 23.4 MB/s eta 0:00:01\n",
            "     ---------------------- ---------------- 13.6/23.7 MB 24.2 MB/s eta 0:00:01\n",
            "     ---------------------- ---------------- 13.6/23.7 MB 24.2 MB/s eta 0:00:01\n",
            "     ---------------------- ---------------- 13.6/23.7 MB 24.2 MB/s eta 0:00:01\n",
            "     ----------------------- --------------- 14.0/23.7 MB 16.8 MB/s eta 0:00:01\n",
            "     ------------------------- ------------- 15.4/23.7 MB 17.2 MB/s eta 0:00:01\n",
            "     -------------------------- ------------ 16.3/23.7 MB 16.8 MB/s eta 0:00:01\n",
            "     --------------------------- ----------- 16.5/23.7 MB 16.0 MB/s eta 0:00:01\n",
            "     --------------------------- ----------- 16.7/23.7 MB 14.9 MB/s eta 0:00:01\n",
            "     ----------------------------- --------- 17.7/23.7 MB 14.9 MB/s eta 0:00:01\n",
            "     ------------------------------ -------- 18.8/23.7 MB 15.2 MB/s eta 0:00:01\n",
            "     --------------------------------- ----- 20.2/23.7 MB 15.6 MB/s eta 0:00:01\n",
            "     ----------------------------------- --- 21.5/23.7 MB 15.6 MB/s eta 0:00:01\n",
            "     ------------------------------------- - 22.9/23.7 MB 15.6 MB/s eta 0:00:01\n",
            "     --------------------------------------  23.6/23.7 MB 16.4 MB/s eta 0:00:01\n",
            "     --------------------------------------  23.7/23.7 MB 15.6 MB/s eta 0:00:01\n",
            "     --------------------------------------- 23.7/23.7 MB 14.5 MB/s eta 0:00:00\n",
            "Collecting text-unidecode<1.4,>=1.3 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "     ---------------------------------------- 0.0/78.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 78.2/78.2 kB 4.2 MB/s eta 0:00:00\n",
            "Collecting torchmetrics<1.2.0,>=1.0.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading torchmetrics-1.1.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "     ---------------------------------------- 0.0/79.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 79.3/79.3 kB ? eta 0:00:00\n",
            "Collecting pytorch-metric-learning<2.0,>=1.3.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)\n",
            "     ---------------------------------------- 0.0/112.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 112.2/112.2 kB ? eta 0:00:00\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "     ---------------------------------------- 0.0/410.5 kB ? eta -:--:--\n",
            "     ------------------------------------- 410.5/410.5 kB 12.9 MB/s eta 0:00:00\n",
            "Collecting nltk<4.0.0,>=3.4.5 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "     ---------------------- ----------------- 0.9/1.5 MB 27.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.5/1.5 MB 23.8 MB/s eta 0:00:00\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting defusedxml<0.7.2,>=0.7.1 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.multimodal==1.0.0->autogluon) (3.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.multimodal==1.0.0->autogluon) (2.13.0)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: xgboost<2.1,>=1.6 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.tabular[all]==1.0.0->autogluon) (2.0.0)\n",
            "Collecting fastai<2.8,>=2.3.1 (from autogluon.tabular[all]==1.0.0->autogluon)\n",
            "  Downloading fastai-2.7.13-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: lightgbm<4.2,>=3.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.tabular[all]==1.0.0->autogluon) (4.1.0)\n",
            "Requirement already satisfied: catboost<1.3,>=1.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.tabular[all]==1.0.0->autogluon) (1.2.2)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (1.3.1)\n",
            "Collecting pytorch-lightning<2.1,>=2.0.0 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading pytorch_lightning-2.0.9.post0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: statsmodels<0.15,>=0.13.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.14.1)\n",
            "Collecting gluonts<0.15,>=0.14.0 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading gluonts-0.14.3-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
            "     ---------------------------------------- 0.0/92.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 92.0/92.0 kB 5.4 MB/s eta 0:00:00\n",
            "Collecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: orjson~=3.9 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (3.9.10)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from autogluon.common==1.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from autogluon.common==1.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.0.0->autogluon) (23.1)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.0.0->autogluon) (6.0.1)\n",
            "Collecting botocore<1.35.0,>=1.34.10 (from boto3<2,>=1.10->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading botocore-1.34.10-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (0.20.1)\n",
            "Requirement already satisfied: plotly in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (5.16.1)\n",
            "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (1.16.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: xxhash in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (3.4.1)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (2023.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (0.16.4)\n",
            "Collecting responses<0.19 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pip in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (23.3.2)\n",
            "Collecting fastdownload<2,>=0.0.5 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon)\n",
            "  Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
            "Collecting fastcore<1.6,>=1.5.29 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon)\n",
            "  Downloading fastcore-1.5.29-py3-none-any.whl (67 kB)\n",
            "     ---------------------------------------- 0.0/67.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 67.6/67.6 kB ? eta 0:00:00\n",
            "Collecting fastprogress>=0.2.4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon)\n",
            "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
            "Collecting spacy<4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon)\n",
            "  Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (2.3.0)\n",
            "Requirement already satisfied: toolz~=0.10 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (4.8.0)\n",
            "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading future-0.18.3.tar.gz (840 kB)\n",
            "     ---------------------------------------- 0.0/840.9 kB ? eta -:--:--\n",
            "     ------------------------------------- 840.9/840.9 kB 51.9 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: cloudpickle in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.0.0->autogluon) (3.0.0)\n",
            "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "     ---------------------------------------- 0.0/200.5 kB ? eta -:--:--\n",
            "     ------------------------------------- 200.5/200.5 kB 12.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.0.0->autogluon) (2.1.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==1.0.0->autogluon) (23.1.0)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<4.18,>=4.14->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pyrsistent-0.20.0-cp311-cp311-win_amd64.whl.metadata (976 bytes)\n",
            "Collecting arrow<3.0,>=1.2.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting backoff<4.0,>=2.2.1 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (4.12.2)\n",
            "Requirement already satisfied: click<10.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (8.1.7)\n",
            "Collecting croniter<1.5.0,>=1.3.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading croniter-1.4.1-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting dateutils<2.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting deepdiff<8.0,>=5.7.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading deepdiff-6.7.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting fastapi<2.0,>=0.92.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading fastapi-0.108.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting inquirer<5.0,>=2.10.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading inquirer-3.1.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting lightning-cloud>=0.5.38 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lightning_cloud-0.5.57-py3-none-any.whl.metadata (933 bytes)\n",
            "Collecting lightning-utilities<2.0,>=0.7.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting pydantic<3,>=1.7 (from gluonts<0.15,>=0.14.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading pydantic-2.1.1-py3-none-any.whl.metadata (136 kB)\n",
            "     ---------------------------------------- 0.0/136.5 kB ? eta -:--:--\n",
            "     -------------------------------------- 136.5/136.5 kB 7.9 MB/s eta 0:00:00\n",
            "Collecting python-multipart<2.0,>=0.0.5 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "     ---------------------------------------- 0.0/45.7 kB ? eta -:--:--\n",
            "     ---------------------------------------- 45.7/45.7 kB ? eta 0:00:00\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (13.5.2)\n",
            "Requirement already satisfied: starlette in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (0.27.0)\n",
            "Collecting starsessions<2.0,>=1.2.1 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (5.9.0)\n",
            "Requirement already satisfied: urllib3<4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (1.26.16)\n",
            "Requirement already satisfied: uvicorn<2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (0.23.2)\n",
            "Collecting websocket-client<3.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting websockets<13.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading websockets-12.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: numba in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.57.1)\n",
            "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading window_ops-0.0.14-py3-none-any.whl (14 kB)\n",
            "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.0.0->autogluon) (2023.8.8)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "     ---------------------------------------- 0.0/117.0 kB ? eta -:--:--\n",
            "     -------------------------------------- 117.0/117.0 kB 6.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon) (0.4.6)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas<2.2.0,>=2.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas<2.2.0,>=2.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas<2.2.0,>=2.0.0->autogluon.core==1.0.0->autogluon.core[all]==1.0.0->autogluon) (2023.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (3.12.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (1.58.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon) (3.8.6)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n",
            "     ---------------------------------------- 0.0/201.4 kB ? eta -:--:--\n",
            "     ---------------------------------------- 201.4/201.4 kB ? eta 0:00:00\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-win_amd64.whl (1.4 MB)\n",
            "     ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
            "     ---------------------------- ----------- 1.0/1.4 MB 33.4 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.4/1.4 MB 18.4 MB/s eta 0:00:00\n",
            "Collecting gpustat>=1.0.0 (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading gpustat-1.1.1.tar.gz (98 kB)\n",
            "     ---------------------------------------- 0.0/98.1 kB ? eta -:--:--\n",
            "     ---------------------------------------- 98.1/98.1 kB ? eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting opencensus (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading opencensus-0.11.3-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic<3,>=1.7 (from gluonts<0.15,>=0.14.0->autogluon.timeseries==1.0.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading pydantic-1.10.13-cp311-cp311-win_amd64.whl.metadata (150 kB)\n",
            "     ---------------------------------------- 0.0/150.9 kB ? eta -:--:--\n",
            "     -------------------------------------- 150.9/150.9 kB 8.8 MB/s eta 0:00:00\n",
            "Collecting prometheus-client>=0.7.1 (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading prometheus_client-0.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting smart-open (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv<20.21.1,>=20.0.24 (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "     ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
            "     ----- ---------------------------------- 1.3/8.7 MB 41.3 MB/s eta 0:00:01\n",
            "     ---------- ----------------------------- 2.3/8.7 MB 29.7 MB/s eta 0:00:01\n",
            "     ---------------- ----------------------- 3.7/8.7 MB 29.3 MB/s eta 0:00:01\n",
            "     ------------------- -------------------- 4.2/8.7 MB 29.8 MB/s eta 0:00:01\n",
            "     ----------------------- ---------------- 5.0/8.7 MB 23.0 MB/s eta 0:00:01\n",
            "     ---------------------------- ----------- 6.3/8.7 MB 23.6 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 7.5/8.7 MB 24.1 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 8.4/8.7 MB 24.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------  8.7/8.7 MB 22.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 8.7/8.7 MB 20.6 MB/s eta 0:00:00\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pyarrow<7.0.0,>=6.0.1 (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading pyarrow-6.0.1.tar.gz (770 kB)\n",
            "     ---------------------------------------- 0.0/770.7 kB ? eta -:--:--\n",
            "     ------------------------------------- 770.7/770.7 kB 23.8 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'DOSKEY'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n",
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × pip subprocess to install build dependencies did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [8 lines of output]\n",
            "      Ignoring numpy: markers 'python_version < \"3.8\"' don't match your environment\n",
            "      Ignoring numpy: markers 'python_version == \"3.8\"' don't match your environment\n",
            "      Ignoring numpy: markers 'python_version == \"3.9\"' don't match your environment\n",
            "      Collecting cython>=0.29\n",
            "        Using cached Cython-3.0.7-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
            "      ERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\n",
            "      ERROR: Could not find a version that satisfies the requirement numpy==1.21.3 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0rc1, 1.23.0rc2, 1.23.0rc3, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0rc1, 1.24.0rc2, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.25.0rc1, 1.25.0, 1.25.1, 1.25.2, 1.26.0b1, 1.26.0rc1, 1.26.0, 1.26.1, 1.26.2)\n",
            "      ERROR: No matching distribution found for numpy==1.21.3\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× pip subprocess to install build dependencies did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!pip install autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (23.3.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'DOSKEY'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.20.3\n",
            "  Downloading numpy-1.20.3.zip (7.8 MB)\n",
            "     ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.3/7.8 MB 3.2 MB/s eta 0:00:03\n",
            "     -- ------------------------------------- 0.6/7.8 MB 4.4 MB/s eta 0:00:02\n",
            "     ---- ----------------------------------- 0.9/7.8 MB 5.0 MB/s eta 0:00:02\n",
            "     ----- ---------------------------------- 1.1/7.8 MB 5.1 MB/s eta 0:00:02\n",
            "     --------- ------------------------------ 1.9/7.8 MB 7.2 MB/s eta 0:00:01\n",
            "     ---------- ----------------------------- 2.1/7.8 MB 7.8 MB/s eta 0:00:01\n",
            "     ---------- ----------------------------- 2.1/7.8 MB 7.8 MB/s eta 0:00:01\n",
            "     ----------- ---------------------------- 2.2/7.8 MB 5.3 MB/s eta 0:00:02\n",
            "     --------------- ------------------------ 3.0/7.8 MB 6.8 MB/s eta 0:00:01\n",
            "     ----------------- ---------------------- 3.4/7.8 MB 7.2 MB/s eta 0:00:01\n",
            "     -------------------- ------------------- 4.0/7.8 MB 7.5 MB/s eta 0:00:01\n",
            "     ------------------------ --------------- 4.7/7.8 MB 8.1 MB/s eta 0:00:01\n",
            "     ------------------------------ --------- 5.9/7.8 MB 9.5 MB/s eta 0:00:01\n",
            "     ---------------------------------- ----- 6.7/7.8 MB 10.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------  7.8/7.8 MB 10.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 7.8/7.8 MB 10.6 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'DOSKEY'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n",
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [215 lines of output]\n",
            "      setup.py:66: RuntimeWarning: NumPy 1.20.3 may not yet support Python 3.11.\n",
            "        warnings.warn(\n",
            "      Running from numpy source directory.\n",
            "      setup.py:485: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\n",
            "        run_build = parse_setuppy_commands()\n",
            "      Cythonizing sources\n",
            "      Processing numpy/random\\_bounded_integers.pxd.in\n",
            "      Processing numpy/random\\bit_generator.pyx\n",
            "      Processing numpy/random\\mtrand.pyx\n",
            "      Processing numpy/random\\_bounded_integers.pyx.in\n",
            "      Processing numpy/random\\_common.pyx\n",
            "      Processing numpy/random\\_generator.pyx\n",
            "      Processing numpy/random\\_mt19937.pyx\n",
            "      Processing numpy/random\\_pcg64.pyx\n",
            "      Processing numpy/random\\_philox.pyx\n",
            "      Processing numpy/random\\_sfc64.pyx\n",
            "      blas_opt_info:\n",
            "      blas_mkl_info:\n",
            "      No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
            "      customize MSVCCompiler\n",
            "        libraries mkl_rt not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      blis_info:\n",
            "        libraries blis not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      openblas_info:\n",
            "        libraries openblas not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "      get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
            "      customize GnuFCompiler\n",
            "      Could not locate executable g77\n",
            "      Could not locate executable f77\n",
            "      customize IntelVisualFCompiler\n",
            "      Could not locate executable ifort\n",
            "      Could not locate executable ifl\n",
            "      customize AbsoftFCompiler\n",
            "      Could not locate executable f90\n",
            "      customize CompaqVisualFCompiler\n",
            "      Could not locate executable DF\n",
            "      customize IntelItaniumVisualFCompiler\n",
            "      Could not locate executable efl\n",
            "      customize Gnu95FCompiler\n",
            "      Could not locate executable gfortran\n",
            "      Could not locate executable f95\n",
            "      customize G95FCompiler\n",
            "      Could not locate executable g95\n",
            "      customize IntelEM64VisualFCompiler\n",
            "      customize IntelEM64TFCompiler\n",
            "      Could not locate executable efort\n",
            "      Could not locate executable efc\n",
            "      customize PGroupFlangCompiler\n",
            "      Could not locate executable flang\n",
            "      don't know how to compile Fortran code on platform 'nt'\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      atlas_3_10_blas_threads_info:\n",
            "      Setting PTATLAS=ATLAS\n",
            "        libraries tatlas not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      atlas_3_10_blas_info:\n",
            "        libraries satlas not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      atlas_blas_threads_info:\n",
            "      Setting PTATLAS=ATLAS\n",
            "        libraries ptf77blas,ptcblas,atlas not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      atlas_blas_info:\n",
            "        libraries f77blas,cblas,atlas not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-f9lw2pj5\\numpy_185ca5f50e3e480bbf0a08d7ae434ce5\\numpy\\distutils\\system_info.py:1989: UserWarning:\n",
            "          Optimized (vendor) Blas libraries are not found.\n",
            "          Falls back to netlib Blas library which has worse performance.\n",
            "          A better performance should be easily gained by switching\n",
            "          Blas library.\n",
            "        if self._calc_info(blas):\n",
            "      blas_info:\n",
            "        libraries blas not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-f9lw2pj5\\numpy_185ca5f50e3e480bbf0a08d7ae434ce5\\numpy\\distutils\\system_info.py:1989: UserWarning:\n",
            "          Blas (http://www.netlib.org/blas/) libraries not found.\n",
            "          Directories to search for the libraries can be specified in the\n",
            "          numpy/distutils/site.cfg file (section [blas]) or by setting\n",
            "          the BLAS environment variable.\n",
            "        if self._calc_info(blas):\n",
            "      blas_src_info:\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-f9lw2pj5\\numpy_185ca5f50e3e480bbf0a08d7ae434ce5\\numpy\\distutils\\system_info.py:1989: UserWarning:\n",
            "          Blas (http://www.netlib.org/blas/) sources not found.\n",
            "          Directories to search for the sources can be specified in the\n",
            "          numpy/distutils/site.cfg file (section [blas_src]) or by setting\n",
            "          the BLAS_SRC environment variable.\n",
            "        if self._calc_info(blas):\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      non-existing path in 'numpy\\\\distutils': 'site.cfg'\n",
            "      lapack_opt_info:\n",
            "      lapack_mkl_info:\n",
            "        libraries mkl_rt not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      openblas_lapack_info:\n",
            "        libraries openblas not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      openblas_clapack_info:\n",
            "        libraries openblas,lapack not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      flame_info:\n",
            "        libraries flame not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      atlas_3_10_threads_info:\n",
            "      Setting PTATLAS=ATLAS\n",
            "        libraries lapack_atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\lib\n",
            "        libraries tatlas,tatlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\lib\n",
            "        libraries lapack_atlas not found in C:\\\n",
            "        libraries tatlas,tatlas not found in C:\\\n",
            "        libraries lapack_atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\libs\n",
            "        libraries tatlas,tatlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\libs\n",
            "        libraries lapack_atlas not found in C:\\Users\\user\\anaconda3\\Library\\lib\n",
            "        libraries tatlas,tatlas not found in C:\\Users\\user\\anaconda3\\Library\\lib\n",
            "      <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      atlas_3_10_info:\n",
            "        libraries lapack_atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\lib\n",
            "        libraries satlas,satlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\lib\n",
            "        libraries lapack_atlas not found in C:\\\n",
            "        libraries satlas,satlas not found in C:\\\n",
            "        libraries lapack_atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\libs\n",
            "        libraries satlas,satlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\libs\n",
            "        libraries lapack_atlas not found in C:\\Users\\user\\anaconda3\\Library\\lib\n",
            "        libraries satlas,satlas not found in C:\\Users\\user\\anaconda3\\Library\\lib\n",
            "      <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      atlas_threads_info:\n",
            "      Setting PTATLAS=ATLAS\n",
            "        libraries lapack_atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\lib\n",
            "        libraries ptf77blas,ptcblas,atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\lib\n",
            "        libraries lapack_atlas not found in C:\\\n",
            "        libraries ptf77blas,ptcblas,atlas not found in C:\\\n",
            "        libraries lapack_atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\libs\n",
            "        libraries ptf77blas,ptcblas,atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\libs\n",
            "        libraries lapack_atlas not found in C:\\Users\\user\\anaconda3\\Library\\lib\n",
            "        libraries ptf77blas,ptcblas,atlas not found in C:\\Users\\user\\anaconda3\\Library\\lib\n",
            "      <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      atlas_info:\n",
            "        libraries lapack_atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\lib\n",
            "        libraries f77blas,cblas,atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\lib\n",
            "        libraries lapack_atlas not found in C:\\\n",
            "        libraries f77blas,cblas,atlas not found in C:\\\n",
            "        libraries lapack_atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\libs\n",
            "        libraries f77blas,cblas,atlas not found in C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\libs\n",
            "        libraries lapack_atlas not found in C:\\Users\\user\\anaconda3\\Library\\lib\n",
            "        libraries f77blas,cblas,atlas not found in C:\\Users\\user\\anaconda3\\Library\\lib\n",
            "      <class 'numpy.distutils.system_info.atlas_info'>\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      lapack_info:\n",
            "        libraries lapack not found in ['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\lib', 'C:\\\\', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\\\libs', 'C:\\\\Users\\\\user\\\\anaconda3\\\\Library\\\\lib']\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-f9lw2pj5\\numpy_185ca5f50e3e480bbf0a08d7ae434ce5\\numpy\\distutils\\system_info.py:1849: UserWarning:\n",
            "          Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
            "          Directories to search for the libraries can be specified in the\n",
            "          numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
            "          the LAPACK environment variable.\n",
            "        return getattr(self, '_calc_info_{}'.format(name))()\n",
            "      lapack_src_info:\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-f9lw2pj5\\numpy_185ca5f50e3e480bbf0a08d7ae434ce5\\numpy\\distutils\\system_info.py:1849: UserWarning:\n",
            "          Lapack (http://www.netlib.org/lapack/) sources not found.\n",
            "          Directories to search for the sources can be specified in the\n",
            "          numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
            "          the LAPACK_SRC environment variable.\n",
            "        return getattr(self, '_calc_info_{}'.format(name))()\n",
            "        NOT AVAILABLE\n",
            "      \n",
            "      numpy_linalg_lapack_lite:\n",
            "        FOUND:\n",
            "          language = c\n",
            "          define_macros = [('HAVE_BLAS_ILP64', None), ('BLAS_SYMBOL_SUFFIX', '64_')]\n",
            "      \n",
            "      C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-e618xc_r\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\n",
            "        warnings.warn(msg)\n",
            "      running dist_info\n",
            "      running build_src\n",
            "      build_src\n",
            "      building py_modules sources\n",
            "      creating build\n",
            "      creating build\\src.win-amd64-3.11\n",
            "      creating build\\src.win-amd64-3.11\\numpy\n",
            "      creating build\\src.win-amd64-3.11\\numpy\\distutils\n",
            "      building library \"npymath\" sources\n",
            "      ============================================================================\n",
            "      error: Could not initialize compiler instance: do you have Visual Studio\n",
            "      installed?  If you are trying to build with MinGW, please use \"python setup.py\n",
            "      build -c mingw32\" instead.  If you have Visual Studio installed, check it is\n",
            "      correctly installed, and the right version (VS 2008 for python 2.6, 2.7 and 3.2,\n",
            "      VS 2010 for >= 3.3).\n",
            "      \n",
            "      Original exception was: [WinError 2] 吏\\x80\\xec젙\\xeb맂 \\xed뙆\\xec씪\\xec쓣 李얠쓣 \\xec닔 \\xec뾾\\xec뒿\\xeb땲\\xeb떎, and the Compiler class was MSVCCompiler\n",
            "      ============================================================================\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: metadata-generation-failed\n",
            "\n",
            "× Encountered error while generating package metadata.\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This is an issue with the package mentioned above, not pip.\n",
            "hint: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'autogluon'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogluon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TabularDataset, TabularPredictor\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autogluon'"
          ]
        }
      ],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_data, y_data = data_s.drop(target,axis=1), data_s[target]\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_data, y_data, test_size = .2, random_state = 42)\n",
        "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = TabularDataset(train)\n",
        "test_df = TabularDataset(test)\n",
        "\n",
        "predictor = TabularPredictor(label = target, problem_type = 'regression', eval_metric = 'mse',\n",
        "                             path = './') \n",
        "\n",
        "predictor.fit(train_data = train_df, presets = 'best_quality',\n",
        "              auto_stack = True, fit_weighted_ensemble = True,\n",
        "              num_bag_folds = 10, num_bag_sets = 30, num_stack_levels = 3,\n",
        "              num_gpus = 1, num_cpus = 24, verbosity = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance 확인\n",
        "feature_importance = predictor.feature_importance(train_df)\n",
        "feature_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9MTBHGZdIpV"
      },
      "source": [
        "## 딥러닝 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfDK9XGk7_B1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,InputLayer\n",
        "# from keras.backend import clear_session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfRydP7hdbkW",
        "outputId": "9b0de5f5-c5eb-4f5a-aa28-cc3f8904e524"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26, 124)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_s.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "josFtFHjdvI_",
        "outputId": "2a1f3e38-e724-47d0-b3fd-b731e32ae8b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((20, 123), (6, 123), (20,), (6,))"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x=data_s.drop(target,axis=1)\n",
        "y=data_s[target]\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.2,random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnK6C0Oz7-_o",
        "outputId": "45a09e88-842b-4650-8ed2-6001797350a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 2048)              253952    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 16)                2064      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 20000)             340000    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 20001     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3419729 (13.05 MB)\n",
            "Trainable params: 3419729 (13.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_dl = Sequential()\n",
        "\n",
        "# 입력 레이어\n",
        "model_dl.add(InputLayer(input_shape=(123,)))\n",
        "\n",
        "model_dl.add(Dense(units=2048, activation='relu'))\n",
        "model_dl.add(Dense(units=1024, activation='relu'))\n",
        "model_dl.add(Dense(units=512, activation='relu'))\n",
        "model_dl.add(Dense(units=256, activation='relu'))\n",
        "model_dl.add(Dense(units=128, activation='relu'))\n",
        "model_dl.add(Dense(units=128, activation='relu'))\n",
        "model_dl.add(Dense(units=16, activation='relu'))\n",
        "\n",
        "model_dl.add(Dense(units=20000, activation='relu'))\n",
        "\n",
        "# 출력 레이어\n",
        "model_dl.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model_dl.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model_dl.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTXb5ms07-9h",
        "outputId": "85bac242-56e7-4a5a-e831-09a6c7c1601e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 6088319616155648.0000 - mse: 6088319616155648.0000 - val_loss: 10376474557153280.0000 - val_mse: 10376474557153280.0000\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 6062663092142080.0000 - mse: 6062663092142080.0000 - val_loss: 10356944267116544.0000 - val_mse: 10356944267116544.0000\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 6037204673495040.0000 - mse: 6037204673495040.0000 - val_loss: 10337646979055616.0000 - val_mse: 10337646979055616.0000\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 6011989457371136.0000 - mse: 6011989457371136.0000 - val_loss: 10318490351173632.0000 - val_mse: 10318490351173632.0000\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 5987019054383104.0000 - mse: 5987019054383104.0000 - val_loss: 10299519480627200.0000 - val_mse: 10299519480627200.0000\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 5962273600307200.0000 - mse: 5962273600307200.0000 - val_loss: 10280698933936128.0000 - val_mse: 10280698933936128.0000\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5937774033108992.0000 - mse: 5937774033108992.0000 - val_loss: 10262046964711424.0000 - val_mse: 10262046964711424.0000\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5913466665697280.0000 - mse: 5913466665697280.0000 - val_loss: 10243635513655296.0000 - val_mse: 10243635513655296.0000\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5889406795776000.0000 - mse: 5889406795776000.0000 - val_loss: 10225345395425280.0000 - val_mse: 10225345395425280.0000\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5865552010543104.0000 - mse: 5865552010543104.0000 - val_loss: 10207250698207232.0000 - val_mse: 10207250698207232.0000\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5841936132866048.0000 - mse: 5841936132866048.0000 - val_loss: 10189249416527872.0000 - val_mse: 10189249416527872.0000\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5818538224779264.0000 - mse: 5818538224779264.0000 - val_loss: 10171460735729664.0000 - val_mse: 10171460735729664.0000\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5795353454444544.0000 - mse: 5795353454444544.0000 - val_loss: 10153839558656000.0000 - val_mse: 10153839558656000.0000\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5772367326347264.0000 - mse: 5772367326347264.0000 - val_loss: 10136356894277632.0000 - val_mse: 10136356894277632.0000\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5749600778452992.0000 - mse: 5749600778452992.0000 - val_loss: 10118999857692672.0000 - val_mse: 10118999857692672.0000\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5727049515794432.0000 - mse: 5727049515794432.0000 - val_loss: 10101913404047360.0000 - val_mse: 10101913404047360.0000\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5704712464629760.0000 - mse: 5704712464629760.0000 - val_loss: 10084899964846080.0000 - val_mse: 10084899964846080.0000\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5682573518831616.0000 - mse: 5682573518831616.0000 - val_loss: 10068040070725632.0000 - val_mse: 10068040070725632.0000\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5660640194592768.0000 - mse: 5660640194592768.0000 - val_loss: 10051403514904576.0000 - val_mse: 10051403514904576.0000\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5638908196945920.0000 - mse: 5638908196945920.0000 - val_loss: 10034860374622208.0000 - val_mse: 10034860374622208.0000\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5617372157181952.0000 - mse: 5617372157181952.0000 - val_loss: 10018513729093632.0000 - val_mse: 10018513729093632.0000\n",
            "Epoch 22/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5596049255170048.0000 - mse: 5596049255170048.0000 - val_loss: 10002301301293056.0000 - val_mse: 10002301301293056.0000\n",
            "Epoch 23/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5574911036751872.0000 - mse: 5574911036751872.0000 - val_loss: 9986185510256640.0000 - val_mse: 9986185510256640.0000\n",
            "Epoch 24/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5553954280701952.0000 - mse: 5553954280701952.0000 - val_loss: 9970303794937856.0000 - val_mse: 9970303794937856.0000\n",
            "Epoch 25/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5533217641725952.0000 - mse: 5533217641725952.0000 - val_loss: 9954489725353984.0000 - val_mse: 9954489725353984.0000\n",
            "Epoch 26/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5512649580216320.0000 - mse: 5512649580216320.0000 - val_loss: 9938872150523904.0000 - val_mse: 9938872150523904.0000\n",
            "Epoch 27/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5492291972104192.0000 - mse: 5492291972104192.0000 - val_loss: 9923369466068992.0000 - val_mse: 9923369466068992.0000\n",
            "Epoch 28/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5472102941458432.0000 - mse: 5472102941458432.0000 - val_loss: 9908018179211264.0000 - val_mse: 9908018179211264.0000\n",
            "Epoch 29/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5452111479308288.0000 - mse: 5452111479308288.0000 - val_loss: 9892851575947264.0000 - val_mse: 9892851575947264.0000\n",
            "Epoch 30/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5432296110817280.0000 - mse: 5432296110817280.0000 - val_loss: 9877835296538624.0000 - val_mse: 9877835296538624.0000\n",
            "Epoch 31/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5412662741565440.0000 - mse: 5412662741565440.0000 - val_loss: 9862953234857984.0000 - val_mse: 9862953234857984.0000\n",
            "Epoch 32/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5393204392230912.0000 - mse: 5393204392230912.0000 - val_loss: 9848191432261632.0000 - val_mse: 9848191432261632.0000\n",
            "Epoch 33/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5373924284039168.0000 - mse: 5373924284039168.0000 - val_loss: 9833526266429440.0000 - val_mse: 9833526266429440.0000\n",
            "Epoch 34/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5354828859441152.0000 - mse: 5354828859441152.0000 - val_loss: 9819043636707328.0000 - val_mse: 9819043636707328.0000\n",
            "Epoch 35/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5335913823469568.0000 - mse: 5335913823469568.0000 - val_loss: 9804687708520448.0000 - val_mse: 9804687708520448.0000\n",
            "Epoch 36/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5317168438706176.0000 - mse: 5317168438706176.0000 - val_loss: 9790404794777600.0000 - val_mse: 9790404794777600.0000\n",
            "Epoch 37/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5298586262700032.0000 - mse: 5298586262700032.0000 - val_loss: 9776319449530368.0000 - val_mse: 9776319449530368.0000\n",
            "Epoch 38/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5280167295451136.0000 - mse: 5280167295451136.0000 - val_loss: 9762366174527488.0000 - val_mse: 9762366174527488.0000\n",
            "Epoch 39/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5261924958732288.0000 - mse: 5261924958732288.0000 - val_loss: 9748536379834368.0000 - val_mse: 9748536379834368.0000\n",
            "Epoch 40/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5243855494447104.0000 - mse: 5243855494447104.0000 - val_loss: 9734883752542208.0000 - val_mse: 9734883752542208.0000\n",
            "Epoch 41/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5225932059049984.0000 - mse: 5225932059049984.0000 - val_loss: 9721352458076160.0000 - val_mse: 9721352458076160.0000\n",
            "Epoch 42/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5208192233504768.0000 - mse: 5208192233504768.0000 - val_loss: 9707907062956032.0000 - val_mse: 9707907062956032.0000\n",
            "Epoch 43/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5190586088816640.0000 - mse: 5190586088816640.0000 - val_loss: 9694581926920192.0000 - val_mse: 9694581926920192.0000\n",
            "Epoch 44/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5173166775205888.0000 - mse: 5173166775205888.0000 - val_loss: 9681408188481536.0000 - val_mse: 9681408188481536.0000\n",
            "Epoch 45/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5155894564225024.0000 - mse: 5155894564225024.0000 - val_loss: 9668316054421504.0000 - val_mse: 9668316054421504.0000\n",
            "Epoch 46/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5138779119550464.0000 - mse: 5138779119550464.0000 - val_loss: 9655390350344192.0000 - val_mse: 9655390350344192.0000\n",
            "Epoch 47/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5121818830569472.0000 - mse: 5121818830569472.0000 - val_loss: 9642541955678208.0000 - val_mse: 9642541955678208.0000\n",
            "Epoch 48/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5105002959863808.0000 - mse: 5105002959863808.0000 - val_loss: 9629873949638656.0000 - val_mse: 9629873949638656.0000\n",
            "Epoch 49/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5088357814108160.0000 - mse: 5088357814108160.0000 - val_loss: 9617288621719552.0000 - val_mse: 9617288621719552.0000\n",
            "Epoch 50/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5071833464307712.0000 - mse: 5071833464307712.0000 - val_loss: 9604797783080960.0000 - val_mse: 9604797783080960.0000\n",
            "Epoch 51/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5055485745037312.0000 - mse: 5055485745037312.0000 - val_loss: 9592466931974144.0000 - val_mse: 9592466931974144.0000\n",
            "Epoch 52/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5039273854107648.0000 - mse: 5039273854107648.0000 - val_loss: 9580245602533376.0000 - val_mse: 9580245602533376.0000\n",
            "Epoch 53/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5023201549615104.0000 - mse: 5023201549615104.0000 - val_loss: 9568101582503936.0000 - val_mse: 9568101582503936.0000\n",
            "Epoch 54/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5007270979043328.0000 - mse: 5007270979043328.0000 - val_loss: 9556176605806592.0000 - val_mse: 9556176605806592.0000\n",
            "Epoch 55/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4991490732326912.0000 - mse: 4991490732326912.0000 - val_loss: 9544310684909568.0000 - val_mse: 9544310684909568.0000\n",
            "Epoch 56/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4975859198853120.0000 - mse: 4975859198853120.0000 - val_loss: 9532524220907520.0000 - val_mse: 9532524220907520.0000\n",
            "Epoch 57/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4960356514398208.0000 - mse: 4960356514398208.0000 - val_loss: 9520858015989760.0000 - val_mse: 9520858015989760.0000\n",
            "Epoch 58/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4944979457736704.0000 - mse: 4944979457736704.0000 - val_loss: 9509318512607232.0000 - val_mse: 9509318512607232.0000\n",
            "Epoch 59/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4929752188059648.0000 - mse: 4929752188059648.0000 - val_loss: 9497835917541376.0000 - val_mse: 9497835917541376.0000\n",
            "Epoch 60/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4914658062368768.0000 - mse: 4914658062368768.0000 - val_loss: 9486505793814528.0000 - val_mse: 9486505793814528.0000\n",
            "Epoch 61/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4899697080664064.0000 - mse: 4899697080664064.0000 - val_loss: 9475234725888000.0000 - val_mse: 9475234725888000.0000\n",
            "Epoch 62/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4884873001041920.0000 - mse: 4884873001041920.0000 - val_loss: 9464109686849536.0000 - val_mse: 9464109686849536.0000\n",
            "Epoch 63/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4870163274924032.0000 - mse: 4870163274924032.0000 - val_loss: 9453036187418624.0000 - val_mse: 9453036187418624.0000\n",
            "Epoch 64/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4855590450888704.0000 - mse: 4855590450888704.0000 - val_loss: 9442118380552192.0000 - val_mse: 9442118380552192.0000\n",
            "Epoch 65/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4841155602677760.0000 - mse: 4841155602677760.0000 - val_loss: 9431304726642688.0000 - val_mse: 9431304726642688.0000\n",
            "Epoch 66/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4826839939809280.0000 - mse: 4826839939809280.0000 - val_loss: 9420597373173760.0000 - val_mse: 9420597373173760.0000\n",
            "Epoch 67/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4812647220379648.0000 - mse: 4812647220379648.0000 - val_loss: 9409989877694464.0000 - val_mse: 9409989877694464.0000\n",
            "Epoch 68/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4798575296905216.0000 - mse: 4798575296905216.0000 - val_loss: 9399488682655744.0000 - val_mse: 9399488682655744.0000\n",
            "Epoch 69/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4784623632515072.0000 - mse: 4784623632515072.0000 - val_loss: 9389016478646272.0000 - val_mse: 9389016478646272.0000\n",
            "Epoch 70/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4770800280272896.0000 - mse: 4770800280272896.0000 - val_loss: 9378663459979264.0000 - val_mse: 9378663459979264.0000\n",
            "Epoch 71/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4757097187115008.0000 - mse: 4757097187115008.0000 - val_loss: 9368409225560064.0000 - val_mse: 9368409225560064.0000\n",
            "Epoch 72/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4743507910590464.0000 - mse: 4743507910590464.0000 - val_loss: 9358217268166656.0000 - val_mse: 9358217268166656.0000\n",
            "Epoch 73/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4730027081990144.0000 - mse: 4730027081990144.0000 - val_loss: 9348141274890240.0000 - val_mse: 9348141274890240.0000\n",
            "Epoch 74/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4716676176150528.0000 - mse: 4716676176150528.0000 - val_loss: 9338151180959744.0000 - val_mse: 9338151180959744.0000\n",
            "Epoch 75/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4703427275784192.0000 - mse: 4703427275784192.0000 - val_loss: 9328274903662592.0000 - val_mse: 9328274903662592.0000\n",
            "Epoch 76/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4690298097631232.0000 - mse: 4690298097631232.0000 - val_loss: 9318495263129600.0000 - val_mse: 9318495263129600.0000\n",
            "Epoch 77/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4677287031078912.0000 - mse: 4677287031078912.0000 - val_loss: 9308829439229952.0000 - val_mse: 9308829439229952.0000\n",
            "Epoch 78/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4664381191225344.0000 - mse: 4664381191225344.0000 - val_loss: 9299208712486912.0000 - val_mse: 9299208712486912.0000\n",
            "Epoch 79/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4651583799296000.0000 - mse: 4651583799296000.0000 - val_loss: 9289656705220608.0000 - val_mse: 9289656705220608.0000\n",
            "Epoch 80/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4638886802227200.0000 - mse: 4638886802227200.0000 - val_loss: 9280228178264064.0000 - val_mse: 9280228178264064.0000\n",
            "Epoch 81/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4626310064242688.0000 - mse: 4626310064242688.0000 - val_loss: 9270866223300608.0000 - val_mse: 9270866223300608.0000\n",
            "Epoch 82/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4613833721118720.0000 - mse: 4613833721118720.0000 - val_loss: 9261549365493760.0000 - val_mse: 9261549365493760.0000\n",
            "Epoch 83/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4601446498566144.0000 - mse: 4601446498566144.0000 - val_loss: 9252347398062080.0000 - val_mse: 9252347398062080.0000\n",
            "Epoch 84/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4589181145710592.0000 - mse: 4589181145710592.0000 - val_loss: 9243219518816256.0000 - val_mse: 9243219518816256.0000\n",
            "Epoch 85/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4577014577102848.0000 - mse: 4577014577102848.0000 - val_loss: 9234144252919808.0000 - val_mse: 9234144252919808.0000\n",
            "Epoch 86/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4564953235193856.0000 - mse: 4564953235193856.0000 - val_loss: 9225184951140352.0000 - val_mse: 9225184951140352.0000\n",
            "Epoch 87/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4552989603790848.0000 - mse: 4552989603790848.0000 - val_loss: 9216304032514048.0000 - val_mse: 9216304032514048.0000\n",
            "Epoch 88/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4541104355540992.0000 - mse: 4541104355540992.0000 - val_loss: 9207527266844672.0000 - val_mse: 9207527266844672.0000\n",
            "Epoch 89/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4529343124471808.0000 - mse: 4529343124471808.0000 - val_loss: 9198790229622784.0000 - val_mse: 9198790229622784.0000\n",
            "Epoch 90/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4517666719006720.0000 - mse: 4517666719006720.0000 - val_loss: 9190147681681408.0000 - val_mse: 9190147681681408.0000\n",
            "Epoch 91/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4506085339693056.0000 - mse: 4506085339693056.0000 - val_loss: 9181576000700416.0000 - val_mse: 9181576000700416.0000\n",
            "Epoch 92/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4494599523401728.0000 - mse: 4494599523401728.0000 - val_loss: 9173055859326976.0000 - val_mse: 9173055859326976.0000\n",
            "Epoch 93/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4483208733261824.0000 - mse: 4483208733261824.0000 - val_loss: 9164597994979328.0000 - val_mse: 9164597994979328.0000\n",
            "Epoch 94/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4471905453080576.0000 - mse: 4471905453080576.0000 - val_loss: 9156162679209984.0000 - val_mse: 9156162679209984.0000\n",
            "Epoch 95/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4460689414422528.0000 - mse: 4460689414422528.0000 - val_loss: 9147875539812352.0000 - val_mse: 9147875539812352.0000\n",
            "Epoch 96/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4449575918108672.0000 - mse: 4449575918108672.0000 - val_loss: 9139595916607488.0000 - val_mse: 9139595916607488.0000\n",
            "Epoch 97/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4438551810801664.0000 - mse: 4438551810801664.0000 - val_loss: 9131447289905152.0000 - val_mse: 9131447289905152.0000\n",
            "Epoch 98/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4427596422971392.0000 - mse: 4427596422971392.0000 - val_loss: 9123375972614144.0000 - val_mse: 9123375972614144.0000\n",
            "Epoch 99/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4416746261839872.0000 - mse: 4416746261839872.0000 - val_loss: 9115360489897984.0000 - val_mse: 9115360489897984.0000\n",
            "Epoch 100/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4405973678555136.0000 - mse: 4405973678555136.0000 - val_loss: 9107381514403840.0000 - val_mse: 9107381514403840.0000\n",
            "Epoch 101/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4395285652439040.0000 - mse: 4395285652439040.0000 - val_loss: 9099488438255616.0000 - val_mse: 9099488438255616.0000\n",
            "Epoch 102/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4384694263087104.0000 - mse: 4384694263087104.0000 - val_loss: 9091652270424064.0000 - val_mse: 9091652270424064.0000\n",
            "Epoch 103/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4374160587358208.0000 - mse: 4374160587358208.0000 - val_loss: 9083888043294720.0000 - val_mse: 9083888043294720.0000\n",
            "Epoch 104/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4363727038054400.0000 - mse: 4363727038054400.0000 - val_loss: 9076188240674816.0000 - val_mse: 9076188240674816.0000\n",
            "Epoch 105/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4353382340886528.0000 - mse: 4353382340886528.0000 - val_loss: 9068510986633216.0000 - val_mse: 9068510986633216.0000\n",
            "Epoch 106/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4343096699518976.0000 - mse: 4343096699518976.0000 - val_loss: 9060898157101056.0000 - val_mse: 9060898157101056.0000\n",
            "Epoch 107/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4332896689061888.0000 - mse: 4332896689061888.0000 - val_loss: 9053347604594688.0000 - val_mse: 9053347604594688.0000\n",
            "Epoch 108/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4322785262305280.0000 - mse: 4322785262305280.0000 - val_loss: 9045888320143360.0000 - val_mse: 9045888320143360.0000\n",
            "Epoch 109/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4312746849992704.0000 - mse: 4312746849992704.0000 - val_loss: 9038478427815936.0000 - val_mse: 9038478427815936.0000\n",
            "Epoch 110/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4302769909399552.0000 - mse: 4302769909399552.0000 - val_loss: 9031114706386944.0000 - val_mse: 9031114706386944.0000\n",
            "Epoch 111/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4292890142441472.0000 - mse: 4292890142441472.0000 - val_loss: 9023836884303872.0000 - val_mse: 9023836884303872.0000\n",
            "Epoch 112/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4283068625977344.0000 - mse: 4283068625977344.0000 - val_loss: 9016559062220800.0000 - val_mse: 9016559062220800.0000\n",
            "Epoch 113/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4273328445456384.0000 - mse: 4273328445456384.0000 - val_loss: 9009371434450944.0000 - val_mse: 9009371434450944.0000\n",
            "Epoch 114/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4263656179105792.0000 - mse: 4263656179105792.0000 - val_loss: 9002234809417728.0000 - val_mse: 9002234809417728.0000\n",
            "Epoch 115/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4254055585021952.0000 - mse: 4254055585021952.0000 - val_loss: 8995126101671936.0000 - val_mse: 8995126101671936.0000\n",
            "Epoch 116/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4244520757624832.0000 - mse: 4244520757624832.0000 - val_loss: 8988067859791872.0000 - val_mse: 8988067859791872.0000\n",
            "Epoch 117/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4235072366444544.0000 - mse: 4235072366444544.0000 - val_loss: 8981074579292160.0000 - val_mse: 8981074579292160.0000\n",
            "Epoch 118/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4225681688887296.0000 - mse: 4225681688887296.0000 - val_loss: 8974140354592768.0000 - val_mse: 8974140354592768.0000\n",
            "Epoch 119/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4216359462371328.0000 - mse: 4216359462371328.0000 - val_loss: 8967243173986304.0000 - val_mse: 8967243173986304.0000\n",
            "Epoch 120/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4207112934653952.0000 - mse: 4207112934653952.0000 - val_loss: 8960467863076864.0000 - val_mse: 8960467863076864.0000\n",
            "Epoch 121/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4197931099881472.0000 - mse: 4197931099881472.0000 - val_loss: 8953623832690688.0000 - val_mse: 8953623832690688.0000\n",
            "Epoch 122/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4188799194103808.0000 - mse: 4188799194103808.0000 - val_loss: 8946940863578112.0000 - val_mse: 8946940863578112.0000\n",
            "Epoch 123/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4179753187672064.0000 - mse: 4179753187672064.0000 - val_loss: 8940230514049024.0000 - val_mse: 8940230514049024.0000\n",
            "Epoch 124/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4170769726701568.0000 - mse: 4170769726701568.0000 - val_loss: 8933613043187712.0000 - val_mse: 8933613043187712.0000\n",
            "Epoch 125/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4161835657854976.0000 - mse: 4161835657854976.0000 - val_loss: 8926974097489920.0000 - val_mse: 8926974097489920.0000\n",
            "Epoch 126/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4152970576920576.0000 - mse: 4152970576920576.0000 - val_loss: 8920447894683648.0000 - val_mse: 8920447894683648.0000\n",
            "Epoch 127/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4144178778865664.0000 - mse: 4144178778865664.0000 - val_loss: 8913889479622656.0000 - val_mse: 8913889479622656.0000\n",
            "Epoch 128/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4135430735790080.0000 - mse: 4135430735790080.0000 - val_loss: 8907441659969536.0000 - val_mse: 8907441659969536.0000\n",
            "Epoch 129/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4126759733690368.0000 - mse: 4126759733690368.0000 - val_loss: 8901051822374912.0000 - val_mse: 8901051822374912.0000\n",
            "Epoch 130/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4118130070650880.0000 - mse: 4118130070650880.0000 - val_loss: 8894648026136576.0000 - val_mse: 8894648026136576.0000\n",
            "Epoch 131/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 4109572348313600.0000 - mse: 4109572348313600.0000 - val_loss: 8888321002438656.0000 - val_mse: 8888321002438656.0000\n",
            "Epoch 132/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4101073144905728.0000 - mse: 4101073144905728.0000 - val_loss: 8881973577646080.0000 - val_mse: 8881973577646080.0000\n",
            "Epoch 133/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4092620112396288.0000 - mse: 4092620112396288.0000 - val_loss: 8875723863359488.0000 - val_mse: 8875723863359488.0000\n",
            "Epoch 134/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4084233920315392.0000 - mse: 4084233920315392.0000 - val_loss: 8869502066360320.0000 - val_mse: 8869502066360320.0000\n",
            "Epoch 135/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 4075912421179392.0000 - mse: 4075912421179392.0000 - val_loss: 8863300670455808.0000 - val_mse: 8863300670455808.0000\n",
            "Epoch 136/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4067626892394496.0000 - mse: 4067626892394496.0000 - val_loss: 8857152424771584.0000 - val_mse: 8857152424771584.0000\n",
            "Epoch 137/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4059405519683584.0000 - mse: 4059405519683584.0000 - val_loss: 8851047665631232.0000 - val_mse: 8851047665631232.0000\n",
            "Epoch 138/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4051242934337536.0000 - mse: 4051242934337536.0000 - val_loss: 8844984245551104.0000 - val_mse: 8844984245551104.0000\n",
            "Epoch 139/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4043137525743616.0000 - mse: 4043137525743616.0000 - val_loss: 8838960553918464.0000 - val_mse: 8838960553918464.0000\n",
            "Epoch 140/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4035069698113536.0000 - mse: 4035069698113536.0000 - val_loss: 8833002360537088.0000 - val_mse: 8833002360537088.0000\n",
            "Epoch 141/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4027062805331968.0000 - mse: 4027062805331968.0000 - val_loss: 8827049535864832.0000 - val_mse: 8827049535864832.0000\n",
            "Epoch 142/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 4019098593787904.0000 - mse: 4019098593787904.0000 - val_loss: 8821123554738176.0000 - val_mse: 8821123554738176.0000\n",
            "Epoch 143/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4011196122398720.0000 - mse: 4011196122398720.0000 - val_loss: 8815211532255232.0000 - val_mse: 8815211532255232.0000\n",
            "Epoch 144/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4003345459052544.0000 - mse: 4003345459052544.0000 - val_loss: 8809334943252480.0000 - val_mse: 8809334943252480.0000\n",
            "Epoch 145/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3995528081702912.0000 - mse: 3995528081702912.0000 - val_loss: 8803479829086208.0000 - val_mse: 8803479829086208.0000\n",
            "Epoch 146/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3987785329410048.0000 - mse: 3987785329410048.0000 - val_loss: 8797661222141952.0000 - val_mse: 8797661222141952.0000\n",
            "Epoch 147/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3980074520936448.0000 - mse: 3980074520936448.0000 - val_loss: 8791923145834496.0000 - val_mse: 8791923145834496.0000\n",
            "Epoch 148/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3972412567715840.0000 - mse: 3972412567715840.0000 - val_loss: 8786221576749056.0000 - val_mse: 8786221576749056.0000\n",
            "Epoch 149/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3964794369474560.0000 - mse: 3964794369474560.0000 - val_loss: 8780498532827136.0000 - val_mse: 8780498532827136.0000\n",
            "Epoch 150/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3957230932066304.0000 - mse: 3957230932066304.0000 - val_loss: 8774868904443904.0000 - val_mse: 8774868904443904.0000\n",
            "Epoch 151/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3949715007733760.0000 - mse: 3949715007733760.0000 - val_loss: 8769251624091648.0000 - val_mse: 8769251624091648.0000\n",
            "Epoch 152/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3942238274977792.0000 - mse: 3942238274977792.0000 - val_loss: 8763631659384832.0000 - val_mse: 8763631659384832.0000\n",
            "Epoch 153/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3934808518426624.0000 - mse: 3934808518426624.0000 - val_loss: 8758054107480064.0000 - val_mse: 8758054107480064.0000\n",
            "Epoch 154/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3927422785290240.0000 - mse: 3927422785290240.0000 - val_loss: 8752483534897152.0000 - val_mse: 8752483534897152.0000\n",
            "Epoch 155/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3920082686181376.0000 - mse: 3920082686181376.0000 - val_loss: 8747023557722112.0000 - val_mse: 8747023557722112.0000\n",
            "Epoch 156/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 3912784731439104.0000 - mse: 3912784731439104.0000 - val_loss: 8741516335906816.0000 - val_mse: 8741516335906816.0000\n",
            "Epoch 157/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3905537779433472.0000 - mse: 3905537779433472.0000 - val_loss: 8736033810153472.0000 - val_mse: 8736033810153472.0000\n",
            "Epoch 158/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3898307738861568.0000 - mse: 3898307738861568.0000 - val_loss: 8730584570396672.0000 - val_mse: 8730584570396672.0000\n",
            "Epoch 159/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3891147223072768.0000 - mse: 3891147223072768.0000 - val_loss: 8725158952960000.0000 - val_mse: 8725158952960000.0000\n",
            "Epoch 160/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3884014893006848.0000 - mse: 3884014893006848.0000 - val_loss: 8719764474036224.0000 - val_mse: 8719764474036224.0000\n",
            "Epoch 161/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3876923633565696.0000 - mse: 3876923633565696.0000 - val_loss: 8714392006819840.0000 - val_mse: 8714392006819840.0000\n",
            "Epoch 162/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3869875055362048.0000 - mse: 3869875055362048.0000 - val_loss: 8709124229431296.0000 - val_mse: 8709124229431296.0000\n",
            "Epoch 163/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3862860031590400.0000 - mse: 3862860031590400.0000 - val_loss: 8703795785629696.0000 - val_mse: 8703795785629696.0000\n",
            "Epoch 164/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3855896278990848.0000 - mse: 3855896278990848.0000 - val_loss: 8698503312179200.0000 - val_mse: 8698503312179200.0000\n",
            "Epoch 165/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3848965543952384.0000 - mse: 3848965543952384.0000 - val_loss: 8693234997919744.0000 - val_mse: 8693234997919744.0000\n",
            "Epoch 166/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3842062994636800.0000 - mse: 3842062994636800.0000 - val_loss: 8688053119877120.0000 - val_mse: 8688053119877120.0000\n",
            "Epoch 167/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3835211716493312.0000 - mse: 3835211716493312.0000 - val_loss: 8682778900037632.0000 - val_mse: 8682778900037632.0000\n",
            "Epoch 168/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3828397214007296.0000 - mse: 3828397214007296.0000 - val_loss: 8677590579544064.0000 - val_mse: 8677590579544064.0000\n",
            "Epoch 169/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3821609823502336.0000 - mse: 3821609823502336.0000 - val_loss: 8672378636730368.0000 - val_mse: 8672378636730368.0000\n",
            "Epoch 170/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3814868067024896.0000 - mse: 3814868067024896.0000 - val_loss: 8667242392715264.0000 - val_mse: 8667242392715264.0000\n",
            "Epoch 171/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3808161207156736.0000 - mse: 3808161207156736.0000 - val_loss: 8662132992245760.0000 - val_mse: 8662132992245760.0000\n",
            "Epoch 172/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3801483606753280.0000 - mse: 3801483606753280.0000 - val_loss: 8657039161032704.0000 - val_mse: 8657039161032704.0000\n",
            "Epoch 173/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3794847076974592.0000 - mse: 3794847076974592.0000 - val_loss: 8651934055530496.0000 - val_mse: 8651934055530496.0000\n",
            "Epoch 174/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3788236316999680.0000 - mse: 3788236316999680.0000 - val_loss: 8646886395215872.0000 - val_mse: 8646886395215872.0000\n",
            "Epoch 175/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 3781662332682240.0000 - mse: 3781662332682240.0000 - val_loss: 8641850009190400.0000 - val_mse: 8641850009190400.0000\n",
            "Epoch 176/2000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 3775129418989568.0000 - mse: 3775129418989568.0000 - val_loss: 8636764231041024.0000 - val_mse: 8636764231041024.0000\n",
            "Epoch 177/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3768624691019776.0000 - mse: 3768624691019776.0000 - val_loss: 8631760594141184.0000 - val_mse: 8631760594141184.0000\n",
            "Epoch 178/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3762156738707456.0000 - mse: 3762156738707456.0000 - val_loss: 8626750514790400.0000 - val_mse: 8626750514790400.0000\n",
            "Epoch 179/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3755708382183424.0000 - mse: 3755708382183424.0000 - val_loss: 8621771037081600.0000 - val_mse: 8621771037081600.0000\n",
            "Epoch 180/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3749304049074176.0000 - mse: 3749304049074176.0000 - val_loss: 8616813034209280.0000 - val_mse: 8616813034209280.0000\n",
            "Epoch 181/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3742924948897792.0000 - mse: 3742924948897792.0000 - val_loss: 8611921066459136.0000 - val_mse: 8611921066459136.0000\n",
            "Epoch 182/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3736588529958912.0000 - mse: 3736588529958912.0000 - val_loss: 8607008697614336.0000 - val_mse: 8607008697614336.0000\n",
            "Epoch 183/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3730285933887488.0000 - mse: 3730285933887488.0000 - val_loss: 8602101697478656.0000 - val_mse: 8602101697478656.0000\n",
            "Epoch 184/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3723993806798848.0000 - mse: 3723993806798848.0000 - val_loss: 8597265564303360.0000 - val_mse: 8597265564303360.0000\n",
            "Epoch 185/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3717741676593152.0000 - mse: 3717741676593152.0000 - val_loss: 8592361248522240.0000 - val_mse: 8592361248522240.0000\n",
            "Epoch 186/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3711519611158528.0000 - mse: 3711519611158528.0000 - val_loss: 8587483776286720.0000 - val_mse: 8587483776286720.0000\n",
            "Epoch 187/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3705306940964864.0000 - mse: 3705306940964864.0000 - val_loss: 8582686297817088.0000 - val_mse: 8582686297817088.0000\n",
            "Epoch 188/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3699153595006976.0000 - mse: 3699153595006976.0000 - val_loss: 8577842648449024.0000 - val_mse: 8577842648449024.0000\n",
            "Epoch 189/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3693027629465600.0000 - mse: 3693027629465600.0000 - val_loss: 8572990946017280.0000 - val_mse: 8572990946017280.0000\n",
            "Epoch 190/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3686910253858816.0000 - mse: 3686910253858816.0000 - val_loss: 8568199373127680.0000 - val_mse: 8568199373127680.0000\n",
            "Epoch 191/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3680821332410368.0000 - mse: 3680821332410368.0000 - val_loss: 8563415853301760.0000 - val_mse: 8563415853301760.0000\n",
            "Epoch 192/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3674771870973952.0000 - mse: 3674771870973952.0000 - val_loss: 8558667230085120.0000 - val_mse: 8558667230085120.0000\n",
            "Epoch 193/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3668747374034944.0000 - mse: 3668747374034944.0000 - val_loss: 8553964777766912.0000 - val_mse: 8553964777766912.0000\n",
            "Epoch 194/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3662747573157888.0000 - mse: 3662747573157888.0000 - val_loss: 8549243534966784.0000 - val_mse: 8549243534966784.0000\n",
            "Epoch 195/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3656773810520064.0000 - mse: 3656773810520064.0000 - val_loss: 8544525513392128.0000 - val_mse: 8544525513392128.0000\n",
            "Epoch 196/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3650834407620608.0000 - mse: 3650834407620608.0000 - val_loss: 8539827892912128.0000 - val_mse: 8539827892912128.0000\n",
            "Epoch 197/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3644904668397568.0000 - mse: 3644904668397568.0000 - val_loss: 8535129198690304.0000 - val_mse: 8535129198690304.0000\n",
            "Epoch 198/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3639010631090176.0000 - mse: 3639010631090176.0000 - val_loss: 8530406882148352.0000 - val_mse: 8530406882148352.0000\n",
            "Epoch 199/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3633140752973824.0000 - mse: 3633140752973824.0000 - val_loss: 8525704966701056.0000 - val_mse: 8525704966701056.0000\n",
            "Epoch 200/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3627301744934912.0000 - mse: 3627301744934912.0000 - val_loss: 8521096466792448.0000 - val_mse: 8521096466792448.0000\n",
            "Epoch 201/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3621471326830592.0000 - mse: 3621471326830592.0000 - val_loss: 8516443406598144.0000 - val_mse: 8516443406598144.0000\n",
            "Epoch 202/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3615681710915584.0000 - mse: 3615681710915584.0000 - val_loss: 8511802157563904.0000 - val_mse: 8511802157563904.0000\n",
            "Epoch 203/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3609908737998848.0000 - mse: 3609908737998848.0000 - val_loss: 8507155539820544.0000 - val_mse: 8507155539820544.0000\n",
            "Epoch 204/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3604161266450432.0000 - mse: 3604161266450432.0000 - val_loss: 8502589989584896.0000 - val_mse: 8502589989584896.0000\n",
            "Epoch 205/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3598428290416640.0000 - mse: 3598428290416640.0000 - val_loss: 8497977731579904.0000 - val_mse: 8497977731579904.0000\n",
            "Epoch 206/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3592725379153920.0000 - mse: 3592725379153920.0000 - val_loss: 8493428824342528.0000 - val_mse: 8493428824342528.0000\n",
            "Epoch 207/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3587054948581376.0000 - mse: 3587054948581376.0000 - val_loss: 8488869716557824.0000 - val_mse: 8488869716557824.0000\n",
            "Epoch 208/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 3581394450120704.0000 - mse: 3581394450120704.0000 - val_loss: 8484305776934912.0000 - val_mse: 8484305776934912.0000\n",
            "Epoch 209/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3575759453028352.0000 - mse: 3575759453028352.0000 - val_loss: 8479731636764672.0000 - val_mse: 8479731636764672.0000\n",
            "Epoch 210/2000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 3570144588595200.0000 - mse: 3570144588595200.0000 - val_loss: 8475145685434368.0000 - val_mse: 8475145685434368.0000\n",
            "Epoch 211/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3564549319950336.0000 - mse: 3564549319950336.0000 - val_loss: 8470589798875136.0000 - val_mse: 8470589798875136.0000\n",
            "Epoch 212/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3558980894851072.0000 - mse: 3558980894851072.0000 - val_loss: 8466089210019840.0000 - val_mse: 8466089210019840.0000\n",
            "Epoch 213/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3553427770572800.0000 - mse: 3553427770572800.0000 - val_loss: 8461589694906368.0000 - val_mse: 8461589694906368.0000\n",
            "Epoch 214/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3547901489840128.0000 - mse: 3547901489840128.0000 - val_loss: 8457061188763648.0000 - val_mse: 8457061188763648.0000\n",
            "Epoch 215/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3542394536460288.0000 - mse: 3542394536460288.0000 - val_loss: 8452614286999552.0000 - val_mse: 8452614286999552.0000\n",
            "Epoch 216/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 3536910936965120.0000 - mse: 3536910936965120.0000 - val_loss: 8448127119917056.0000 - val_mse: 8448127119917056.0000\n",
            "Epoch 217/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3531443175161856.0000 - mse: 3531443175161856.0000 - val_loss: 8443650690252800.0000 - val_mse: 8443650690252800.0000\n",
            "Epoch 218/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3525993398534144.0000 - mse: 3525993398534144.0000 - val_loss: 8439222042099712.0000 - val_mse: 8439222042099712.0000\n",
            "Epoch 219/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3520568854839296.0000 - mse: 3520568854839296.0000 - val_loss: 8434753665499136.0000 - val_mse: 8434753665499136.0000\n",
            "Epoch 220/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3515154780127232.0000 - mse: 3515154780127232.0000 - val_loss: 8430318038024192.0000 - val_mse: 8430318038024192.0000\n",
            "Epoch 221/2000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 3509757616848896.0000 - mse: 3509757616848896.0000 - val_loss: 8425853956390912.0000 - val_mse: 8425853956390912.0000\n",
            "Epoch 222/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 3504390518341632.0000 - mse: 3504390518341632.0000 - val_loss: 8421387190403072.0000 - val_mse: 8421387190403072.0000\n",
            "Epoch 223/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3499045968412672.0000 - mse: 3499045968412672.0000 - val_loss: 8416941362380800.0000 - val_mse: 8416941362380800.0000\n",
            "Epoch 224/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3493716182433792.0000 - mse: 3493716182433792.0000 - val_loss: 8412522377904128.0000 - val_mse: 8412522377904128.0000\n",
            "Epoch 225/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3488396865437696.0000 - mse: 3488396865437696.0000 - val_loss: 8408138826907648.0000 - val_mse: 8408138826907648.0000\n",
            "Epoch 226/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3483099560148992.0000 - mse: 3483099560148992.0000 - val_loss: 8403733264203776.0000 - val_mse: 8403733264203776.0000\n",
            "Epoch 227/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 3477822387519488.0000 - mse: 3477822387519488.0000 - val_loss: 8399328238370816.0000 - val_mse: 8399328238370816.0000\n",
            "Epoch 228/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3472555683872768.0000 - mse: 3472555683872768.0000 - val_loss: 8394964551598080.0000 - val_mse: 8394964551598080.0000\n",
            "Epoch 229/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 3467312602546176.0000 - mse: 3467312602546176.0000 - val_loss: 8390572410667008.0000 - val_mse: 8390572410667008.0000\n",
            "Epoch 230/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3462089117007872.0000 - mse: 3462089117007872.0000 - val_loss: 8386237178052608.0000 - val_mse: 8386237178052608.0000\n",
            "Epoch 231/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3456876637323264.0000 - mse: 3456876637323264.0000 - val_loss: 8381813361737728.0000 - val_mse: 8381813361737728.0000\n",
            "Epoch 232/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3451687779958784.0000 - mse: 3451687779958784.0000 - val_loss: 8377448064352256.0000 - val_mse: 8377448064352256.0000\n",
            "Epoch 233/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3446504559738880.0000 - mse: 3446504559738880.0000 - val_loss: 8373081693224960.0000 - val_mse: 8373081693224960.0000\n",
            "Epoch 234/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3441339056259072.0000 - mse: 3441339056259072.0000 - val_loss: 8368716395839488.0000 - val_mse: 8368716395839488.0000\n",
            "Epoch 235/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3436192343261184.0000 - mse: 3436192343261184.0000 - val_loss: 8364409617383424.0000 - val_mse: 8364409617383424.0000\n",
            "Epoch 236/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3431067373535232.0000 - mse: 3431067373535232.0000 - val_loss: 8360049151836160.0000 - val_mse: 8360049151836160.0000\n",
            "Epoch 237/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3425955288711168.0000 - mse: 3425955288711168.0000 - val_loss: 8355778880602112.0000 - val_mse: 8355778880602112.0000\n",
            "Epoch 238/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3420857162530816.0000 - mse: 3420857162530816.0000 - val_loss: 8351462438469632.0000 - val_mse: 8351462438469632.0000\n",
            "Epoch 239/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3415771652816896.0000 - mse: 3415771652816896.0000 - val_loss: 8347150828175360.0000 - val_mse: 8347150828175360.0000\n",
            "Epoch 240/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3410709228552192.0000 - mse: 3410709228552192.0000 - val_loss: 8342860692717568.0000 - val_mse: 8342860692717568.0000\n",
            "Epoch 241/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3405652709867520.0000 - mse: 3405652709867520.0000 - val_loss: 8338522238877696.0000 - val_mse: 8338522238877696.0000\n",
            "Epoch 242/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3400621960986624.0000 - mse: 3400621960986624.0000 - val_loss: 8334205259874304.0000 - val_mse: 8334205259874304.0000\n",
            "Epoch 243/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3395596312379392.0000 - mse: 3395596312379392.0000 - val_loss: 8329962905927680.0000 - val_mse: 8329962905927680.0000\n",
            "Epoch 244/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3390579790577664.0000 - mse: 3390579790577664.0000 - val_loss: 8325599219154944.0000 - val_mse: 8325599219154944.0000\n",
            "Epoch 245/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3385587696402432.0000 - mse: 3385587696402432.0000 - val_loss: 8321331095404544.0000 - val_mse: 8321331095404544.0000\n",
            "Epoch 246/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3380612245225472.0000 - mse: 3380612245225472.0000 - val_loss: 8317055992332288.0000 - val_mse: 8317055992332288.0000\n",
            "Epoch 247/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3375651557998592.0000 - mse: 3375651557998592.0000 - val_loss: 8312824912674816.0000 - val_mse: 8312824912674816.0000\n",
            "Epoch 248/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3370696776351744.0000 - mse: 3370696776351744.0000 - val_loss: 8308509544284160.0000 - val_mse: 8308509544284160.0000\n",
            "Epoch 249/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3365758100832256.0000 - mse: 3365758100832256.0000 - val_loss: 8304261284757504.0000 - val_mse: 8304261284757504.0000\n",
            "Epoch 250/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3360834994569216.0000 - mse: 3360834994569216.0000 - val_loss: 8300023762649088.0000 - val_mse: 8300023762649088.0000\n",
            "Epoch 251/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3355924236337152.0000 - mse: 3355924236337152.0000 - val_loss: 8295781408702464.0000 - val_mse: 8295781408702464.0000\n",
            "Epoch 252/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3351026631442432.0000 - mse: 3351026631442432.0000 - val_loss: 8291537981014016.0000 - val_mse: 8291537981014016.0000\n",
            "Epoch 253/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3346144058933248.0000 - mse: 3346144058933248.0000 - val_loss: 8287254824878080.0000 - val_mse: 8287254824878080.0000\n",
            "Epoch 254/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3341270613229568.0000 - mse: 3341270613229568.0000 - val_loss: 8283047904411648.0000 - val_mse: 8283047904411648.0000\n",
            "Epoch 255/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3336412736782336.0000 - mse: 3336412736782336.0000 - val_loss: 8278757768953856.0000 - val_mse: 8278757768953856.0000\n",
            "Epoch 256/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3331564255576064.0000 - mse: 3331564255576064.0000 - val_loss: 8274538500456448.0000 - val_mse: 8274538500456448.0000\n",
            "Epoch 257/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3326725974917120.0000 - mse: 3326725974917120.0000 - val_loss: 8270363792244736.0000 - val_mse: 8270363792244736.0000\n",
            "Epoch 258/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3321896821063680.0000 - mse: 3321896821063680.0000 - val_loss: 8266113922105344.0000 - val_mse: 8266113922105344.0000\n",
            "Epoch 259/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3317100147900416.0000 - mse: 3317100147900416.0000 - val_loss: 8261893579866112.0000 - val_mse: 8261893579866112.0000\n",
            "Epoch 260/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3312293542625280.0000 - mse: 3312293542625280.0000 - val_loss: 8257712429203456.0000 - val_mse: 8257712429203456.0000\n",
            "Epoch 261/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3307509754363904.0000 - mse: 3307509754363904.0000 - val_loss: 8253490476351488.0000 - val_mse: 8253490476351488.0000\n",
            "Epoch 262/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3302737508827136.0000 - mse: 3302737508827136.0000 - val_loss: 8249313620656128.0000 - val_mse: 8249313620656128.0000\n",
            "Epoch 263/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3297978148192256.0000 - mse: 3297978148192256.0000 - val_loss: 8245083614740480.0000 - val_mse: 8245083614740480.0000\n",
            "Epoch 264/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3293224156266496.0000 - mse: 3293224156266496.0000 - val_loss: 8240857366921216.0000 - val_mse: 8240857366921216.0000\n",
            "Epoch 265/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3288485196726272.0000 - mse: 3288485196726272.0000 - val_loss: 8236742788251648.0000 - val_mse: 8236742788251648.0000\n",
            "Epoch 266/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3283754290249728.0000 - mse: 3283754290249728.0000 - val_loss: 8232548752687104.0000 - val_mse: 8232548752687104.0000\n",
            "Epoch 267/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3279036537110528.0000 - mse: 3279036537110528.0000 - val_loss: 8228385855635456.0000 - val_mse: 8228385855635456.0000\n",
            "Epoch 268/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3274331400437760.0000 - mse: 3274331400437760.0000 - val_loss: 8224184303878144.0000 - val_mse: 8224184303878144.0000\n",
            "Epoch 269/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3269634585264128.0000 - mse: 3269634585264128.0000 - val_loss: 8219973088444416.0000 - val_mse: 8219973088444416.0000\n",
            "Epoch 270/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3264950654992384.0000 - mse: 3264950654992384.0000 - val_loss: 8215815023230976.0000 - val_mse: 8215815023230976.0000\n",
            "Epoch 271/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3260279341187072.0000 - mse: 3260279341187072.0000 - val_loss: 8211605955280896.0000 - val_mse: 8211605955280896.0000\n",
            "Epoch 272/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3255611517042688.0000 - mse: 3255611517042688.0000 - val_loss: 8207431783940096.0000 - val_mse: 8207431783940096.0000\n",
            "Epoch 273/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3250959530590208.0000 - mse: 3250959530590208.0000 - val_loss: 8203294656692224.0000 - val_mse: 8203294656692224.0000\n",
            "Epoch 274/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3246322576523264.0000 - mse: 3246322576523264.0000 - val_loss: 8199159676928000.0000 - val_mse: 8199159676928000.0000\n",
            "Epoch 275/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3241686427762688.0000 - mse: 3241686427762688.0000 - val_loss: 8195013959745536.0000 - val_mse: 8195013959745536.0000\n",
            "Epoch 276/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3237061284855808.0000 - mse: 3237061284855808.0000 - val_loss: 8190874685014016.0000 - val_mse: 8190874685014016.0000\n",
            "Epoch 277/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3232447416238080.0000 - mse: 3232447416238080.0000 - val_loss: 8186718767284224.0000 - val_mse: 8186718767284224.0000\n",
            "Epoch 278/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3227848043134976.0000 - mse: 3227848043134976.0000 - val_loss: 8182562849554432.0000 - val_mse: 8182562849554432.0000\n",
            "Epoch 279/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 3223250012209152.0000 - mse: 3223250012209152.0000 - val_loss: 8178397805019136.0000 - val_mse: 8178397805019136.0000\n",
            "Epoch 280/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3218667282104320.0000 - mse: 3218667282104320.0000 - val_loss: 8174203232583680.0000 - val_mse: 8174203232583680.0000\n",
            "Epoch 281/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3214097436901376.0000 - mse: 3214097436901376.0000 - val_loss: 8170074158399488.0000 - val_mse: 8170074158399488.0000\n",
            "Epoch 282/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3209530007617536.0000 - mse: 3209530007617536.0000 - val_loss: 8165991791984640.0000 - val_mse: 8165991791984640.0000\n",
            "Epoch 283/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3204971973574656.0000 - mse: 3204971973574656.0000 - val_loss: 8161896540667904.0000 - val_mse: 8161896540667904.0000\n",
            "Epoch 284/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3200430850965504.0000 - mse: 3200430850965504.0000 - val_loss: 8157813100511232.0000 - val_mse: 8157813100511232.0000\n",
            "Epoch 285/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3195892144275456.0000 - mse: 3195892144275456.0000 - val_loss: 8153707648647168.0000 - val_mse: 8153707648647168.0000\n",
            "Epoch 286/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3191361222213632.0000 - mse: 3191361222213632.0000 - val_loss: 8149569447657472.0000 - val_mse: 8149569447657472.0000\n",
            "Epoch 287/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3186849359069184.0000 - mse: 3186849359069184.0000 - val_loss: 8145407087476736.0000 - val_mse: 8145407087476736.0000\n",
            "Epoch 288/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3182337495924736.0000 - mse: 3182337495924736.0000 - val_loss: 8141290361323520.0000 - val_mse: 8141290361323520.0000\n",
            "Epoch 289/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3177838249246720.0000 - mse: 3177838249246720.0000 - val_loss: 8137144107270144.0000 - val_mse: 8137144107270144.0000\n",
            "Epoch 290/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3173342223794176.0000 - mse: 3173342223794176.0000 - val_loss: 8133012348731392.0000 - val_mse: 8133012348731392.0000\n",
            "Epoch 291/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3168858546372608.0000 - mse: 3168858546372608.0000 - val_loss: 8128923002994688.0000 - val_mse: 8128923002994688.0000\n",
            "Epoch 292/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3164385874804736.0000 - mse: 3164385874804736.0000 - val_loss: 8124852447739904.0000 - val_mse: 8124852447739904.0000\n",
            "Epoch 293/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3159920450994176.0000 - mse: 3159920450994176.0000 - val_loss: 8120808199159808.0000 - val_mse: 8120808199159808.0000\n",
            "Epoch 294/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3155460127457280.0000 - mse: 3155460127457280.0000 - val_loss: 8116746770710528.0000 - val_mse: 8116746770710528.0000\n",
            "Epoch 295/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3151014836305920.0000 - mse: 3151014836305920.0000 - val_loss: 8112649371910144.0000 - val_mse: 8112649371910144.0000\n",
            "Epoch 296/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3146564444880896.0000 - mse: 3146564444880896.0000 - val_loss: 8108539088207872.0000 - val_mse: 8108539088207872.0000\n",
            "Epoch 297/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3142134722985984.0000 - mse: 3142134722985984.0000 - val_loss: 8104394444767232.0000 - val_mse: 8104394444767232.0000\n",
            "Epoch 298/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3137702853607424.0000 - mse: 3137702853607424.0000 - val_loss: 8100273960517632.0000 - val_mse: 8100273960517632.0000\n",
            "Epoch 299/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3133285479743488.0000 - mse: 3133285479743488.0000 - val_loss: 8096183541039104.0000 - val_mse: 8096183541039104.0000\n",
            "Epoch 300/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3128886091055104.0000 - mse: 3128886091055104.0000 - val_loss: 8092071109853184.0000 - val_mse: 8092071109853184.0000\n",
            "Epoch 301/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3124482138963968.0000 - mse: 3124482138963968.0000 - val_loss: 8088052631076864.0000 - val_mse: 8088052631076864.0000\n",
            "Epoch 302/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3120081944969216.0000 - mse: 3120081944969216.0000 - val_loss: 8083985297047552.0000 - val_mse: 8083985297047552.0000\n",
            "Epoch 303/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3115701346762752.0000 - mse: 3115701346762752.0000 - val_loss: 8079986145624064.0000 - val_mse: 8079986145624064.0000\n",
            "Epoch 304/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3111320480120832.0000 - mse: 3111320480120832.0000 - val_loss: 8075948876365824.0000 - val_mse: 8075948876365824.0000\n",
            "Epoch 305/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3106946055929856.0000 - mse: 3106946055929856.0000 - val_loss: 8071953483038720.0000 - val_mse: 8071953483038720.0000\n",
            "Epoch 306/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3102585053511680.0000 - mse: 3102585053511680.0000 - val_loss: 8067870579752960.0000 - val_mse: 8067870579752960.0000\n",
            "Epoch 307/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3098224051093504.0000 - mse: 3098224051093504.0000 - val_loss: 8063732915634176.0000 - val_mse: 8063732915634176.0000\n",
            "Epoch 308/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3093879691673600.0000 - mse: 3093879691673600.0000 - val_loss: 8059645180510208.0000 - val_mse: 8059645180510208.0000\n",
            "Epoch 309/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3089538285043712.0000 - mse: 3089538285043712.0000 - val_loss: 8055557445386240.0000 - val_mse: 8055557445386240.0000\n",
            "Epoch 310/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3085196609978368.0000 - mse: 3085196609978368.0000 - val_loss: 8051510512451584.0000 - val_mse: 8051510512451584.0000\n",
            "Epoch 311/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3080875067572224.0000 - mse: 3080875067572224.0000 - val_loss: 8047471095709696.0000 - val_mse: 8047471095709696.0000\n",
            "Epoch 312/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3076548961763328.0000 - mse: 3076548961763328.0000 - val_loss: 8043490734768128.0000 - val_mse: 8043490734768128.0000\n",
            "Epoch 313/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3072239230517248.0000 - mse: 3072239230517248.0000 - val_loss: 8039466350411776.0000 - val_mse: 8039466350411776.0000\n",
            "Epoch 314/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3067932452061184.0000 - mse: 3067932452061184.0000 - val_loss: 8035441429184512.0000 - val_mse: 8035441429184512.0000\n",
            "Epoch 315/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3063626478911488.0000 - mse: 3063626478911488.0000 - val_loss: 8031406844280832.0000 - val_mse: 8031406844280832.0000\n",
            "Epoch 316/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3059336343453696.0000 - mse: 3059336343453696.0000 - val_loss: 8027375480602624.0000 - val_mse: 8027375480602624.0000\n",
            "Epoch 317/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3055042449899520.0000 - mse: 3055042449899520.0000 - val_loss: 8023357538697216.0000 - val_mse: 8023357538697216.0000\n",
            "Epoch 318/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3050765199343616.0000 - mse: 3050765199343616.0000 - val_loss: 8019288057184256.0000 - val_mse: 8019288057184256.0000\n",
            "Epoch 319/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3046497075593216.0000 - mse: 3046497075593216.0000 - val_loss: 8015265820311552.0000 - val_mse: 8015265820311552.0000\n",
            "Epoch 320/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3042220361908224.0000 - mse: 3042220361908224.0000 - val_loss: 8011212981796864.0000 - val_mse: 8011212981796864.0000\n",
            "Epoch 321/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3037961096527872.0000 - mse: 3037961096527872.0000 - val_loss: 8007191818665984.0000 - val_mse: 8007191818665984.0000\n",
            "Epoch 322/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3033713373872128.0000 - mse: 3033713373872128.0000 - val_loss: 8003172803018752.0000 - val_mse: 8003172803018752.0000\n",
            "Epoch 323/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3029462161555456.0000 - mse: 3029462161555456.0000 - val_loss: 7999189220851712.0000 - val_mse: 7999189220851712.0000\n",
            "Epoch 324/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3025220881350656.0000 - mse: 3025220881350656.0000 - val_loss: 7995199196233728.0000 - val_mse: 7995199196233728.0000\n",
            "Epoch 325/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3020985775161344.0000 - mse: 3020985775161344.0000 - val_loss: 7991203802906624.0000 - val_mse: 7991203802906624.0000\n",
            "Epoch 326/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3016753084891136.0000 - mse: 3016753084891136.0000 - val_loss: 7987198209032192.0000 - val_mse: 7987198209032192.0000\n",
            "Epoch 327/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3012533547958272.0000 - mse: 3012533547958272.0000 - val_loss: 7983184025223168.0000 - val_mse: 7983184025223168.0000\n",
            "Epoch 328/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3008315353202688.0000 - mse: 3008315353202688.0000 - val_loss: 7979174673252352.0000 - val_mse: 7979174673252352.0000\n",
            "Epoch 329/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3004108969607168.0000 - mse: 3004108969607168.0000 - val_loss: 7975165321281536.0000 - val_mse: 7975165321281536.0000\n",
            "Epoch 330/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2999898291044352.0000 - mse: 2999898291044352.0000 - val_loss: 7971190865920000.0000 - val_mse: 7971190865920000.0000\n",
            "Epoch 331/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2995696202416128.0000 - mse: 2995696202416128.0000 - val_loss: 7967204599398400.0000 - val_mse: 7967204599398400.0000\n",
            "Epoch 332/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2991511830528000.0000 - mse: 2991511830528000.0000 - val_loss: 7963258598195200.0000 - val_mse: 7963258598195200.0000\n",
            "Epoch 333/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2987321016188928.0000 - mse: 2987321016188928.0000 - val_loss: 7959297564606464.0000 - val_mse: 7959297564606464.0000\n",
            "Epoch 334/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2983140670832640.0000 - mse: 2983140670832640.0000 - val_loss: 7955262979702784.0000 - val_mse: 7955262979702784.0000\n",
            "Epoch 335/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2978966499491840.0000 - mse: 2978966499491840.0000 - val_loss: 7951288524341248.0000 - val_mse: 7951288524341248.0000\n",
            "Epoch 336/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2974793670328320.0000 - mse: 2974793670328320.0000 - val_loss: 7947250181341184.0000 - val_mse: 7947250181341184.0000\n",
            "Epoch 337/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2970629967970304.0000 - mse: 2970629967970304.0000 - val_loss: 7943282168430592.0000 - val_mse: 7943282168430592.0000\n",
            "Epoch 338/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2966471365885952.0000 - mse: 2966471365885952.0000 - val_loss: 7939308786810880.0000 - val_mse: 7939308786810880.0000\n",
            "Epoch 339/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2962327259316224.0000 - mse: 2962327259316224.0000 - val_loss: 7935364396220416.0000 - val_mse: 7935364396220416.0000\n",
            "Epoch 340/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2958170536280064.0000 - mse: 2958170536280064.0000 - val_loss: 7931402288889856.0000 - val_mse: 7931402288889856.0000\n",
            "Epoch 341/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2954021866307584.0000 - mse: 2954021866307584.0000 - val_loss: 7927499774230528.0000 - val_mse: 7927499774230528.0000\n",
            "Epoch 342/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2949896013348864.0000 - mse: 2949896013348864.0000 - val_loss: 7923531761319936.0000 - val_mse: 7923531761319936.0000\n",
            "Epoch 343/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2945765060116480.0000 - mse: 2945765060116480.0000 - val_loss: 7919543884185600.0000 - val_mse: 7919543884185600.0000\n",
            "Epoch 344/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2941636254367744.0000 - mse: 2941636254367744.0000 - val_loss: 7915583924338688.0000 - val_mse: 7915583924338688.0000\n",
            "Epoch 345/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2937513085763584.0000 - mse: 2937513085763584.0000 - val_loss: 7911649734295552.0000 - val_mse: 7911649734295552.0000\n",
            "Epoch 346/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2933404144238592.0000 - mse: 2933404144238592.0000 - val_loss: 7907704806834176.0000 - val_mse: 7907704806834176.0000\n",
            "Epoch 347/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2929296008019968.0000 - mse: 2929296008019968.0000 - val_loss: 7903772764274688.0000 - val_mse: 7903772764274688.0000\n",
            "Epoch 348/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2925187871801344.0000 - mse: 2925187871801344.0000 - val_loss: 7899840184844288.0000 - val_mse: 7899840184844288.0000\n",
            "Epoch 349/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2921093962661888.0000 - mse: 2921093962661888.0000 - val_loss: 7895936059572224.0000 - val_mse: 7895936059572224.0000\n",
            "Epoch 350/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2916992268894208.0000 - mse: 2916992268894208.0000 - val_loss: 7892028176203776.0000 - val_mse: 7892028176203776.0000\n",
            "Epoch 351/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2912911244656640.0000 - mse: 2912911244656640.0000 - val_loss: 7888063384518656.0000 - val_mse: 7888063384518656.0000\n",
            "Epoch 352/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2908820825178112.0000 - mse: 2908820825178112.0000 - val_loss: 7884101814059008.0000 - val_mse: 7884101814059008.0000\n",
            "Epoch 353/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2904739532505088.0000 - mse: 2904739532505088.0000 - val_loss: 7880143464824832.0000 - val_mse: 7880143464824832.0000\n",
            "Epoch 354/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2900672466911232.0000 - mse: 2900672466911232.0000 - val_loss: 7876212496007168.0000 - val_mse: 7876212496007168.0000\n",
            "Epoch 355/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2896597616689152.0000 - mse: 2896597616689152.0000 - val_loss: 7872272937254912.0000 - val_mse: 7872272937254912.0000\n",
            "Epoch 356/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2892533772320768.0000 - mse: 2892533772320768.0000 - val_loss: 7868414982881280.0000 - val_mse: 7868414982881280.0000\n",
            "Epoch 357/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2888474222919680.0000 - mse: 2888474222919680.0000 - val_loss: 7864518910672896.0000 - val_mse: 7864518910672896.0000\n",
            "Epoch 358/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2884422995017728.0000 - mse: 2884422995017728.0000 - val_loss: 7860612101046272.0000 - val_mse: 7860612101046272.0000\n",
            "Epoch 359/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2880368545890304.0000 - mse: 2880368545890304.0000 - val_loss: 7856736966803456.0000 - val_mse: 7856736966803456.0000\n",
            "Epoch 360/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2876325639487488.0000 - mse: 2876325639487488.0000 - val_loss: 7852812440436736.0000 - val_mse: 7852812440436736.0000\n",
            "Epoch 361/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2872286759616512.0000 - mse: 2872286759616512.0000 - val_loss: 7848904557068288.0000 - val_mse: 7848904557068288.0000\n",
            "Epoch 362/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2868249490358272.0000 - mse: 2868249490358272.0000 - val_loss: 7844976809476096.0000 - val_mse: 7844976809476096.0000\n",
            "Epoch 363/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2864220811034624.0000 - mse: 2864220811034624.0000 - val_loss: 7841074831687680.0000 - val_mse: 7841074831687680.0000\n",
            "Epoch 364/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2860192131710976.0000 - mse: 2860192131710976.0000 - val_loss: 7837168558931968.0000 - val_mse: 7837168558931968.0000\n",
            "Epoch 365/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2856179021643776.0000 - mse: 2856179021643776.0000 - val_loss: 7833326710685696.0000 - val_mse: 7833326710685696.0000\n",
            "Epoch 366/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2852152221368320.0000 - mse: 2852152221368320.0000 - val_loss: 7829443523379200.0000 - val_mse: 7829443523379200.0000\n",
            "Epoch 367/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2848137769123840.0000 - mse: 2848137769123840.0000 - val_loss: 7825582884651008.0000 - val_mse: 7825582884651008.0000\n",
            "Epoch 368/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2844138617700352.0000 - mse: 2844138617700352.0000 - val_loss: 7821755531919360.0000 - val_mse: 7821755531919360.0000\n",
            "Epoch 369/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2840132486955008.0000 - mse: 2840132486955008.0000 - val_loss: 7817844964196352.0000 - val_mse: 7817844964196352.0000\n",
            "Epoch 370/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2836140314853376.0000 - mse: 2836140314853376.0000 - val_loss: 7813995062886400.0000 - val_mse: 7813995062886400.0000\n",
            "Epoch 371/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2832139821252608.0000 - mse: 2832139821252608.0000 - val_loss: 7810076442099712.0000 - val_mse: 7810076442099712.0000\n",
            "Epoch 372/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2828151407247360.0000 - mse: 2828151407247360.0000 - val_loss: 7806224930177024.0000 - val_mse: 7806224930177024.0000\n",
            "Epoch 373/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2824167019773952.0000 - mse: 2824167019773952.0000 - val_loss: 7802311141228544.0000 - val_mse: 7802311141228544.0000\n",
            "Epoch 374/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2820187732574208.0000 - mse: 2820187732574208.0000 - val_loss: 7798417753374720.0000 - val_mse: 7798417753374720.0000\n",
            "Epoch 375/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2816210861293568.0000 - mse: 2816210861293568.0000 - val_loss: 7794588790030336.0000 - val_mse: 7794588790030336.0000\n",
            "Epoch 376/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2812235600625664.0000 - mse: 2812235600625664.0000 - val_loss: 7790775932813312.0000 - val_mse: 7790775932813312.0000\n",
            "Epoch 377/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2808270003634176.0000 - mse: 2808270003634176.0000 - val_loss: 7786906167279616.0000 - val_mse: 7786906167279616.0000\n",
            "Epoch 378/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2804308701609984.0000 - mse: 2804308701609984.0000 - val_loss: 7783121227350016.0000 - val_mse: 7783121227350016.0000\n",
            "Epoch 379/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2800343641489408.0000 - mse: 2800343641489408.0000 - val_loss: 7779285821554688.0000 - val_mse: 7779285821554688.0000\n",
            "Epoch 380/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2796395761238016.0000 - mse: 2796395761238016.0000 - val_loss: 7775409613570048.0000 - val_mse: 7775409613570048.0000\n",
            "Epoch 381/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2792436875132928.0000 - mse: 2792436875132928.0000 - val_loss: 7771560786001920.0000 - val_mse: 7771560786001920.0000\n",
            "Epoch 382/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2788497316380672.0000 - mse: 2788497316380672.0000 - val_loss: 7767717327142912.0000 - val_mse: 7767717327142912.0000\n",
            "Epoch 383/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2784553999532032.0000 - mse: 2784553999532032.0000 - val_loss: 7763876552638464.0000 - val_mse: 7763876552638464.0000\n",
            "Epoch 384/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2780610414247936.0000 - mse: 2780610414247936.0000 - val_loss: 7760082485903360.0000 - val_mse: 7760082485903360.0000\n",
            "Epoch 385/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2776677029511168.0000 - mse: 2776677029511168.0000 - val_loss: 7756251911946240.0000 - val_mse: 7756251911946240.0000\n",
            "Epoch 386/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2772746597564416.0000 - mse: 2772746597564416.0000 - val_loss: 7752461603307520.0000 - val_mse: 7752461603307520.0000\n",
            "Epoch 387/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2768825292423168.0000 - mse: 2768825292423168.0000 - val_loss: 7748668610314240.0000 - val_mse: 7748668610314240.0000\n",
            "Epoch 388/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2764902913540096.0000 - mse: 2764902913540096.0000 - val_loss: 7744878301675520.0000 - val_mse: 7744878301675520.0000\n",
            "Epoch 389/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2760981876834304.0000 - mse: 2760981876834304.0000 - val_loss: 7741053633298432.0000 - val_mse: 7741053633298432.0000\n",
            "Epoch 390/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2757067014144000.0000 - mse: 2757067014144000.0000 - val_loss: 7737231112404992.0000 - val_mse: 7737231112404992.0000\n",
            "Epoch 391/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2753160472952832.0000 - mse: 2753160472952832.0000 - val_loss: 7733416644575232.0000 - val_mse: 7733416644575232.0000\n",
            "Epoch 392/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2749244268085248.0000 - mse: 2749244268085248.0000 - val_loss: 7729585533747200.0000 - val_mse: 7729585533747200.0000\n",
            "Epoch 393/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2745350343360512.0000 - mse: 2745350343360512.0000 - val_loss: 7725825826750464.0000 - val_mse: 7725825826750464.0000\n",
            "Epoch 394/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2741452392103936.0000 - mse: 2741452392103936.0000 - val_loss: 7722040349949952.0000 - val_mse: 7722040349949952.0000\n",
            "Epoch 395/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2737554709282816.0000 - mse: 2737554709282816.0000 - val_loss: 7718274737373184.0000 - val_mse: 7718274737373184.0000\n",
            "Epoch 396/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2733664542654464.0000 - mse: 2733664542654464.0000 - val_loss: 7714471543832576.0000 - val_mse: 7714471543832576.0000\n",
            "Epoch 397/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2729781623783424.0000 - mse: 2729781623783424.0000 - val_loss: 7710728479834112.0000 - val_mse: 7710728479834112.0000\n",
            "Epoch 398/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2725899241783296.0000 - mse: 2725899241783296.0000 - val_loss: 7706972530933760.0000 - val_mse: 7706972530933760.0000\n",
            "Epoch 399/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2722020081008640.0000 - mse: 2722020081008640.0000 - val_loss: 7703227319451648.0000 - val_mse: 7703227319451648.0000\n",
            "Epoch 400/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2718141725540352.0000 - mse: 2718141725540352.0000 - val_loss: 7699428957749248.0000 - val_mse: 7699428957749248.0000\n",
            "Epoch 401/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2714271691571200.0000 - mse: 2714271691571200.0000 - val_loss: 7695643480948736.0000 - val_mse: 7695643480948736.0000\n",
            "Epoch 402/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2710402194472960.0000 - mse: 2710402194472960.0000 - val_loss: 7691884310822912.0000 - val_mse: 7691884310822912.0000\n",
            "Epoch 403/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2706543166357504.0000 - mse: 2706543166357504.0000 - val_loss: 7688055347478528.0000 - val_mse: 7688055347478528.0000\n",
            "Epoch 404/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2702683064500224.0000 - mse: 2702683064500224.0000 - val_loss: 7684358454378496.0000 - val_mse: 7684358454378496.0000\n",
            "Epoch 405/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2698828062916608.0000 - mse: 2698828062916608.0000 - val_loss: 7680599821123584.0000 - val_mse: 7680599821123584.0000\n",
            "Epoch 406/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2694971719155712.0000 - mse: 2694971719155712.0000 - val_loss: 7676869642027008.0000 - val_mse: 7676869642027008.0000\n",
            "Epoch 407/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2691125039071232.0000 - mse: 2691125039071232.0000 - val_loss: 7673141073543168.0000 - val_mse: 7673141073543168.0000\n",
            "Epoch 408/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2687281848647680.0000 - mse: 2687281848647680.0000 - val_loss: 7669432906153984.0000 - val_mse: 7669432906153984.0000\n",
            "Epoch 409/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2683439731965952.0000 - mse: 2683439731965952.0000 - val_loss: 7665668367319040.0000 - val_mse: 7665668367319040.0000\n",
            "Epoch 410/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2679598420590592.0000 - mse: 2679598420590592.0000 - val_loss: 7661963958026240.0000 - val_mse: 7661963958026240.0000\n",
            "Epoch 411/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2675772946907136.0000 - mse: 2675772946907136.0000 - val_loss: 7658238610767872.0000 - val_mse: 7658238610767872.0000\n",
            "Epoch 412/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2671931367096320.0000 - mse: 2671931367096320.0000 - val_loss: 7654493399285760.0000 - val_mse: 7654493399285760.0000\n",
            "Epoch 413/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2668107772461056.0000 - mse: 2668107772461056.0000 - val_loss: 7650771273252864.0000 - val_mse: 7650771273252864.0000\n",
            "Epoch 414/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2664281493471232.0000 - mse: 2664281493471232.0000 - val_loss: 7647028746125312.0000 - val_mse: 7647028746125312.0000\n",
            "Epoch 415/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2660461120061440.0000 - mse: 2660461120061440.0000 - val_loss: 7643319504994304.0000 - val_mse: 7643319504994304.0000\n",
            "Epoch 416/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2656652289376256.0000 - mse: 2656652289376256.0000 - val_loss: 7639625296248832.0000 - val_mse: 7639625296248832.0000\n",
            "Epoch 417/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2652834600321024.0000 - mse: 2652834600321024.0000 - val_loss: 7635952025468928.0000 - val_mse: 7635952025468928.0000\n",
            "Epoch 418/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2649034359570432.0000 - mse: 2649034359570432.0000 - val_loss: 7632261574819840.0000 - val_mse: 7632261574819840.0000\n",
            "Epoch 419/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2645216133644288.0000 - mse: 2645216133644288.0000 - val_loss: 7628592599007232.0000 - val_mse: 7628592599007232.0000\n",
            "Epoch 420/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2641423140651008.0000 - mse: 2641423140651008.0000 - val_loss: 7624900537745408.0000 - val_mse: 7624900537745408.0000\n",
            "Epoch 421/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2637621289287680.0000 - mse: 2637621289287680.0000 - val_loss: 7621174653616128.0000 - val_mse: 7621174653616128.0000\n",
            "Epoch 422/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2633829101600768.0000 - mse: 2633829101600768.0000 - val_loss: 7617464338743296.0000 - val_mse: 7617464338743296.0000\n",
            "Epoch 423/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2630031276769280.0000 - mse: 2630031276769280.0000 - val_loss: 7613798584156160.0000 - val_mse: 7613798584156160.0000\n",
            "Epoch 424/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2626239625953280.0000 - mse: 2626239625953280.0000 - val_loss: 7610106522894336.0000 - val_mse: 7610106522894336.0000\n",
            "Epoch 425/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2622464886571008.0000 - mse: 2622464886571008.0000 - val_loss: 7606468148723712.0000 - val_mse: 7606468148723712.0000\n",
            "Epoch 426/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2618679409770496.0000 - mse: 2618679409770496.0000 - val_loss: 7602824405843968.0000 - val_mse: 7602824405843968.0000\n",
            "Epoch 427/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2614901449162752.0000 - mse: 2614901449162752.0000 - val_loss: 7599154356289536.0000 - val_mse: 7599154356289536.0000\n",
            "Epoch 428/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2611124293861376.0000 - mse: 2611124293861376.0000 - val_loss: 7595486454218752.0000 - val_mse: 7595486454218752.0000\n",
            "Epoch 429/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2607356802236416.0000 - mse: 2607356802236416.0000 - val_loss: 7591814794051584.0000 - val_mse: 7591814794051584.0000\n",
            "Epoch 430/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2603585015644160.0000 - mse: 2603585015644160.0000 - val_loss: 7588169440559104.0000 - val_mse: 7588169440559104.0000\n",
            "Epoch 431/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2599826113953792.0000 - mse: 2599826113953792.0000 - val_loss: 7584487579844608.0000 - val_mse: 7584487579844608.0000\n",
            "Epoch 432/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2596065333215232.0000 - mse: 2596065333215232.0000 - val_loss: 7580838468255744.0000 - val_mse: 7580838468255744.0000\n",
            "Epoch 433/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2592302136557568.0000 - mse: 2592302136557568.0000 - val_loss: 7577186135441408.0000 - val_mse: 7577186135441408.0000\n",
            "Epoch 434/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2588548603576320.0000 - mse: 2588548603576320.0000 - val_loss: 7573601448361984.0000 - val_mse: 7573601448361984.0000\n",
            "Epoch 435/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2584800170868736.0000 - mse: 2584800170868736.0000 - val_loss: 7569982938415104.0000 - val_mse: 7569982938415104.0000\n",
            "Epoch 436/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2581052006596608.0000 - mse: 2581052006596608.0000 - val_loss: 7566344564244480.0000 - val_mse: 7566344564244480.0000\n",
            "Epoch 437/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2577311895388160.0000 - mse: 2577311895388160.0000 - val_loss: 7562748066004992.0000 - val_mse: 7562748066004992.0000\n",
            "Epoch 438/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2573569636696064.0000 - mse: 2573569636696064.0000 - val_loss: 7559097343803392.0000 - val_mse: 7559097343803392.0000\n",
            "Epoch 439/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2569832209842176.0000 - mse: 2569832209842176.0000 - val_loss: 7555465412083712.0000 - val_mse: 7555465412083712.0000\n",
            "Epoch 440/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2566092635504640.0000 - mse: 2566092635504640.0000 - val_loss: 7551862471393280.0000 - val_mse: 7551862471393280.0000\n",
            "Epoch 441/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2562364603891712.0000 - mse: 2562364603891712.0000 - val_loss: 7548254161993728.0000 - val_mse: 7548254161993728.0000\n",
            "Epoch 442/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2558639525068800.0000 - mse: 2558639525068800.0000 - val_loss: 7544639947014144.0000 - val_mse: 7544639947014144.0000\n",
            "Epoch 443/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2554909077536768.0000 - mse: 2554909077536768.0000 - val_loss: 7541046133129216.0000 - val_mse: 7541046133129216.0000\n",
            "Epoch 444/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2551188562116608.0000 - mse: 2551188562116608.0000 - val_loss: 7537487752724480.0000 - val_mse: 7537487752724480.0000\n",
            "Epoch 445/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2547468583567360.0000 - mse: 2547468583567360.0000 - val_loss: 7533906823741440.0000 - val_mse: 7533906823741440.0000\n",
            "Epoch 446/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2543752899985408.0000 - mse: 2543752899985408.0000 - val_loss: 7530288850665472.0000 - val_mse: 7530288850665472.0000\n",
            "Epoch 447/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2540044464160768.0000 - mse: 2540044464160768.0000 - val_loss: 7526712753520640.0000 - val_mse: 7526712753520640.0000\n",
            "Epoch 448/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2536332001804288.0000 - mse: 2536332001804288.0000 - val_loss: 7523116792152064.0000 - val_mse: 7523116792152064.0000\n",
            "Epoch 449/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2532631887478784.0000 - mse: 2532631887478784.0000 - val_loss: 7519579886583808.0000 - val_mse: 7519579886583808.0000\n",
            "Epoch 450/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2528926941315072.0000 - mse: 2528926941315072.0000 - val_loss: 7515965134733312.0000 - val_mse: 7515965134733312.0000\n",
            "Epoch 451/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2525230853521408.0000 - mse: 2525230853521408.0000 - val_loss: 7512361657171968.0000 - val_mse: 7512361657171968.0000\n",
            "Epoch 452/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2521528054841344.0000 - mse: 2521528054841344.0000 - val_loss: 7508856426987520.0000 - val_mse: 7508856426987520.0000\n",
            "Epoch 453/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2517836798885888.0000 - mse: 2517836798885888.0000 - val_loss: 7505315226451968.0000 - val_mse: 7505315226451968.0000\n",
            "Epoch 454/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2514144469188608.0000 - mse: 2514144469188608.0000 - val_loss: 7501772415303680.0000 - val_mse: 7501772415303680.0000\n",
            "Epoch 455/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2510461803167744.0000 - mse: 2510461803167744.0000 - val_loss: 7498204908093440.0000 - val_mse: 7498204908093440.0000\n",
            "Epoch 456/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2506776452792320.0000 - mse: 2506776452792320.0000 - val_loss: 7494665855041536.0000 - val_mse: 7494665855041536.0000\n",
            "Epoch 457/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 2503100229222400.0000 - mse: 2503100229222400.0000 - val_loss: 7491099958444032.0000 - val_mse: 7491099958444032.0000\n",
            "Epoch 458/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2499416489459712.0000 - mse: 2499416489459712.0000 - val_loss: 7487592580775936.0000 - val_mse: 7487592580775936.0000\n",
            "Epoch 459/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2495748855824384.0000 - mse: 2495748855824384.0000 - val_loss: 7484050843369472.0000 - val_mse: 7484050843369472.0000\n",
            "Epoch 460/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2492075048173568.0000 - mse: 2492075048173568.0000 - val_loss: 7480524675219456.0000 - val_mse: 7480524675219456.0000\n",
            "Epoch 461/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2488403656441856.0000 - mse: 2488403656441856.0000 - val_loss: 7476982400942080.0000 - val_mse: 7476982400942080.0000\n",
            "Epoch 462/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2484743002128384.0000 - mse: 2484743002128384.0000 - val_loss: 7473449790341120.0000 - val_mse: 7473449790341120.0000\n",
            "Epoch 463/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2481078052847616.0000 - mse: 2481078052847616.0000 - val_loss: 7469995562893312.0000 - val_mse: 7469995562893312.0000\n",
            "Epoch 464/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2477419814453248.0000 - mse: 2477419814453248.0000 - val_loss: 7466459194195968.0000 - val_mse: 7466459194195968.0000\n",
            "Epoch 465/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2473769092251648.0000 - mse: 2473769092251648.0000 - val_loss: 7462957185236992.0000 - val_mse: 7462957185236992.0000\n",
            "Epoch 466/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2470110316986368.0000 - mse: 2470110316986368.0000 - val_loss: 7459430480216064.0000 - val_mse: 7459430480216064.0000\n",
            "Epoch 467/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2466464426622976.0000 - mse: 2466464426622976.0000 - val_loss: 7455944577384448.0000 - val_mse: 7455944577384448.0000\n",
            "Epoch 468/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2462817194082304.0000 - mse: 2462817194082304.0000 - val_loss: 7452425925427200.0000 - val_mse: 7452425925427200.0000\n",
            "Epoch 469/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2459171572154368.0000 - mse: 2459171572154368.0000 - val_loss: 7448959886819328.0000 - val_mse: 7448959886819328.0000\n",
            "Epoch 470/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2455532392677376.0000 - mse: 2455532392677376.0000 - val_loss: 7445474520858624.0000 - val_mse: 7445474520858624.0000\n",
            "Epoch 471/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2451894286942208.0000 - mse: 2451894286942208.0000 - val_loss: 7442008482250752.0000 - val_mse: 7442008482250752.0000\n",
            "Epoch 472/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2448254302158848.0000 - mse: 2448254302158848.0000 - val_loss: 7438518821322752.0000 - val_mse: 7438518821322752.0000\n",
            "Epoch 473/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2444624786358272.0000 - mse: 2444624786358272.0000 - val_loss: 7435086605582336.0000 - val_mse: 7435086605582336.0000\n",
            "Epoch 474/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2441000370831360.0000 - mse: 2441000370831360.0000 - val_loss: 7431632915005440.0000 - val_mse: 7431632915005440.0000\n",
            "Epoch 475/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2437370855030784.0000 - mse: 2437370855030784.0000 - val_loss: 7428132516659200.0000 - val_mse: 7428132516659200.0000\n",
            "Epoch 476/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2433747781681152.0000 - mse: 2433747781681152.0000 - val_loss: 7424660572471296.0000 - val_mse: 7424660572471296.0000\n",
            "Epoch 477/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2430132492959744.0000 - mse: 2430132492959744.0000 - val_loss: 7421193996992512.0000 - val_mse: 7421193996992512.0000\n",
            "Epoch 478/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2426512640835584.0000 - mse: 2426512640835584.0000 - val_loss: 7417765002477568.0000 - val_mse: 7417765002477568.0000\n",
            "Epoch 479/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2422899768033280.0000 - mse: 2422899768033280.0000 - val_loss: 7414309164417024.0000 - val_mse: 7414309164417024.0000\n",
            "Epoch 480/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2419287700537344.0000 - mse: 2419287700537344.0000 - val_loss: 7410878022418432.0000 - val_mse: 7410878022418432.0000\n",
            "Epoch 481/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2415683686105088.0000 - mse: 2415683686105088.0000 - val_loss: 7407437216743424.0000 - val_mse: 7407437216743424.0000\n",
            "Epoch 482/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2412074571399168.0000 - mse: 2412074571399168.0000 - val_loss: 7404036676386816.0000 - val_mse: 7404036676386816.0000\n",
            "Epoch 483/2000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2408477804724224.0000 - mse: 2408477804724224.0000 - val_loss: 7400604460646400.0000 - val_mse: 7400604460646400.0000\n",
            "Epoch 484/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2404872179679232.0000 - mse: 2404872179679232.0000 - val_loss: 7397164728713216.0000 - val_mse: 7397164728713216.0000\n",
            "Epoch 485/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2401282392326144.0000 - mse: 2401282392326144.0000 - val_loss: 7393743787261952.0000 - val_mse: 7393743787261952.0000\n",
            "Epoch 486/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2397681867554816.0000 - mse: 2397681867554816.0000 - val_loss: 7390309960908800.0000 - val_mse: 7390309960908800.0000\n",
            "Epoch 487/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2394095301427200.0000 - mse: 2394095301427200.0000 - val_loss: 7386911568035840.0000 - val_mse: 7386911568035840.0000\n",
            "Epoch 488/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2390509540605952.0000 - mse: 2390509540605952.0000 - val_loss: 7383474520457216.0000 - val_mse: 7383474520457216.0000\n",
            "Epoch 489/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2386919484817408.0000 - mse: 2386919484817408.0000 - val_loss: 7380062168940544.0000 - val_mse: 7380062168940544.0000\n",
            "Epoch 490/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2383343387672576.0000 - mse: 2383343387672576.0000 - val_loss: 7376692230225920.0000 - val_mse: 7376692230225920.0000\n",
            "Epoch 491/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2379763532431360.0000 - mse: 2379763532431360.0000 - val_loss: 7373285784289280.0000 - val_mse: 7373285784289280.0000\n",
            "Epoch 492/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2376194414608384.0000 - mse: 2376194414608384.0000 - val_loss: 7369917456187392.0000 - val_mse: 7369917456187392.0000\n",
            "Epoch 493/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2372611338141696.0000 - mse: 2372611338141696.0000 - val_loss: 7366515305218048.0000 - val_mse: 7366515305218048.0000\n",
            "Epoch 494/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2369041146576896.0000 - mse: 2369041146576896.0000 - val_loss: 7363167378210816.0000 - val_mse: 7363167378210816.0000\n",
            "Epoch 495/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2365481423994880.0000 - mse: 2365481423994880.0000 - val_loss: 7359788849561600.0000 - val_mse: 7359788849561600.0000\n",
            "Epoch 496/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2361913916784640.0000 - mse: 2361913916784640.0000 - val_loss: 7356414079008768.0000 - val_mse: 7356414079008768.0000\n",
            "Epoch 497/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2358355267944448.0000 - mse: 2358355267944448.0000 - val_loss: 7353070446968832.0000 - val_mse: 7353070446968832.0000\n",
            "Epoch 498/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2354796082233344.0000 - mse: 2354796082233344.0000 - val_loss: 7349733257379840.0000 - val_mse: 7349733257379840.0000\n",
            "Epoch 499/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2351246291763200.0000 - mse: 2351246291763200.0000 - val_loss: 7346355265601536.0000 - val_mse: 7346355265601536.0000\n",
            "Epoch 500/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2347689253535744.0000 - mse: 2347689253535744.0000 - val_loss: 7343005191110656.0000 - val_mse: 7343005191110656.0000\n",
            "Epoch 501/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2344140268371968.0000 - mse: 2344140268371968.0000 - val_loss: 7339668001521664.0000 - val_mse: 7339668001521664.0000\n",
            "Epoch 502/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2340591283208192.0000 - mse: 2340591283208192.0000 - val_loss: 7336291620356096.0000 - val_mse: 7336291620356096.0000\n",
            "Epoch 503/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2337056256688128.0000 - mse: 2337056256688128.0000 - val_loss: 7332943156477952.0000 - val_mse: 7332943156477952.0000\n",
            "Epoch 504/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2333508882137088.0000 - mse: 2333508882137088.0000 - val_loss: 7329591471374336.0000 - val_mse: 7329591471374336.0000\n",
            "Epoch 505/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2329966607859712.0000 - mse: 2329966607859712.0000 - val_loss: 7326244081238016.0000 - val_mse: 7326244081238016.0000\n",
            "Epoch 506/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2326435071000576.0000 - mse: 2326435071000576.0000 - val_loss: 7322943398871040.0000 - val_mse: 7322943398871040.0000\n",
            "Epoch 507/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2322902460399616.0000 - mse: 2322902460399616.0000 - val_loss: 7319599229960192.0000 - val_mse: 7319599229960192.0000\n",
            "Epoch 508/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2319375218507776.0000 - mse: 2319375218507776.0000 - val_loss: 7316311969366016.0000 - val_mse: 7316311969366016.0000\n",
            "Epoch 509/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2315845829132288.0000 - mse: 2315845829132288.0000 - val_loss: 7312997865226240.0000 - val_mse: 7312997865226240.0000\n",
            "Epoch 510/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2312320734724096.0000 - mse: 2312320734724096.0000 - val_loss: 7309641885155328.0000 - val_mse: 7309641885155328.0000\n",
            "Epoch 511/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2308799398412288.0000 - mse: 2308799398412288.0000 - val_loss: 7306369120075776.0000 - val_mse: 7306369120075776.0000\n",
            "Epoch 512/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2305279404277760.0000 - mse: 2305279404277760.0000 - val_loss: 7303054479065088.0000 - val_mse: 7303054479065088.0000\n",
            "Epoch 513/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2301761826062336.0000 - mse: 2301761826062336.0000 - val_loss: 7299760239149056.0000 - val_mse: 7299760239149056.0000\n",
            "Epoch 514/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2298255790571520.0000 - mse: 2298255790571520.0000 - val_loss: 7296457409298432.0000 - val_mse: 7296457409298432.0000\n",
            "Epoch 515/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2294743849500672.0000 - mse: 2294743849500672.0000 - val_loss: 7293174443671552.0000 - val_mse: 7293174443671552.0000\n",
            "Epoch 516/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2291231371558912.0000 - mse: 2291231371558912.0000 - val_loss: 7289902215462912.0000 - val_mse: 7289902215462912.0000\n",
            "Epoch 517/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2287734999744512.0000 - mse: 2287734999744512.0000 - val_loss: 7286603680579584.0000 - val_mse: 7286603680579584.0000\n",
            "Epoch 518/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2284232453914624.0000 - mse: 2284232453914624.0000 - val_loss: 7283350242852864.0000 - val_mse: 7283350242852864.0000\n",
            "Epoch 519/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2280735008358400.0000 - mse: 2280735008358400.0000 - val_loss: 7280043118034944.0000 - val_mse: 7280043118034944.0000\n",
            "Epoch 520/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2277235146883072.0000 - mse: 2277235146883072.0000 - val_loss: 7276807933919232.0000 - val_mse: 7276807933919232.0000\n",
            "Epoch 521/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2273748438745088.0000 - mse: 2273748438745088.0000 - val_loss: 7273552348708864.0000 - val_mse: 7273552348708864.0000\n",
            "Epoch 522/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2270248845705216.0000 - mse: 2270248845705216.0000 - val_loss: 7270269383081984.0000 - val_mse: 7270269383081984.0000\n",
            "Epoch 523/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2266769385324544.0000 - mse: 2266769385324544.0000 - val_loss: 7267050305093632.0000 - val_mse: 7267050305093632.0000\n",
            "Epoch 524/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2263277845348352.0000 - mse: 2263277845348352.0000 - val_loss: 7263765191983104.0000 - val_mse: 7263765191983104.0000\n",
            "Epoch 525/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2259797848096768.0000 - mse: 2259797848096768.0000 - val_loss: 7260517659836416.0000 - val_mse: 7260517659836416.0000\n",
            "Epoch 526/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2256319998328832.0000 - mse: 2256319998328832.0000 - val_loss: 7257268517076992.0000 - val_mse: 7257268517076992.0000\n",
            "Epoch 527/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2252841880125440.0000 - mse: 2252841880125440.0000 - val_loss: 7254020984930304.0000 - val_mse: 7254020984930304.0000\n",
            "Epoch 528/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2249371680768000.0000 - mse: 2249371680768000.0000 - val_loss: 7250801906941952.0000 - val_mse: 7250801906941952.0000\n",
            "Epoch 529/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2245896112701440.0000 - mse: 2245896112701440.0000 - val_loss: 7247587123920896.0000 - val_mse: 7247587123920896.0000\n",
            "Epoch 530/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2242433563754496.0000 - mse: 2242433563754496.0000 - val_loss: 7244363750965248.0000 - val_mse: 7244363750965248.0000\n",
            "Epoch 531/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2238963901267968.0000 - mse: 2238963901267968.0000 - val_loss: 7241151652298752.0000 - val_mse: 7241151652298752.0000\n",
            "Epoch 532/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2235501218103296.0000 - mse: 2235501218103296.0000 - val_loss: 7237932574310400.0000 - val_mse: 7237932574310400.0000\n",
            "Epoch 533/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2232041621946368.0000 - mse: 2232041621946368.0000 - val_loss: 7234719401902080.0000 - val_mse: 7234719401902080.0000\n",
            "Epoch 534/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2228589005111296.0000 - mse: 2228589005111296.0000 - val_loss: 7231539515490304.0000 - val_mse: 7231539515490304.0000\n",
            "Epoch 535/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2225131690655744.0000 - mse: 2225131690655744.0000 - val_loss: 7228324195598336.0000 - val_mse: 7228324195598336.0000\n",
            "Epoch 536/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2221678805385216.0000 - mse: 2221678805385216.0000 - val_loss: 7225102970126336.0000 - val_mse: 7225102970126336.0000\n",
            "Epoch 537/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2218233838960640.0000 - mse: 2218233838960640.0000 - val_loss: 7221909661941760.0000 - val_mse: 7221909661941760.0000\n",
            "Epoch 538/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2214787933011968.0000 - mse: 2214787933011968.0000 - val_loss: 7218740512948224.0000 - val_mse: 7218740512948224.0000\n",
            "Epoch 539/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2211341624410112.0000 - mse: 2211341624410112.0000 - val_loss: 7215547204763648.0000 - val_mse: 7215547204763648.0000\n",
            "Epoch 540/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2207907798056960.0000 - mse: 2207907798056960.0000 - val_loss: 7212364097126400.0000 - val_mse: 7212364097126400.0000\n",
            "Epoch 541/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2204465381769216.0000 - mse: 2204465381769216.0000 - val_loss: 7209223402291200.0000 - val_mse: 7209223402291200.0000\n",
            "Epoch 542/2000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2201034642423808.0000 - mse: 2201034642423808.0000 - val_loss: 7206010229882880.0000 - val_mse: 7206010229882880.0000\n",
            "Epoch 543/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2197602024030208.0000 - mse: 2197602024030208.0000 - val_loss: 7202855039533056.0000 - val_mse: 7202855039533056.0000\n",
            "Epoch 544/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2194166050193408.0000 - mse: 2194166050193408.0000 - val_loss: 7199717565923328.0000 - val_mse: 7199717565923328.0000\n",
            "Epoch 545/2000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2190741887516672.0000 - mse: 2190741887516672.0000 - val_loss: 7196559154348032.0000 - val_mse: 7196559154348032.0000\n",
            "Epoch 546/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2187322422460416.0000 - mse: 2187322422460416.0000 - val_loss: 7193351350648832.0000 - val_mse: 7193351350648832.0000\n",
            "Epoch 547/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2183896380735488.0000 - mse: 2183896380735488.0000 - val_loss: 7190232130650112.0000 - val_mse: 7190232130650112.0000\n",
            "Epoch 548/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 2180475707719680.0000 - mse: 2180475707719680.0000 - val_loss: 7187083919622144.0000 - val_mse: 7187083919622144.0000\n",
            "Epoch 549/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2177065906339840.0000 - mse: 2177065906339840.0000 - val_loss: 7183933561110528.0000 - val_mse: 7183933561110528.0000\n",
            "Epoch 550/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2173660131491840.0000 - mse: 2173660131491840.0000 - val_loss: 7180816488595456.0000 - val_mse: 7180816488595456.0000\n",
            "Epoch 551/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2170239726911488.0000 - mse: 2170239726911488.0000 - val_loss: 7177680088727552.0000 - val_mse: 7177680088727552.0000\n",
            "Epoch 552/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2166833146757120.0000 - mse: 2166833146757120.0000 - val_loss: 7174552278794240.0000 - val_mse: 7174552278794240.0000\n",
            "Epoch 553/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2163428982521856.0000 - mse: 2163428982521856.0000 - val_loss: 7171458828599296.0000 - val_mse: 7171458828599296.0000\n",
            "Epoch 554/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2160032737132544.0000 - mse: 2160032737132544.0000 - val_loss: 7168321354989568.0000 - val_mse: 7168321354989568.0000\n",
            "Epoch 555/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2156628707115008.0000 - mse: 2156628707115008.0000 - val_loss: 7165193545056256.0000 - val_mse: 7165193545056256.0000\n",
            "Epoch 556/2000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2153231656419328.0000 - mse: 2153231656419328.0000 - val_loss: 7162078620024832.0000 - val_mse: 7162078620024832.0000\n",
            "Epoch 557/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2149842256134144.0000 - mse: 2149842256134144.0000 - val_loss: 7158931482738688.0000 - val_mse: 7158931482738688.0000\n",
            "Epoch 558/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2146450708365312.0000 - mse: 2146450708365312.0000 - val_loss: 7155845011865600.0000 - val_mse: 7155845011865600.0000\n",
            "Epoch 559/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2143064529305600.0000 - mse: 2143064529305600.0000 - val_loss: 7152767667798016.0000 - val_mse: 7152767667798016.0000\n",
            "Epoch 560/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2139676873850880.0000 - mse: 2139676873850880.0000 - val_loss: 7149660258959360.0000 - val_mse: 7149660258959360.0000\n",
            "Epoch 561/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2136296600371200.0000 - mse: 2136296600371200.0000 - val_loss: 7146610295308288.0000 - val_mse: 7146610295308288.0000\n",
            "Epoch 562/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2132915118931968.0000 - mse: 2132915118931968.0000 - val_loss: 7143534024982528.0000 - val_mse: 7143534024982528.0000\n",
            "Epoch 563/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2129536456065024.0000 - mse: 2129536456065024.0000 - val_loss: 7140443796013056.0000 - val_mse: 7140443796013056.0000\n",
            "Epoch 564/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2126162625036288.0000 - mse: 2126162625036288.0000 - val_loss: 7137380410589184.0000 - val_mse: 7137380410589184.0000\n",
            "Epoch 565/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2122792283668480.0000 - mse: 2122792283668480.0000 - val_loss: 7134270854266880.0000 - val_mse: 7134270854266880.0000\n",
            "Epoch 566/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2119425029308416.0000 - mse: 2119425029308416.0000 - val_loss: 7131154855493632.0000 - val_mse: 7131154855493632.0000\n",
            "Epoch 567/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2116058446036992.0000 - mse: 2116058446036992.0000 - val_loss: 7128109723680768.0000 - val_mse: 7128109723680768.0000\n",
            "Epoch 568/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2112692533854208.0000 - mse: 2112692533854208.0000 - val_loss: 7125069960577024.0000 - val_mse: 7125069960577024.0000\n",
            "Epoch 569/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2109332124598272.0000 - mse: 2109332124598272.0000 - val_loss: 7122030197473280.0000 - val_mse: 7122030197473280.0000\n",
            "Epoch 570/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2105975607656448.0000 - mse: 2105975607656448.0000 - val_loss: 7118980770693120.0000 - val_mse: 7118980770693120.0000\n",
            "Epoch 571/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2102619224932352.0000 - mse: 2102619224932352.0000 - val_loss: 7115910405947392.0000 - val_mse: 7115910405947392.0000\n",
            "Epoch 572/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2099260828942336.0000 - mse: 2099260828942336.0000 - val_loss: 7112863663521792.0000 - val_mse: 7112863663521792.0000\n",
            "Epoch 573/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2095908606967808.0000 - mse: 2095908606967808.0000 - val_loss: 7109826584772608.0000 - val_mse: 7109826584772608.0000\n",
            "Epoch 574/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2092569269895168.0000 - mse: 2092569269895168.0000 - val_loss: 7106791653507072.0000 - val_mse: 7106791653507072.0000\n",
            "Epoch 575/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2089224966766592.0000 - mse: 2089224966766592.0000 - val_loss: 7103742226726912.0000 - val_mse: 7103742226726912.0000\n",
            "Epoch 576/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2085883079557120.0000 - mse: 2085883079557120.0000 - val_loss: 7100737897103360.0000 - val_mse: 7100737897103360.0000\n",
            "Epoch 577/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2082539447517184.0000 - mse: 2082539447517184.0000 - val_loss: 7097732493737984.0000 - val_mse: 7097732493737984.0000\n",
            "Epoch 578/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2079209505685504.0000 - mse: 2079209505685504.0000 - val_loss: 7094719037308928.0000 - val_mse: 7094719037308928.0000\n",
            "Epoch 579/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2075873926709248.0000 - mse: 2075873926709248.0000 - val_loss: 7091692695977984.0000 - val_mse: 7091692695977984.0000\n",
            "Epoch 580/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2072543179571200.0000 - mse: 2072543179571200.0000 - val_loss: 7088650785390592.0000 - val_mse: 7088650785390592.0000\n",
            "Epoch 581/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2069212432433152.0000 - mse: 2069212432433152.0000 - val_loss: 7085649676992512.0000 - val_mse: 7085649676992512.0000\n",
            "Epoch 582/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2065887188221952.0000 - mse: 2065887188221952.0000 - val_loss: 7082616356339712.0000 - val_mse: 7082616356339712.0000\n",
            "Epoch 583/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2062567178502144.0000 - mse: 2062567178502144.0000 - val_loss: 7079633501552640.0000 - val_mse: 7079633501552640.0000\n",
            "Epoch 584/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2059246497693696.0000 - mse: 2059246497693696.0000 - val_loss: 7076630245670912.0000 - val_mse: 7076630245670912.0000\n",
            "Epoch 585/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2055929709199360.0000 - mse: 2055929709199360.0000 - val_loss: 7073672086945792.0000 - val_mse: 7073672086945792.0000\n",
            "Epoch 586/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2052613860229120.0000 - mse: 2052613860229120.0000 - val_loss: 7070690842771456.0000 - val_mse: 7070690842771456.0000\n",
            "Epoch 587/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2049300024524800.0000 - mse: 2049300024524800.0000 - val_loss: 7067759527591936.0000 - val_mse: 7067759527591936.0000\n",
            "Epoch 588/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2045991423311872.0000 - mse: 2045991423311872.0000 - val_loss: 7064767545999360.0000 - val_mse: 7064767545999360.0000\n",
            "Epoch 589/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2042682151010304.0000 - mse: 2042682151010304.0000 - val_loss: 7061765363859456.0000 - val_mse: 7061765363859456.0000\n",
            "Epoch 590/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2039382139731968.0000 - mse: 2039382139731968.0000 - val_loss: 7058792172748800.0000 - val_mse: 7058792172748800.0000\n",
            "Epoch 591/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2036075686002688.0000 - mse: 2036075686002688.0000 - val_loss: 7055830255927296.0000 - val_mse: 7055830255927296.0000\n",
            "Epoch 592/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2032780372344832.0000 - mse: 2032780372344832.0000 - val_loss: 7052853306720256.0000 - val_mse: 7052853306720256.0000\n",
            "Epoch 593/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2029486535081984.0000 - mse: 2029486535081984.0000 - val_loss: 7049867230707712.0000 - val_mse: 7049867230707712.0000\n",
            "Epoch 594/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 2026192429383680.0000 - mse: 2026192429383680.0000 - val_loss: 7046997655683072.0000 - val_mse: 7046997655683072.0000\n",
            "Epoch 595/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2022907047837696.0000 - mse: 2022907047837696.0000 - val_loss: 7044034665119744.0000 - val_mse: 7044034665119744.0000\n",
            "Epoch 596/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2019622203162624.0000 - mse: 2019622203162624.0000 - val_loss: 7041135562194944.0000 - val_mse: 7041135562194944.0000\n",
            "Epoch 597/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2016330379165696.0000 - mse: 2016330379165696.0000 - val_loss: 7038182235308032.0000 - val_mse: 7038182235308032.0000\n",
            "Epoch 598/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2013054124425216.0000 - mse: 2013054124425216.0000 - val_loss: 7035203675488256.0000 - val_mse: 7035203675488256.0000\n",
            "Epoch 599/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2009768474443776.0000 - mse: 2009768474443776.0000 - val_loss: 7032241758666752.0000 - val_mse: 7032241758666752.0000\n",
            "Epoch 600/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2006496380452864.0000 - mse: 2006496380452864.0000 - val_loss: 7029321180905472.0000 - val_mse: 7029321180905472.0000\n",
            "Epoch 601/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2003217844011008.0000 - mse: 2003217844011008.0000 - val_loss: 7026388791984128.0000 - val_mse: 7026388791984128.0000\n",
            "Epoch 602/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1999948031721472.0000 - mse: 1999948031721472.0000 - val_loss: 7023462845513728.0000 - val_mse: 7023462845513728.0000\n",
            "Epoch 603/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1996680501133312.0000 - mse: 1996680501133312.0000 - val_loss: 7020602397294592.0000 - val_mse: 7020602397294592.0000\n",
            "Epoch 604/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1993410957279232.0000 - mse: 1993410957279232.0000 - val_loss: 7017671082115072.0000 - val_mse: 7017671082115072.0000\n",
            "Epoch 605/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1990150406012928.0000 - mse: 1990150406012928.0000 - val_loss: 7014821908185088.0000 - val_mse: 7014821908185088.0000\n",
            "Epoch 606/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1986893747060736.0000 - mse: 1986893747060736.0000 - val_loss: 7011897035456512.0000 - val_mse: 7011897035456512.0000\n",
            "Epoch 607/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1983634135318528.0000 - mse: 1983634135318528.0000 - val_loss: 7008969478373376.0000 - val_mse: 7008969478373376.0000\n",
            "Epoch 608/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1980380160720896.0000 - mse: 1980380160720896.0000 - val_loss: 7006040847548416.0000 - val_mse: 7006040847548416.0000\n",
            "Epoch 609/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1977131957485568.0000 - mse: 1977131957485568.0000 - val_loss: 7003191673618432.0000 - val_mse: 7003191673618432.0000\n",
            "Epoch 610/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1973881875202048.0000 - mse: 1973881875202048.0000 - val_loss: 7000266264018944.0000 - val_mse: 7000266264018944.0000\n",
            "Epoch 611/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1970632329789440.0000 - mse: 1970632329789440.0000 - val_loss: 6997394541510656.0000 - val_mse: 6997394541510656.0000\n",
            "Epoch 612/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1967386408255488.0000 - mse: 1967386408255488.0000 - val_loss: 6994512618455040.0000 - val_mse: 6994512618455040.0000\n",
            "Epoch 613/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1964146123866112.0000 - mse: 1964146123866112.0000 - val_loss: 6991663981395968.0000 - val_mse: 6991663981395968.0000\n",
            "Epoch 614/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1960910268661760.0000 - mse: 1960910268661760.0000 - val_loss: 6988772394663936.0000 - val_mse: 6988772394663936.0000\n",
            "Epoch 615/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1957670521143296.0000 - mse: 1957670521143296.0000 - val_loss: 6985887250382848.0000 - val_mse: 6985887250382848.0000\n",
            "Epoch 616/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1954438424035328.0000 - mse: 1954438424035328.0000 - val_loss: 6983032707743744.0000 - val_mse: 6983032707743744.0000\n",
            "Epoch 617/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1951207669104640.0000 - mse: 1951207669104640.0000 - val_loss: 6980181386330112.0000 - val_mse: 6980181386330112.0000\n",
            "Epoch 618/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1947976377303040.0000 - mse: 1947976377303040.0000 - val_loss: 6977301073887232.0000 - val_mse: 6977301073887232.0000\n",
            "Epoch 619/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1944756494008320.0000 - mse: 1944756494008320.0000 - val_loss: 6974450826215424.0000 - val_mse: 6974450826215424.0000\n",
            "Epoch 620/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1941533926359040.0000 - mse: 1941533926359040.0000 - val_loss: 6971661781827584.0000 - val_mse: 6971661781827584.0000\n",
            "Epoch 621/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1938312029798400.0000 - mse: 1938312029798400.0000 - val_loss: 6968772879450112.0000 - val_mse: 6968772879450112.0000\n",
            "Epoch 622/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1935092951810048.0000 - mse: 1935092951810048.0000 - val_loss: 6965957528387584.0000 - val_mse: 6965957528387584.0000\n",
            "Epoch 623/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1931878705659904.0000 - mse: 1931878705659904.0000 - val_loss: 6963114260037632.0000 - val_mse: 6963114260037632.0000\n",
            "Epoch 624/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1928664996380672.0000 - mse: 1928664996380672.0000 - val_loss: 6960237168820224.0000 - val_mse: 6960237168820224.0000\n",
            "Epoch 625/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1925458266423296.0000 - mse: 1925458266423296.0000 - val_loss: 6957390142373888.0000 - val_mse: 6957390142373888.0000\n",
            "Epoch 626/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1922255562997760.0000 - mse: 1922255562997760.0000 - val_loss: 6954568348860416.0000 - val_mse: 6954568348860416.0000\n",
            "Epoch 627/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1919059436240896.0000 - mse: 1919059436240896.0000 - val_loss: 6951754608410624.0000 - val_mse: 6951754608410624.0000\n",
            "Epoch 628/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1915853108936704.0000 - mse: 1915853108936704.0000 - val_loss: 6948975227699200.0000 - val_mse: 6948975227699200.0000\n",
            "Epoch 629/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1912656713744384.0000 - mse: 1912656713744384.0000 - val_loss: 6946171687796736.0000 - val_mse: 6946171687796736.0000\n",
            "Epoch 630/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1909457365762048.0000 - mse: 1909457365762048.0000 - val_loss: 6943337009381376.0000 - val_mse: 6943337009381376.0000\n",
            "Epoch 631/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1906260299481088.0000 - mse: 1906260299481088.0000 - val_loss: 6940549038735360.0000 - val_mse: 6940549038735360.0000\n",
            "Epoch 632/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1903078534021120.0000 - mse: 1903078534021120.0000 - val_loss: 6937732077060096.0000 - val_mse: 6937732077060096.0000\n",
            "Epoch 633/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1899891265634304.0000 - mse: 1899891265634304.0000 - val_loss: 6934924779061248.0000 - val_mse: 6934924779061248.0000\n",
            "Epoch 634/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1896706950037504.0000 - mse: 1896706950037504.0000 - val_loss: 6932126070996992.0000 - val_mse: 6932126070996992.0000\n",
            "Epoch 635/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1893519815868416.0000 - mse: 1893519815868416.0000 - val_loss: 6929374070702080.0000 - val_mse: 6929374070702080.0000\n",
            "Epoch 636/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1890346908778496.0000 - mse: 1890346908778496.0000 - val_loss: 6926575899508736.0000 - val_mse: 6926575899508736.0000\n",
            "Epoch 637/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1887170646245376.0000 - mse: 1887170646245376.0000 - val_loss: 6923770212122624.0000 - val_mse: 6923770212122624.0000\n",
            "Epoch 638/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1883994517929984.0000 - mse: 1883994517929984.0000 - val_loss: 6921026801762304.0000 - val_mse: 6921026801762304.0000\n",
            "Epoch 639/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1880823355670528.0000 - mse: 1880823355670528.0000 - val_loss: 6918252252889088.0000 - val_mse: 6918252252889088.0000\n",
            "Epoch 640/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1877656354160640.0000 - mse: 1877656354160640.0000 - val_loss: 6915458376663040.0000 - val_mse: 6915458376663040.0000\n",
            "Epoch 641/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1874491902787584.0000 - mse: 1874491902787584.0000 - val_loss: 6912685438402560.0000 - val_mse: 6912685438402560.0000\n",
            "Epoch 642/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1871326646108160.0000 - mse: 1871326646108160.0000 - val_loss: 6909916795109376.0000 - val_mse: 6909916795109376.0000\n",
            "Epoch 643/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1868171187322880.0000 - mse: 1868171187322880.0000 - val_loss: 6907158352363520.0000 - val_mse: 6907158352363520.0000\n",
            "Epoch 644/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1865018412892160.0000 - mse: 1865018412892160.0000 - val_loss: 6904416015745024.0000 - val_mse: 6904416015745024.0000\n",
            "Epoch 645/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1861860001316864.0000 - mse: 1861860001316864.0000 - val_loss: 6901650056806400.0000 - val_mse: 6901650056806400.0000\n",
            "Epoch 646/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1858710850764800.0000 - mse: 1858710850764800.0000 - val_loss: 6898915236380672.0000 - val_mse: 6898915236380672.0000\n",
            "Epoch 647/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1855559015858176.0000 - mse: 1855559015858176.0000 - val_loss: 6896151424925696.0000 - val_mse: 6896151424925696.0000\n",
            "Epoch 648/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1852417515716608.0000 - mse: 1852417515716608.0000 - val_loss: 6893385465987072.0000 - val_mse: 6893385465987072.0000\n",
            "Epoch 649/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1849274673397760.0000 - mse: 1849274673397760.0000 - val_loss: 6890683931557888.0000 - val_mse: 6890683931557888.0000\n",
            "Epoch 650/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1846132904820736.0000 - mse: 1846132904820736.0000 - val_loss: 6887980786515968.0000 - val_mse: 6887980786515968.0000\n",
            "Epoch 651/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1842993820598272.0000 - mse: 1842993820598272.0000 - val_loss: 6885229323091968.0000 - val_mse: 6885229323091968.0000\n",
            "Epoch 652/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1839857957601280.0000 - mse: 1839857957601280.0000 - val_loss: 6882460142927872.0000 - val_mse: 6882460142927872.0000\n",
            "Epoch 653/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1836723034128384.0000 - mse: 1836723034128384.0000 - val_loss: 6879736059920384.0000 - val_mse: 6879736059920384.0000\n",
            "Epoch 654/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1833591734534144.0000 - mse: 1833591734534144.0000 - val_loss: 6877004997591040.0000 - val_mse: 6877004997591040.0000\n",
            "Epoch 655/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1830469293309952.0000 - mse: 1830469293309952.0000 - val_loss: 6874316348063744.0000 - val_mse: 6874316348063744.0000\n",
            "Epoch 656/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1827344570384384.0000 - mse: 1827344570384384.0000 - val_loss: 6871588506959872.0000 - val_mse: 6871588506959872.0000\n",
            "Epoch 657/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1824222129160192.0000 - mse: 1824222129160192.0000 - val_loss: 6868900394303488.0000 - val_mse: 6868900394303488.0000\n",
            "Epoch 658/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1821108814741504.0000 - mse: 1821108814741504.0000 - val_loss: 6866171479457792.0000 - val_mse: 6866171479457792.0000\n",
            "Epoch 659/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1817990131613696.0000 - mse: 1817990131613696.0000 - val_loss: 6863486588026880.0000 - val_mse: 6863486588026880.0000\n",
            "Epoch 660/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1814872522227712.0000 - mse: 1814872522227712.0000 - val_loss: 6860798475370496.0000 - val_mse: 6860798475370496.0000\n",
            "Epoch 661/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1811761355292672.0000 - mse: 1811761355292672.0000 - val_loss: 6858100699037696.0000 - val_mse: 6858100699037696.0000\n",
            "Epoch 662/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1808659717816320.0000 - mse: 1808659717816320.0000 - val_loss: 6855399701479424.0000 - val_mse: 6855399701479424.0000\n",
            "Epoch 663/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1805559154081792.0000 - mse: 1805559154081792.0000 - val_loss: 6852730379304960.0000 - val_mse: 6852730379304960.0000\n",
            "Epoch 664/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1802450403065856.0000 - mse: 1802450403065856.0000 - val_loss: 6850013812490240.0000 - val_mse: 6850013812490240.0000\n",
            "Epoch 665/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1799356818653184.0000 - mse: 1799356818653184.0000 - val_loss: 6847359522701312.0000 - val_mse: 6847359522701312.0000\n",
            "Epoch 666/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1796257328660480.0000 - mse: 1796257328660480.0000 - val_loss: 6844696642977792.0000 - val_mse: 6844696642977792.0000\n",
            "Epoch 667/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1793156764925952.0000 - mse: 1793156764925952.0000 - val_loss: 6841984371130368.0000 - val_mse: 6841984371130368.0000\n",
            "Epoch 668/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1790069220311040.0000 - mse: 1790069220311040.0000 - val_loss: 6839327933857792.0000 - val_mse: 6839327933857792.0000\n",
            "Epoch 669/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1786978991341568.0000 - mse: 1786978991341568.0000 - val_loss: 6836672570327040.0000 - val_mse: 6836672570327040.0000\n",
            "Epoch 670/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1783895607476224.0000 - mse: 1783895607476224.0000 - val_loss: 6834003248152576.0000 - val_mse: 6834003248152576.0000\n",
            "Epoch 671/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1780815042183168.0000 - mse: 1780815042183168.0000 - val_loss: 6831312451141632.0000 - val_mse: 6831312451141632.0000\n",
            "Epoch 672/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1777731792535552.0000 - mse: 1777731792535552.0000 - val_loss: 6828710774702080.0000 - val_mse: 6828710774702080.0000\n",
            "Epoch 673/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1774654448467968.0000 - mse: 1774654448467968.0000 - val_loss: 6826032862593024.0000 - val_mse: 6826032862593024.0000\n",
            "Epoch 674/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1771582338891776.0000 - mse: 1771582338891776.0000 - val_loss: 6823403268866048.0000 - val_mse: 6823403268866048.0000\n",
            "Epoch 675/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1768510766186496.0000 - mse: 1768510766186496.0000 - val_loss: 6820736631046144.0000 - val_mse: 6820736631046144.0000\n",
            "Epoch 676/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1765443354230784.0000 - mse: 1765443354230784.0000 - val_loss: 6818092541804544.0000 - val_mse: 6818092541804544.0000\n",
            "Epoch 677/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1762376210710528.0000 - mse: 1762376210710528.0000 - val_loss: 6815425903984640.0000 - val_mse: 6815425903984640.0000\n",
            "Epoch 678/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1759305845964800.0000 - mse: 1759305845964800.0000 - val_loss: 6812797383999488.0000 - val_mse: 6812797383999488.0000\n",
            "Epoch 679/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1756256016531456.0000 - mse: 1756256016531456.0000 - val_loss: 6810217719267328.0000 - val_mse: 6810217719267328.0000\n",
            "Epoch 680/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1753190886277120.0000 - mse: 1753190886277120.0000 - val_loss: 6807593494249472.0000 - val_mse: 6807593494249472.0000\n",
            "Epoch 681/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1750136761876480.0000 - mse: 1750136761876480.0000 - val_loss: 6804939741331456.0000 - val_mse: 6804939741331456.0000\n",
            "Epoch 682/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1747084516524032.0000 - mse: 1747084516524032.0000 - val_loss: 6802336991150080.0000 - val_mse: 6802336991150080.0000\n",
            "Epoch 683/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1744036297703424.0000 - mse: 1744036297703424.0000 - val_loss: 6799667132104704.0000 - val_mse: 6799667132104704.0000\n",
            "Epoch 684/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1740986334052352.0000 - mse: 1740986334052352.0000 - val_loss: 6797115921530880.0000 - val_mse: 6797115921530880.0000\n",
            "Epoch 685/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1737944826118144.0000 - mse: 1737944826118144.0000 - val_loss: 6794483643449344.0000 - val_mse: 6794483643449344.0000\n",
            "Epoch 686/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1734903318183936.0000 - mse: 1734903318183936.0000 - val_loss: 6791885725106176.0000 - val_mse: 6791885725106176.0000\n",
            "Epoch 687/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1731868118482944.0000 - mse: 1731868118482944.0000 - val_loss: 6789282438053888.0000 - val_mse: 6789282438053888.0000\n",
            "Epoch 688/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1728829429121024.0000 - mse: 1728829429121024.0000 - val_loss: 6786683445968896.0000 - val_mse: 6786683445968896.0000\n",
            "Epoch 689/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1725795974250496.0000 - mse: 1725795974250496.0000 - val_loss: 6784074253336576.0000 - val_mse: 6784074253336576.0000\n",
            "Epoch 690/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1722763190468608.0000 - mse: 1722763190468608.0000 - val_loss: 6781460765736960.0000 - val_mse: 6781460765736960.0000\n",
            "Epoch 691/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1719733627912192.0000 - mse: 1719733627912192.0000 - val_loss: 6778873047941120.0000 - val_mse: 6778873047941120.0000\n",
            "Epoch 692/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1716712789508096.0000 - mse: 1716712789508096.0000 - val_loss: 6776301436272640.0000 - val_mse: 6776301436272640.0000\n",
            "Epoch 693/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1713685777088512.0000 - mse: 1713685777088512.0000 - val_loss: 6773706739154944.0000 - val_mse: 6773706739154944.0000\n",
            "Epoch 694/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1710669770522624.0000 - mse: 1710669770522624.0000 - val_loss: 6771114189520896.0000 - val_mse: 6771114189520896.0000\n",
            "Epoch 695/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1707651482255360.0000 - mse: 1707651482255360.0000 - val_loss: 6768586601267200.0000 - val_mse: 6768586601267200.0000\n",
            "Epoch 696/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1704641381269504.0000 - mse: 1704641381269504.0000 - val_loss: 6765951638831104.0000 - val_mse: 6765951638831104.0000\n",
            "Epoch 697/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1701631682936832.0000 - mse: 1701631682936832.0000 - val_loss: 6763392912064512.0000 - val_mse: 6763392912064512.0000\n",
            "Epoch 698/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1698622118821888.0000 - mse: 1698622118821888.0000 - val_loss: 6760818079170560.0000 - val_mse: 6760818079170560.0000\n",
            "Epoch 699/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1695619131375616.0000 - mse: 1695619131375616.0000 - val_loss: 6758266331725824.0000 - val_mse: 6758266331725824.0000\n",
            "Epoch 700/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1692616949235712.0000 - mse: 1692616949235712.0000 - val_loss: 6755710289313792.0000 - val_mse: 6755710289313792.0000\n",
            "Epoch 701/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1689614498660352.0000 - mse: 1689614498660352.0000 - val_loss: 6753142435741696.0000 - val_mse: 6753142435741696.0000\n",
            "Epoch 702/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1686615806181376.0000 - mse: 1686615806181376.0000 - val_loss: 6750560623525888.0000 - val_mse: 6750560623525888.0000\n",
            "Epoch 703/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1683625435201536.0000 - mse: 1683625435201536.0000 - val_loss: 6748038403981312.0000 - val_mse: 6748038403981312.0000\n",
            "Epoch 704/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1680632111431680.0000 - mse: 1680632111431680.0000 - val_loss: 6745512426340352.0000 - val_mse: 6745512426340352.0000\n",
            "Epoch 705/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1677641069363200.0000 - mse: 1677641069363200.0000 - val_loss: 6742959605153792.0000 - val_mse: 6742959605153792.0000\n",
            "Epoch 706/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1674660764712960.0000 - mse: 1674660764712960.0000 - val_loss: 6740407857709056.0000 - val_mse: 6740407857709056.0000\n",
            "Epoch 707/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1671677507272704.0000 - mse: 1671677507272704.0000 - val_loss: 6737871679520768.0000 - val_mse: 6737871679520768.0000\n",
            "Epoch 708/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1668693578743808.0000 - mse: 1668693578743808.0000 - val_loss: 6735294162272256.0000 - val_mse: 6735294162272256.0000\n",
            "Epoch 709/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1665717032189952.0000 - mse: 1665717032189952.0000 - val_loss: 6732812208046080.0000 - val_mse: 6732812208046080.0000\n",
            "Epoch 710/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1662746525433856.0000 - mse: 1662746525433856.0000 - val_loss: 6730300189048832.0000 - val_mse: 6730300189048832.0000\n",
            "Epoch 711/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1659776421330944.0000 - mse: 1659776421330944.0000 - val_loss: 6727762937118720.0000 - val_mse: 6727762937118720.0000\n",
            "Epoch 712/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1656804303962112.0000 - mse: 1656804303962112.0000 - val_loss: 6725253065605120.0000 - val_mse: 6725253065605120.0000\n",
            "Epoch 713/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1653837421084672.0000 - mse: 1653837421084672.0000 - val_loss: 6722716887416832.0000 - val_mse: 6722716887416832.0000\n",
            "Epoch 714/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1650875101609984.0000 - mse: 1650875101609984.0000 - val_loss: 6720214532096000.0000 - val_mse: 6720214532096000.0000\n",
            "Epoch 715/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1647912916353024.0000 - mse: 1647912916353024.0000 - val_loss: 6717671911456768.0000 - val_mse: 6717671911456768.0000\n",
            "Epoch 716/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1644958113071104.0000 - mse: 1644958113071104.0000 - val_loss: 6715157744975872.0000 - val_mse: 6715157744975872.0000\n",
            "Epoch 717/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1641998477950976.0000 - mse: 1641998477950976.0000 - val_loss: 6712643578494976.0000 - val_mse: 6712643578494976.0000\n",
            "Epoch 718/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1639046359023616.0000 - mse: 1639046359023616.0000 - val_loss: 6710194373394432.0000 - val_mse: 6710194373394432.0000\n",
            "Epoch 719/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1636096253362176.0000 - mse: 1636096253362176.0000 - val_loss: 6707697923653632.0000 - val_mse: 6707697923653632.0000\n",
            "Epoch 720/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1633154066546688.0000 - mse: 1633154066546688.0000 - val_loss: 6705184294043648.0000 - val_mse: 6705184294043648.0000\n",
            "Epoch 721/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1630210000683008.0000 - mse: 1630210000683008.0000 - val_loss: 6702695897366528.0000 - val_mse: 6702695897366528.0000\n",
            "Epoch 722/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1627265397948416.0000 - mse: 1627265397948416.0000 - val_loss: 6700228975525888.0000 - val_mse: 6700228975525888.0000\n",
            "Epoch 723/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1624330056237056.0000 - mse: 1624330056237056.0000 - val_loss: 6697726620205056.0000 - val_mse: 6697726620205056.0000\n",
            "Epoch 724/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1621396190920704.0000 - mse: 1621396190920704.0000 - val_loss: 6695246813462528.0000 - val_mse: 6695246813462528.0000\n",
            "Epoch 725/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1618458299072512.0000 - mse: 1618458299072512.0000 - val_loss: 6692774522912768.0000 - val_mse: 6692774522912768.0000\n",
            "Epoch 726/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1615531144642560.0000 - mse: 1615531144642560.0000 - val_loss: 6690296326782976.0000 - val_mse: 6690296326782976.0000\n",
            "Epoch 727/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1612602648035328.0000 - mse: 1612602648035328.0000 - val_loss: 6687812225073152.0000 - val_mse: 6687812225073152.0000\n",
            "Epoch 728/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1609680459661312.0000 - mse: 1609680459661312.0000 - val_loss: 6685323291525120.0000 - val_mse: 6685323291525120.0000\n",
            "Epoch 729/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1606767934963712.0000 - mse: 1606767934963712.0000 - val_loss: 6682875160166400.0000 - val_mse: 6682875160166400.0000\n",
            "Epoch 730/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1603845746589696.0000 - mse: 1603845746589696.0000 - val_loss: 6680380857909248.0000 - val_mse: 6680380857909248.0000\n",
            "Epoch 731/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1600924095086592.0000 - mse: 1600924095086592.0000 - val_loss: 6677919841648640.0000 - val_mse: 6677919841648640.0000\n",
            "Epoch 732/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1598013046784000.0000 - mse: 1598013046784000.0000 - val_loss: 6675472784031744.0000 - val_mse: 6675472784031744.0000\n",
            "Epoch 733/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1595103474876416.0000 - mse: 1595103474876416.0000 - val_loss: 6673011767771136.0000 - val_mse: 6673011767771136.0000\n",
            "Epoch 734/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1592197661065216.0000 - mse: 1592197661065216.0000 - val_loss: 6670580816281600.0000 - val_mse: 6670580816281600.0000\n",
            "Epoch 735/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1589293055213568.0000 - mse: 1589293055213568.0000 - val_loss: 6668148791050240.0000 - val_mse: 6668148791050240.0000\n",
            "Epoch 736/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1586395294466048.0000 - mse: 1586395294466048.0000 - val_loss: 6665678111113216.0000 - val_mse: 6665678111113216.0000\n",
            "Epoch 737/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1583493507186688.0000 - mse: 1583493507186688.0000 - val_loss: 6663219242336256.0000 - val_mse: 6663219242336256.0000\n",
            "Epoch 738/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1580596014874624.0000 - mse: 1580596014874624.0000 - val_loss: 6660757152333824.0000 - val_mse: 6660757152333824.0000\n",
            "Epoch 739/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 1577708991545344.0000 - mse: 1577708991545344.0000 - val_loss: 6658280029945856.0000 - val_mse: 6658280029945856.0000\n",
            "Epoch 740/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1574813915152384.0000 - mse: 1574813915152384.0000 - val_loss: 6655863037100032.0000 - val_mse: 6655863037100032.0000\n",
            "Epoch 741/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1571928368218112.0000 - mse: 1571928368218112.0000 - val_loss: 6653464834736128.0000 - val_mse: 6653464834736128.0000\n",
            "Epoch 742/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1569047250468864.0000 - mse: 1569047250468864.0000 - val_loss: 6651037641342976.0000 - val_mse: 6651037641342976.0000\n",
            "Epoch 743/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1566161300881408.0000 - mse: 1566161300881408.0000 - val_loss: 6648607226724352.0000 - val_mse: 6648607226724352.0000\n",
            "Epoch 744/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1563285954494464.0000 - mse: 1563285954494464.0000 - val_loss: 6646154263527424.0000 - val_mse: 6646154263527424.0000\n",
            "Epoch 745/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1560410071236608.0000 - mse: 1560410071236608.0000 - val_loss: 6643720090812416.0000 - val_mse: 6643720090812416.0000\n",
            "Epoch 746/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1557536603897856.0000 - mse: 1557536603897856.0000 - val_loss: 6641297192386560.0000 - val_mse: 6641297192386560.0000\n",
            "Epoch 747/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1554664210300928.0000 - mse: 1554664210300928.0000 - val_loss: 6638871072735232.0000 - val_mse: 6638871072735232.0000\n",
            "Epoch 748/2000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 1551797185413120.0000 - mse: 1551797185413120.0000 - val_loss: 6636457301114880.0000 - val_mse: 6636457301114880.0000\n",
            "Epoch 749/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1548934052839424.0000 - mse: 1548934052839424.0000 - val_loss: 6634069299298304.0000 - val_mse: 6634069299298304.0000\n",
            "Epoch 750/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1546073336184832.0000 - mse: 1546073336184832.0000 - val_loss: 6631706530414592.0000 - val_mse: 6631706530414592.0000\n",
            "Epoch 751/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1543212619530240.0000 - mse: 1543212619530240.0000 - val_loss: 6629292758794240.0000 - val_mse: 6629292758794240.0000\n",
            "Epoch 752/2000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1540361432334336.0000 - mse: 1540361432334336.0000 - val_loss: 6626898314526720.0000 - val_mse: 6626898314526720.0000\n",
            "Epoch 753/2000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 1537502594727936.0000 - mse: 1537502594727936.0000 - val_loss: 6624488837873664.0000 - val_mse: 6624488837873664.0000\n",
            "Epoch 754/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1534653420797952.0000 - mse: 1534653420797952.0000 - val_loss: 6622090635509760.0000 - val_mse: 6622090635509760.0000\n",
            "Epoch 755/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 1531800354553856.0000 - mse: 1531800354553856.0000 - val_loss: 6619708539273216.0000 - val_mse: 6619708539273216.0000\n",
            "Epoch 756/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1528961918042112.0000 - mse: 1528961918042112.0000 - val_loss: 6617296378265600.0000 - val_mse: 6617296378265600.0000\n",
            "Epoch 757/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1526121736699904.0000 - mse: 1526121736699904.0000 - val_loss: 6614886901612544.0000 - val_mse: 6614886901612544.0000\n",
            "Epoch 758/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1523280884269056.0000 - mse: 1523280884269056.0000 - val_loss: 6612533259534336.0000 - val_mse: 6612533259534336.0000\n",
            "Epoch 759/2000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1520445534765056.0000 - mse: 1520445534765056.0000 - val_loss: 6610131299074048.0000 - val_mse: 6610131299074048.0000\n",
            "Epoch 760/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1517611661656064.0000 - mse: 1517611661656064.0000 - val_loss: 6607809332379648.0000 - val_mse: 6607809332379648.0000\n",
            "Epoch 761/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 1514783828344832.0000 - mse: 1514783828344832.0000 - val_loss: 6605421330563072.0000 - val_mse: 6605421330563072.0000\n",
            "Epoch 762/2000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 1511957068775424.0000 - mse: 1511957068775424.0000 - val_loss: 6603042455552000.0000 - val_mse: 6603042455552000.0000\n",
            "Epoch 763/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 1509128698593280.0000 - mse: 1509128698593280.0000 - val_loss: 6600658748702720.0000 - val_mse: 6600658748702720.0000\n",
            "Epoch 764/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1506313347530752.0000 - mse: 1506313347530752.0000 - val_loss: 6598281484304384.0000 - val_mse: 6598281484304384.0000\n",
            "Epoch 765/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1503487393267712.0000 - mse: 1503487393267712.0000 - val_loss: 6595917104807936.0000 - val_mse: 6595917104807936.0000\n",
            "Epoch 766/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1500668820979712.0000 - mse: 1500668820979712.0000 - val_loss: 6593574200147968.0000 - val_mse: 6593574200147968.0000\n",
            "Epoch 767/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1497860986109952.0000 - mse: 1497860986109952.0000 - val_loss: 6591221631811584.0000 - val_mse: 6591221631811584.0000\n",
            "Epoch 768/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1495052480151552.0000 - mse: 1495052480151552.0000 - val_loss: 6588861547282432.0000 - val_mse: 6588861547282432.0000\n",
            "Epoch 769/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1492245450588160.0000 - mse: 1492245450588160.0000 - val_loss: 6586520790106112.0000 - val_mse: 6586520790106112.0000\n",
            "Epoch 770/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1489434931363840.0000 - mse: 1489434931363840.0000 - val_loss: 6584178959187968.0000 - val_mse: 6584178959187968.0000\n",
            "Epoch 771/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 1486639712960512.0000 - mse: 1486639712960512.0000 - val_loss: 6581804916015104.0000 - val_mse: 6581804916015104.0000\n",
            "Epoch 772/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1483841139113984.0000 - mse: 1483841139113984.0000 - val_loss: 6579462011355136.0000 - val_mse: 6579462011355136.0000\n",
            "Epoch 773/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1481046726017024.0000 - mse: 1481046726017024.0000 - val_loss: 6577136286564352.0000 - val_mse: 6577136286564352.0000\n",
            "Epoch 774/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1478248017952768.0000 - mse: 1478248017952768.0000 - val_loss: 6574791234420736.0000 - val_mse: 6574791234420736.0000\n",
            "Epoch 775/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1475465684451328.0000 - mse: 1475465684451328.0000 - val_loss: 6572442961051648.0000 - val_mse: 6572442961051648.0000\n",
            "Epoch 776/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1472672613531648.0000 - mse: 1472672613531648.0000 - val_loss: 6570120994357248.0000 - val_mse: 6570120994357248.0000\n",
            "Epoch 777/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1469888400982016.0000 - mse: 1469888400982016.0000 - val_loss: 6567797953921024.0000 - val_mse: 6567797953921024.0000\n",
            "Epoch 778/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1467109288706048.0000 - mse: 1467109288706048.0000 - val_loss: 6565459344228352.0000 - val_mse: 6565459344228352.0000\n",
            "Epoch 779/2000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1464328028946432.0000 - mse: 1464328028946432.0000 - val_loss: 6563128787599360.0000 - val_mse: 6563128787599360.0000\n",
            "Epoch 780/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 1461553480073216.0000 - mse: 1461553480073216.0000 - val_loss: 6560792325390336.0000 - val_mse: 6560792325390336.0000\n",
            "Epoch 781/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1458780407595008.0000 - mse: 1458780407595008.0000 - val_loss: 6558488612306944.0000 - val_mse: 6558488612306944.0000\n",
            "Epoch 782/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1456010019471360.0000 - mse: 1456010019471360.0000 - val_loss: 6556156445065216.0000 - val_mse: 6556156445065216.0000\n",
            "Epoch 783/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1453243792097280.0000 - mse: 1453243792097280.0000 - val_loss: 6553828572790784.0000 - val_mse: 6553828572790784.0000\n",
            "Epoch 784/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1450480517513216.0000 - mse: 1450480517513216.0000 - val_loss: 6551525396578304.0000 - val_mse: 6551525396578304.0000\n",
            "Epoch 785/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1447718182453248.0000 - mse: 1447718182453248.0000 - val_loss: 6549267317522432.0000 - val_mse: 6549267317522432.0000\n",
            "Epoch 786/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1444961618755584.0000 - mse: 1444961618755584.0000 - val_loss: 6546943203344384.0000 - val_mse: 6546943203344384.0000\n",
            "Epoch 787/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1442206263017472.0000 - mse: 1442206263017472.0000 - val_loss: 6544613720457216.0000 - val_mse: 6544613720457216.0000\n",
            "Epoch 788/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1439457886601216.0000 - mse: 1439457886601216.0000 - val_loss: 6542356715143168.0000 - val_mse: 6542356715143168.0000\n",
            "Epoch 789/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1436704007258112.0000 - mse: 1436704007258112.0000 - val_loss: 6540034748448768.0000 - val_mse: 6540034748448768.0000\n",
            "Epoch 790/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1433958315196416.0000 - mse: 1433958315196416.0000 - val_loss: 6537738551558144.0000 - val_mse: 6537738551558144.0000\n",
            "Epoch 791/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1431215441707008.0000 - mse: 1431215441707008.0000 - val_loss: 6535427859152896.0000 - val_mse: 6535427859152896.0000\n",
            "Epoch 792/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1428475252572160.0000 - mse: 1428475252572160.0000 - val_loss: 6533126830424064.0000 - val_mse: 6533126830424064.0000\n",
            "Epoch 793/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1425732647518208.0000 - mse: 1425732647518208.0000 - val_loss: 6530835465371648.0000 - val_mse: 6530835465371648.0000\n",
            "Epoch 794/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1422997558657024.0000 - mse: 1422997558657024.0000 - val_loss: 6528576312573952.0000 - val_mse: 6528576312573952.0000\n",
            "Epoch 795/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1420267570069504.0000 - mse: 1420267570069504.0000 - val_loss: 6526294611197952.0000 - val_mse: 6526294611197952.0000\n",
            "Epoch 796/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1417543487062016.0000 - mse: 1417543487062016.0000 - val_loss: 6524003783016448.0000 - val_mse: 6524003783016448.0000\n",
            "Epoch 797/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 1414816451264512.0000 - mse: 1414816451264512.0000 - val_loss: 6521708659867648.0000 - val_mse: 6521708659867648.0000\n",
            "Epoch 798/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1412090757644288.0000 - mse: 1412090757644288.0000 - val_loss: 6519405483655168.0000 - val_mse: 6519405483655168.0000\n",
            "Epoch 799/2000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 1409371238039552.0000 - mse: 1409371238039552.0000 - val_loss: 6517149015212032.0000 - val_mse: 6517149015212032.0000\n",
            "Epoch 800/2000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 1406650778910720.0000 - mse: 1406650778910720.0000 - val_loss: 6514897915478016.0000 - val_mse: 6514897915478016.0000\n",
            "Epoch 801/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1403941191417856.0000 - mse: 1403941191417856.0000 - val_loss: 6512637688938496.0000 - val_mse: 6512637688938496.0000\n",
            "Epoch 802/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1401221537595392.0000 - mse: 1401221537595392.0000 - val_loss: 6510358671917056.0000 - val_mse: 6510358671917056.0000\n",
            "Epoch 803/2000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1398516916158464.0000 - mse: 1398516916158464.0000 - val_loss: 6508109719666688.0000 - val_mse: 6508109719666688.0000\n",
            "Epoch 804/2000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1395811220979712.0000 - mse: 1395811220979712.0000 - val_loss: 6505829628903424.0000 - val_mse: 6505829628903424.0000\n",
            "Epoch 805/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1393106196889600.0000 - mse: 1393106196889600.0000 - val_loss: 6503579602911232.0000 - val_mse: 6503579602911232.0000\n",
            "Epoch 806/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1390407346814976.0000 - mse: 1390407346814976.0000 - val_loss: 6501303270244352.0000 - val_mse: 6501303270244352.0000\n",
            "Epoch 807/2000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 1387709302046720.0000 - mse: 1387709302046720.0000 - val_loss: 6499081698410496.0000 - val_mse: 6499081698410496.0000\n",
            "Epoch 808/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 1385016357552128.0000 - mse: 1385016357552128.0000 - val_loss: 6496775837843456.0000 - val_mse: 6496775837843456.0000\n",
            "Epoch 809/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 1382320728702976.0000 - mse: 1382320728702976.0000 - val_loss: 6494530106818560.0000 - val_mse: 6494530106818560.0000\n",
            "Epoch 810/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1379636105707520.0000 - mse: 1379636105707520.0000 - val_loss: 6492291891986432.0000 - val_mse: 6492291891986432.0000\n",
            "Epoch 811/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1376951482712064.0000 - mse: 1376951482712064.0000 - val_loss: 6490100921794560.0000 - val_mse: 6490100921794560.0000\n",
            "Epoch 812/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1374268336111616.0000 - mse: 1374268336111616.0000 - val_loss: 6487840695255040.0000 - val_mse: 6487840695255040.0000\n",
            "Epoch 813/2000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1371589618696192.0000 - mse: 1371589618696192.0000 - val_loss: 6485585837424640.0000 - val_mse: 6485585837424640.0000\n",
            "Epoch 814/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1368914659377152.0000 - mse: 1368914659377152.0000 - val_loss: 6483373392396288.0000 - val_mse: 6483373392396288.0000\n",
            "Epoch 815/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1366239834275840.0000 - mse: 1366239834275840.0000 - val_loss: 6481118534565888.0000 - val_mse: 6481118534565888.0000\n",
            "Epoch 816/2000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1363565948698624.0000 - mse: 1363565948698624.0000 - val_loss: 6478880856604672.0000 - val_mse: 6478880856604672.0000\n",
            "Epoch 817/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1360899579314176.0000 - mse: 1360899579314176.0000 - val_loss: 6476658747899904.0000 - val_mse: 6476658747899904.0000\n",
            "Epoch 818/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 1358238578638848.0000 - mse: 1358238578638848.0000 - val_loss: 6474457577160704.0000 - val_mse: 6474457577160704.0000\n",
            "Epoch 819/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1355574088302592.0000 - mse: 1355574088302592.0000 - val_loss: 6472216677974016.0000 - val_mse: 6472216677974016.0000\n",
            "Epoch 820/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 1352915771981824.0000 - mse: 1352915771981824.0000 - val_loss: 6469986516205568.0000 - val_mse: 6469986516205568.0000\n",
            "Epoch 821/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 1350254100217856.0000 - mse: 1350254100217856.0000 - val_loss: 6467784271724544.0000 - val_mse: 6467784271724544.0000\n",
            "Epoch 822/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1347605313355776.0000 - mse: 1347605313355776.0000 - val_loss: 6465549814988800.0000 - val_mse: 6465549814988800.0000\n",
            "Epoch 823/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 1344953707921408.0000 - mse: 1344953707921408.0000 - val_loss: 6463337906831360.0000 - val_mse: 6463337906831360.0000\n",
            "Epoch 824/2000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 1342302102487040.0000 - mse: 1342302102487040.0000 - val_loss: 6461117408739328.0000 - val_mse: 6461117408739328.0000\n",
            "Epoch 825/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1339665663655936.0000 - mse: 1339665663655936.0000 - val_loss: 6458883488874496.0000 - val_mse: 6458883488874496.0000\n",
            "Epoch 826/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 1337021977067520.0000 - mse: 1337021977067520.0000 - val_loss: 6456698961133568.0000 - val_mse: 6456698961133568.0000\n",
            "Epoch 827/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 1334382988099584.0000 - mse: 1334382988099584.0000 - val_loss: 6454502622232576.0000 - val_mse: 6454502622232576.0000\n",
            "Epoch 828/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1331749636276224.0000 - mse: 1331749636276224.0000 - val_loss: 6452278366044160.0000 - val_mse: 6452278366044160.0000\n",
            "Epoch 829/2000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1329108768260096.0000 - mse: 1329108768260096.0000 - val_loss: 6450111555043328.0000 - val_mse: 6450111555043328.0000\n",
            "Epoch 830/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1326484543242240.0000 - mse: 1326484543242240.0000 - val_loss: 6447877635178496.0000 - val_mse: 6447877635178496.0000\n",
            "Epoch 831/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1323853607337984.0000 - mse: 1323853607337984.0000 - val_loss: 6445703844855808.0000 - val_mse: 6445703844855808.0000\n",
            "Epoch 832/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1321233945722880.0000 - mse: 1321233945722880.0000 - val_loss: 6443494621052928.0000 - val_mse: 6443494621052928.0000\n",
            "Epoch 833/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1318611599753216.0000 - mse: 1318611599753216.0000 - val_loss: 6441289155346432.0000 - val_mse: 6441289155346432.0000\n",
            "Epoch 834/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1315992877662208.0000 - mse: 1315992877662208.0000 - val_loss: 6439156704083968.0000 - val_mse: 6439156704083968.0000\n",
            "Epoch 835/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1313380866457600.0000 - mse: 1313380866457600.0000 - val_loss: 6436967881375744.0000 - val_mse: 6436967881375744.0000\n",
            "Epoch 836/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1310767915728896.0000 - mse: 1310767915728896.0000 - val_loss: 6434764563152896.0000 - val_mse: 6434764563152896.0000\n",
            "Epoch 837/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1308159394185216.0000 - mse: 1308159394185216.0000 - val_loss: 6432581646024704.0000 - val_mse: 6432581646024704.0000\n",
            "Epoch 838/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1305556375568384.0000 - mse: 1305556375568384.0000 - val_loss: 6430387991478272.0000 - val_mse: 6430387991478272.0000\n",
            "Epoch 839/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1302947317153792.0000 - mse: 1302947317153792.0000 - val_loss: 6428202389995520.0000 - val_mse: 6428202389995520.0000\n",
            "Epoch 840/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1300351546294272.0000 - mse: 1300351546294272.0000 - val_loss: 6426061348798464.0000 - val_mse: 6426061348798464.0000\n",
            "Epoch 841/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1297748661895168.0000 - mse: 1297748661895168.0000 - val_loss: 6423889705959424.0000 - val_mse: 6423889705959424.0000\n",
            "Epoch 842/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1295158259744768.0000 - mse: 1295158259744768.0000 - val_loss: 6421736316731392.0000 - val_mse: 6421736316731392.0000\n",
            "Epoch 843/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1292566783852544.0000 - mse: 1292566783852544.0000 - val_loss: 6419522261090304.0000 - val_mse: 6419522261090304.0000\n",
            "Epoch 844/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1289976247484416.0000 - mse: 1289976247484416.0000 - val_loss: 6417348470767616.0000 - val_mse: 6417348470767616.0000\n",
            "Epoch 845/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1287391482478592.0000 - mse: 1287391482478592.0000 - val_loss: 6415174143574016.0000 - val_mse: 6415174143574016.0000\n",
            "Epoch 846/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1284808730738688.0000 - mse: 1284808730738688.0000 - val_loss: 6413025586184192.0000 - val_mse: 6413025586184192.0000\n",
            "Epoch 847/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1282230005530624.0000 - mse: 1282230005530624.0000 - val_loss: 6410854480216064.0000 - val_mse: 6410854480216064.0000\n",
            "Epoch 848/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1279658930733056.0000 - mse: 1279658930733056.0000 - val_loss: 6408754241208320.0000 - val_mse: 6408754241208320.0000\n",
            "Epoch 849/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1277080205524992.0000 - mse: 1277080205524992.0000 - val_loss: 6406600851980288.0000 - val_mse: 6406600851980288.0000\n",
            "Epoch 850/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1274508996509696.0000 - mse: 1274508996509696.0000 - val_loss: 6404436188463104.0000 - val_mse: 6404436188463104.0000\n",
            "Epoch 851/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1271947988041728.0000 - mse: 1271947988041728.0000 - val_loss: 6402316085231616.0000 - val_mse: 6402316085231616.0000\n",
            "Epoch 852/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1269377584332800.0000 - mse: 1269377584332800.0000 - val_loss: 6400104177074176.0000 - val_mse: 6400104177074176.0000\n",
            "Epoch 853/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1266817649606656.0000 - mse: 1266817649606656.0000 - val_loss: 6397977094520832.0000 - val_mse: 6397977094520832.0000\n",
            "Epoch 854/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1264259325493248.0000 - mse: 1264259325493248.0000 - val_loss: 6395803841069056.0000 - val_mse: 6395803841069056.0000\n",
            "Epoch 855/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1261701538250752.0000 - mse: 1261701538250752.0000 - val_loss: 6393654209937408.0000 - val_mse: 6393654209937408.0000\n",
            "Epoch 856/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1259146301145088.0000 - mse: 1259146301145088.0000 - val_loss: 6391531422351360.0000 - val_mse: 6391531422351360.0000\n",
            "Epoch 857/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1256599251320832.0000 - mse: 1256599251320832.0000 - val_loss: 6389422593409024.0000 - val_mse: 6389422593409024.0000\n",
            "Epoch 858/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1254050993537024.0000 - mse: 1254050993537024.0000 - val_loss: 6387272962277376.0000 - val_mse: 6387272962277376.0000\n",
            "Epoch 859/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1251508641333248.0000 - mse: 1251508641333248.0000 - val_loss: 6385173260140544.0000 - val_mse: 6385173260140544.0000\n",
            "Epoch 860/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1248966154911744.0000 - mse: 1248966154911744.0000 - val_loss: 6383024165879808.0000 - val_mse: 6383024165879808.0000\n",
            "Epoch 861/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1246425010667520.0000 - mse: 1246425010667520.0000 - val_loss: 6380911041970176.0000 - val_mse: 6380911041970176.0000\n",
            "Epoch 862/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1243895006494720.0000 - mse: 1243895006494720.0000 - val_loss: 6378759263354880.0000 - val_mse: 6378759263354880.0000\n",
            "Epoch 863/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1241363391709184.0000 - mse: 1241363391709184.0000 - val_loss: 6376625738350592.0000 - val_mse: 6376625738350592.0000\n",
            "Epoch 864/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1238835535020032.0000 - mse: 1238835535020032.0000 - val_loss: 6374522278117376.0000 - val_mse: 6374522278117376.0000\n",
            "Epoch 865/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1236304188669952.0000 - mse: 1236304188669952.0000 - val_loss: 6372404322369536.0000 - val_mse: 6372404322369536.0000\n",
            "Epoch 866/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1233785727221760.0000 - mse: 1233785727221760.0000 - val_loss: 6370269723623424.0000 - val_mse: 6370269723623424.0000\n",
            "Epoch 867/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1231260823322624.0000 - mse: 1231260823322624.0000 - val_loss: 6368189348839424.0000 - val_mse: 6368189348839424.0000\n",
            "Epoch 868/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1228744777793536.0000 - mse: 1228744777793536.0000 - val_loss: 6366052602609664.0000 - val_mse: 6366052602609664.0000\n",
            "Epoch 869/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1226228061175808.0000 - mse: 1226228061175808.0000 - val_loss: 6363938941829120.0000 - val_mse: 6363938941829120.0000\n",
            "Epoch 870/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1223721276669952.0000 - mse: 1223721276669952.0000 - val_loss: 6361804343083008.0000 - val_mse: 6361804343083008.0000\n",
            "Epoch 871/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1221214089510912.0000 - mse: 1221214089510912.0000 - val_loss: 6359701419720704.0000 - val_mse: 6359701419720704.0000\n",
            "Epoch 872/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1218707036569600.0000 - mse: 1218707036569600.0000 - val_loss: 6357618897453056.0000 - val_mse: 6357618897453056.0000\n",
            "Epoch 873/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1216202936418304.0000 - mse: 1216202936418304.0000 - val_loss: 6355484298706944.0000 - val_mse: 6355484298706944.0000\n",
            "Epoch 874/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1213708365725696.0000 - mse: 1213708365725696.0000 - val_loss: 6353424861888512.0000 - val_mse: 6353424861888512.0000\n",
            "Epoch 875/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1211210708025344.0000 - mse: 1211210708025344.0000 - val_loss: 6351348782071808.0000 - val_mse: 6351348782071808.0000\n",
            "Epoch 876/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1208714526720000.0000 - mse: 1208714526720000.0000 - val_loss: 6349214183325696.0000 - val_mse: 6349214183325696.0000\n",
            "Epoch 877/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1206226935349248.0000 - mse: 1206226935349248.0000 - val_loss: 6347141324734464.0000 - val_mse: 6347141324734464.0000\n",
            "Epoch 878/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1203741491462144.0000 - mse: 1203741491462144.0000 - val_loss: 6345018000277504.0000 - val_mse: 6345018000277504.0000\n",
            "Epoch 879/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1201253631655936.0000 - mse: 1201253631655936.0000 - val_loss: 6342934941138944.0000 - val_mse: 6342934941138944.0000\n",
            "Epoch 880/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1198769798381568.0000 - mse: 1198769798381568.0000 - val_loss: 6340814837907456.0000 - val_mse: 6340814837907456.0000\n",
            "Epoch 881/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1196290796945408.0000 - mse: 1196290796945408.0000 - val_loss: 6338744663670784.0000 - val_mse: 6338744663670784.0000\n",
            "Epoch 882/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1193819714355200.0000 - mse: 1193819714355200.0000 - val_loss: 6336678247530496.0000 - val_mse: 6336678247530496.0000\n",
            "Epoch 883/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1191345678974976.0000 - mse: 1191345678974976.0000 - val_loss: 6334582303490048.0000 - val_mse: 6334582303490048.0000\n",
            "Epoch 884/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1188878891352064.0000 - mse: 1188878891352064.0000 - val_loss: 6332518571704320.0000 - val_mse: 6332518571704320.0000\n",
            "Epoch 885/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1186413177470976.0000 - mse: 1186413177470976.0000 - val_loss: 6330445176242176.0000 - val_mse: 6330445176242176.0000\n",
            "Epoch 886/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1183950416379904.0000 - mse: 1183950416379904.0000 - val_loss: 6328362117103616.0000 - val_mse: 6328362117103616.0000\n",
            "Epoch 887/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1181487789506560.0000 - mse: 1181487789506560.0000 - val_loss: 6326295164092416.0000 - val_mse: 6326295164092416.0000\n",
            "Epoch 888/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1179034021003264.0000 - mse: 1179034021003264.0000 - val_loss: 6324227674210304.0000 - val_mse: 6324227674210304.0000\n",
            "Epoch 889/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1176579715629056.0000 - mse: 1176579715629056.0000 - val_loss: 6322160184328192.0000 - val_mse: 6322160184328192.0000\n",
            "Epoch 890/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1174130107875328.0000 - mse: 1174130107875328.0000 - val_loss: 6320077125189632.0000 - val_mse: 6320077125189632.0000\n",
            "Epoch 891/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1171676473589760.0000 - mse: 1171676473589760.0000 - val_loss: 6317984939245568.0000 - val_mse: 6317984939245568.0000\n",
            "Epoch 892/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1169234918899712.0000 - mse: 1169234918899712.0000 - val_loss: 6315945366650880.0000 - val_mse: 6315945366650880.0000\n",
            "Epoch 893/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1166793095774208.0000 - mse: 1166793095774208.0000 - val_loss: 6313893982896128.0000 - val_mse: 6313893982896128.0000\n",
            "Epoch 894/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1164349930471424.0000 - mse: 1164349930471424.0000 - val_loss: 6311813608112128.0000 - val_mse: 6311813608112128.0000\n",
            "Epoch 895/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1161912939184128.0000 - mse: 1161912939184128.0000 - val_loss: 6309753634422784.0000 - val_mse: 6309753634422784.0000\n",
            "Epoch 896/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1159478766469120.0000 - mse: 1159478766469120.0000 - val_loss: 6307726409859072.0000 - val_mse: 6307726409859072.0000\n",
            "Epoch 897/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1157050499334144.0000 - mse: 1157050499334144.0000 - val_loss: 6305670731137024.0000 - val_mse: 6305670731137024.0000\n",
            "Epoch 898/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1154624648118272.0000 - mse: 1154624648118272.0000 - val_loss: 6303579082063872.0000 - val_mse: 6303579082063872.0000\n",
            "Epoch 899/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1152196917854208.0000 - mse: 1152196917854208.0000 - val_loss: 6301538972598272.0000 - val_mse: 6301538972598272.0000\n",
            "Epoch 900/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1149778448613376.0000 - mse: 1149778448613376.0000 - val_loss: 6299495641907200.0000 - val_mse: 6299495641907200.0000\n",
            "Epoch 901/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1147361589985280.0000 - mse: 1147361589985280.0000 - val_loss: 6297445868765184.0000 - val_mse: 6297445868765184.0000\n",
            "Epoch 902/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1144945939316736.0000 - mse: 1144945939316736.0000 - val_loss: 6295429918490624.0000 - val_mse: 6295429918490624.0000\n",
            "Epoch 903/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1142531093954560.0000 - mse: 1142531093954560.0000 - val_loss: 6293374776639488.0000 - val_mse: 6293374776639488.0000\n",
            "Epoch 904/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1140122288390144.0000 - mse: 1140122288390144.0000 - val_loss: 6291335204044800.0000 - val_mse: 6291335204044800.0000\n",
            "Epoch 905/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1137713348608000.0000 - mse: 1137713348608000.0000 - val_loss: 6289303684513792.0000 - val_mse: 6289303684513792.0000\n",
            "Epoch 906/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1135315280461824.0000 - mse: 1135315280461824.0000 - val_loss: 6287259280080896.0000 - val_mse: 6287259280080896.0000\n",
            "Epoch 907/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1132917480751104.0000 - mse: 1132917480751104.0000 - val_loss: 6285219170615296.0000 - val_mse: 6285219170615296.0000\n",
            "Epoch 908/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1130513909678080.0000 - mse: 1130513909678080.0000 - val_loss: 6283233821982720.0000 - val_mse: 6283233821982720.0000\n",
            "Epoch 909/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1128120539152384.0000 - mse: 1128120539152384.0000 - val_loss: 6281183511969792.0000 - val_mse: 6281183511969792.0000\n",
            "Epoch 910/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1125727571279872.0000 - mse: 1125727571279872.0000 - val_loss: 6279136423182336.0000 - val_mse: 6279136423182336.0000\n",
            "Epoch 911/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1123340643205120.0000 - mse: 1123340643205120.0000 - val_loss: 6277143558356992.0000 - val_mse: 6277143558356992.0000\n",
            "Epoch 912/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 1120958546968576.0000 - mse: 1120958546968576.0000 - val_loss: 6275080363442176.0000 - val_mse: 6275080363442176.0000\n",
            "Epoch 913/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1118572893962240.0000 - mse: 1118572893962240.0000 - val_loss: 6273068708134912.0000 - val_mse: 6273068708134912.0000\n",
            "Epoch 914/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1116194153168896.0000 - mse: 1116194153168896.0000 - val_loss: 6271040946700288.0000 - val_mse: 6271040946700288.0000\n",
            "Epoch 915/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1113821720608768.0000 - mse: 1113821720608768.0000 - val_loss: 6268994394783744.0000 - val_mse: 6268994394783744.0000\n",
            "Epoch 916/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1111448415633408.0000 - mse: 1111448415633408.0000 - val_loss: 6266973075800064.0000 - val_mse: 6266973075800064.0000\n",
            "Epoch 917/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1109078264774656.0000 - mse: 1109078264774656.0000 - val_loss: 6264998464585728.0000 - val_mse: 6264998464585728.0000\n",
            "Epoch 918/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1106710194290688.0000 - mse: 1106710194290688.0000 - val_loss: 6262983051182080.0000 - val_mse: 6262983051182080.0000\n",
            "Epoch 919/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1104344741052416.0000 - mse: 1104344741052416.0000 - val_loss: 6260969785262080.0000 - val_mse: 6260969785262080.0000\n",
            "Epoch 920/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1101984992067584.0000 - mse: 1101984992067584.0000 - val_loss: 6258957593083904.0000 - val_mse: 6258957593083904.0000\n",
            "Epoch 921/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1099626518151168.0000 - mse: 1099626518151168.0000 - val_loss: 6256965802000384.0000 - val_mse: 6256965802000384.0000\n",
            "Epoch 922/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1097272204984320.0000 - mse: 1097272204984320.0000 - val_loss: 6254906365181952.0000 - val_mse: 6254906365181952.0000\n",
            "Epoch 923/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1094916348313600.0000 - mse: 1094916348313600.0000 - val_loss: 6252925311516672.0000 - val_mse: 6252925311516672.0000\n",
            "Epoch 924/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1092570088210432.0000 - mse: 1092570088210432.0000 - val_loss: 6250915266822144.0000 - val_mse: 6250915266822144.0000\n",
            "Epoch 925/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1090224834740224.0000 - mse: 1090224834740224.0000 - val_loss: 6248912738320384.0000 - val_mse: 6248912738320384.0000\n",
            "Epoch 926/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1087879648378880.0000 - mse: 1087879648378880.0000 - val_loss: 6246933832138752.0000 - val_mse: 6246933832138752.0000\n",
            "Epoch 927/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1085542984843264.0000 - mse: 1085542984843264.0000 - val_loss: 6244957610311680.0000 - val_mse: 6244957610311680.0000\n",
            "Epoch 928/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1083202026340352.0000 - mse: 1083202026340352.0000 - val_loss: 6242945418133504.0000 - val_mse: 6242945418133504.0000\n",
            "Epoch 929/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1080870798622720.0000 - mse: 1080870798622720.0000 - val_loss: 6240936984051712.0000 - val_mse: 6240936984051712.0000\n",
            "Epoch 930/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1078543194783744.0000 - mse: 1078543194783744.0000 - val_loss: 6238905464520704.0000 - val_mse: 6238905464520704.0000\n",
            "Epoch 931/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1076214450094080.0000 - mse: 1076214450094080.0000 - val_loss: 6236922263371776.0000 - val_mse: 6236922263371776.0000\n",
            "Epoch 932/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1073885369860096.0000 - mse: 1073885369860096.0000 - val_loss: 6234958389575680.0000 - val_mse: 6234958389575680.0000\n",
            "Epoch 933/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1071566423064576.0000 - mse: 1071566423064576.0000 - val_loss: 6232977335910400.0000 - val_mse: 6232977335910400.0000\n",
            "Epoch 934/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1069248080248832.0000 - mse: 1069248080248832.0000 - val_loss: 6231011314630656.0000 - val_mse: 6231011314630656.0000\n",
            "Epoch 935/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1066929871650816.0000 - mse: 1066929871650816.0000 - val_loss: 6229039924641792.0000 - val_mse: 6229039924641792.0000\n",
            "Epoch 936/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1064617031761920.0000 - mse: 1064617031761920.0000 - val_loss: 6227039543623680.0000 - val_mse: 6227039543623680.0000\n",
            "Epoch 937/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1062310030344192.0000 - mse: 1062310030344192.0000 - val_loss: 6225061711183872.0000 - val_mse: 6225061711183872.0000\n",
            "Epoch 938/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1060000747225088.0000 - mse: 1060000747225088.0000 - val_loss: 6223064014520320.0000 - val_mse: 6223064014520320.0000\n",
            "Epoch 939/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1057699986931712.0000 - mse: 1057699986931712.0000 - val_loss: 6221120541818880.0000 - val_mse: 6221120541818880.0000\n",
            "Epoch 940/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1055398891094016.0000 - mse: 1055398891094016.0000 - val_loss: 6219127140122624.0000 - val_mse: 6219127140122624.0000\n",
            "Epoch 941/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1053102895529984.0000 - mse: 1053102895529984.0000 - val_loss: 6217184741163008.0000 - val_mse: 6217184741163008.0000\n",
            "Epoch 942/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1050808309252096.0000 - mse: 1050808309252096.0000 - val_loss: 6215184360144896.0000 - val_mse: 6215184360144896.0000\n",
            "Epoch 943/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1048515534913536.0000 - mse: 1048515534913536.0000 - val_loss: 6213233371250688.0000 - val_mse: 6213233371250688.0000\n",
            "Epoch 944/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1046229538570240.0000 - mse: 1046229538570240.0000 - val_loss: 6211254465069056.0000 - val_mse: 6211254465069056.0000\n",
            "Epoch 945/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1043941730287616.0000 - mse: 1043941730287616.0000 - val_loss: 6209278780112896.0000 - val_mse: 6209278780112896.0000\n",
            "Epoch 946/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1041658216972288.0000 - mse: 1041658216972288.0000 - val_loss: 6207313832574976.0000 - val_mse: 6207313832574976.0000\n",
            "Epoch 947/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1039378864406528.0000 - mse: 1039378864406528.0000 - val_loss: 6205351569391616.0000 - val_mse: 6205351569391616.0000\n",
            "Epoch 948/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1037103404154880.0000 - mse: 1037103404154880.0000 - val_loss: 6203390916820992.0000 - val_mse: 6203390916820992.0000\n",
            "Epoch 949/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 1034831567781888.0000 - mse: 1034831567781888.0000 - val_loss: 6201453349699584.0000 - val_mse: 6201453349699584.0000\n",
            "Epoch 950/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1032560201170944.0000 - mse: 1032560201170944.0000 - val_loss: 6199521688158208.0000 - val_mse: 6199521688158208.0000\n",
            "Epoch 951/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1030293062418432.0000 - mse: 1030293062418432.0000 - val_loss: 6197563183071232.0000 - val_mse: 6197563183071232.0000\n",
            "Epoch 952/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1028029748871168.0000 - mse: 1028029748871168.0000 - val_loss: 6195590719340544.0000 - val_mse: 6195590719340544.0000\n",
            "Epoch 953/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 1025766636650496.0000 - mse: 1025766636650496.0000 - val_loss: 6193636509220864.0000 - val_mse: 6193636509220864.0000\n",
            "Epoch 954/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1023506678546432.0000 - mse: 1023506678546432.0000 - val_loss: 6191672098553856.0000 - val_mse: 6191672098553856.0000\n",
            "Epoch 955/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1021253431328768.0000 - mse: 1021253431328768.0000 - val_loss: 6189759227494400.0000 - val_mse: 6189759227494400.0000\n",
            "Epoch 956/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1018999043260416.0000 - mse: 1018999043260416.0000 - val_loss: 6187802333020160.0000 - val_mse: 6187802333020160.0000\n",
            "Epoch 957/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1016753379344384.0000 - mse: 1016753379344384.0000 - val_loss: 6185854028480512.0000 - val_mse: 6185854028480512.0000\n",
            "Epoch 958/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1014506574577664.0000 - mse: 1014506574577664.0000 - val_loss: 6183919682584576.0000 - val_mse: 6183919682584576.0000\n",
            "Epoch 959/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1012263662125056.0000 - mse: 1012263662125056.0000 - val_loss: 6181957419401216.0000 - val_mse: 6181957419401216.0000\n",
            "Epoch 960/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1010022561611776.0000 - mse: 1010022561611776.0000 - val_loss: 6180027905343488.0000 - val_mse: 6180027905343488.0000\n",
            "Epoch 961/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1007789178617856.0000 - mse: 1007789178617856.0000 - val_loss: 6178135972249600.0000 - val_mse: 6178135972249600.0000\n",
            "Epoch 962/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1005552373071872.0000 - mse: 1005552373071872.0000 - val_loss: 6176183909613568.0000 - val_mse: 6176183909613568.0000\n",
            "Epoch 963/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1003322479738880.0000 - mse: 1003322479738880.0000 - val_loss: 6174232920719360.0000 - val_mse: 6174232920719360.0000\n",
            "Epoch 964/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 1001093727256576.0000 - mse: 1001093727256576.0000 - val_loss: 6172296964210688.0000 - val_mse: 6172296964210688.0000\n",
            "Epoch 965/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 998870544809984.0000 - mse: 998870544809984.0000 - val_loss: 6170342754091008.0000 - val_mse: 6170342754091008.0000\n",
            "Epoch 966/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 996647362363392.0000 - mse: 996647362363392.0000 - val_loss: 6168472832704512.0000 - val_mse: 6168472832704512.0000\n",
            "Epoch 967/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 994431897436160.0000 - mse: 994431897436160.0000 - val_loss: 6166513790746624.0000 - val_mse: 6166513790746624.0000\n",
            "Epoch 968/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 992212607303680.0000 - mse: 992212607303680.0000 - val_loss: 6164613804589056.0000 - val_mse: 6164613804589056.0000\n",
            "Epoch 969/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 990002108432384.0000 - mse: 990002108432384.0000 - val_loss: 6162678921822208.0000 - val_mse: 6162678921822208.0000\n",
            "Epoch 970/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 987793622827008.0000 - mse: 987793622827008.0000 - val_loss: 6160781083148288.0000 - val_mse: 6160781083148288.0000\n",
            "Epoch 971/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 985586747834368.0000 - mse: 985586747834368.0000 - val_loss: 6158858011541504.0000 - val_mse: 6158858011541504.0000\n",
            "Epoch 972/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 983377456922624.0000 - mse: 983377456922624.0000 - val_loss: 6156894137745408.0000 - val_mse: 6156894137745408.0000\n",
            "Epoch 973/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 981181319348224.0000 - mse: 981181319348224.0000 - val_loss: 6154956033753088.0000 - val_mse: 6154956033753088.0000\n",
            "Epoch 974/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 978981222350848.0000 - mse: 978981222350848.0000 - val_loss: 6153081817399296.0000 - val_mse: 6153081817399296.0000\n",
            "Epoch 975/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 976789044199424.0000 - mse: 976789044199424.0000 - val_loss: 6151172167565312.0000 - val_mse: 6151172167565312.0000\n",
            "Epoch 976/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 974595590979584.0000 - mse: 974595590979584.0000 - val_loss: 6149252317184000.0000 - val_mse: 6149252317184000.0000\n",
            "Epoch 977/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 972409788170240.0000 - mse: 972409788170240.0000 - val_loss: 6147328708706304.0000 - val_mse: 6147328708706304.0000\n",
            "Epoch 978/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 970223247163392.0000 - mse: 970223247163392.0000 - val_loss: 6145413690163200.0000 - val_mse: 6145413690163200.0000\n",
            "Epoch 979/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 968043014389760.0000 - mse: 968043014389760.0000 - val_loss: 6143521757069312.0000 - val_mse: 6143521757069312.0000\n",
            "Epoch 980/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 965862311854080.0000 - mse: 965862311854080.0000 - val_loss: 6141622307782656.0000 - val_mse: 6141622307782656.0000\n",
            "Epoch 981/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 963687179354112.0000 - mse: 963687179354112.0000 - val_loss: 6139707289239552.0000 - val_mse: 6139707289239552.0000\n",
            "Epoch 982/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 961511979745280.0000 - mse: 961511979745280.0000 - val_loss: 6137829851660288.0000 - val_mse: 6137829851660288.0000\n",
            "Epoch 983/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 959345370071040.0000 - mse: 959345370071040.0000 - val_loss: 6135937918566400.0000 - val_mse: 6135937918566400.0000\n",
            "Epoch 984/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 957173525905408.0000 - mse: 957173525905408.0000 - val_loss: 6134022363152384.0000 - val_mse: 6134022363152384.0000\n",
            "Epoch 985/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 955008862388224.0000 - mse: 955008862388224.0000 - val_loss: 6132105733996544.0000 - val_mse: 6132105733996544.0000\n",
            "Epoch 986/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 952849634689024.0000 - mse: 952849634689024.0000 - val_loss: 6130196621033472.0000 - val_mse: 6130196621033472.0000\n",
            "Epoch 987/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 950693896650752.0000 - mse: 950693896650752.0000 - val_loss: 6128308446035968.0000 - val_mse: 6128308446035968.0000\n",
            "Epoch 988/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 948539433680896.0000 - mse: 948539433680896.0000 - val_loss: 6126434229682176.0000 - val_mse: 6126434229682176.0000\n",
            "Epoch 989/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 946388191936512.0000 - mse: 946388191936512.0000 - val_loss: 6124551960264704.0000 - val_mse: 6124551960264704.0000\n",
            "Epoch 990/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 944237285736448.0000 - mse: 944237285736448.0000 - val_loss: 6122694923780096.0000 - val_mse: 6122694923780096.0000\n",
            "Epoch 991/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 942090338959360.0000 - mse: 942090338959360.0000 - val_loss: 6120782052720640.0000 - val_mse: 6120782052720640.0000\n",
            "Epoch 992/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 939950774157312.0000 - mse: 939950774157312.0000 - val_loss: 6118894414594048.0000 - val_mse: 6118894414594048.0000\n",
            "Epoch 993/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 937810739593216.0000 - mse: 937810739593216.0000 - val_loss: 6116976711696384.0000 - val_mse: 6116976711696384.0000\n",
            "Epoch 994/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 935672248532992.0000 - mse: 935672248532992.0000 - val_loss: 6115103032213504.0000 - val_mse: 6115103032213504.0000\n",
            "Epoch 995/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 933538522202112.0000 - mse: 933538522202112.0000 - val_loss: 6113254048792576.0000 - val_mse: 6113254048792576.0000\n",
            "Epoch 996/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 931405735395328.0000 - mse: 931405735395328.0000 - val_loss: 6111383590535168.0000 - val_mse: 6111383590535168.0000\n",
            "Epoch 997/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 929280934543360.0000 - mse: 929280934543360.0000 - val_loss: 6109493804924928.0000 - val_mse: 6109493804924928.0000\n",
            "Epoch 998/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 927155462602752.0000 - mse: 927155462602752.0000 - val_loss: 6107616904216576.0000 - val_mse: 6107616904216576.0000\n",
            "Epoch 999/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 925034285629440.0000 - mse: 925034285629440.0000 - val_loss: 6105737856024576.0000 - val_mse: 6105737856024576.0000\n",
            "Epoch 1000/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 922916933861376.0000 - mse: 922916933861376.0000 - val_loss: 6103857197219840.0000 - val_mse: 6103857197219840.0000\n",
            "Epoch 1001/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 920802333556736.0000 - mse: 920802333556736.0000 - val_loss: 6101975464673280.0000 - val_mse: 6101975464673280.0000\n",
            "Epoch 1002/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 918685652877312.0000 - mse: 918685652877312.0000 - val_loss: 6100110375124992.0000 - val_mse: 6100110375124992.0000\n",
            "Epoch 1003/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 916580179378176.0000 - mse: 916580179378176.0000 - val_loss: 6098262465445888.0000 - val_mse: 6098262465445888.0000\n",
            "Epoch 1004/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 914473162375168.0000 - mse: 914473162375168.0000 - val_loss: 6096416703250432.0000 - val_mse: 6096416703250432.0000\n",
            "Epoch 1005/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 912372722040832.0000 - mse: 912372722040832.0000 - val_loss: 6094504905932800.0000 - val_mse: 6094504905932800.0000\n",
            "Epoch 1006/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 910266376126464.0000 - mse: 910266376126464.0000 - val_loss: 6092633910804480.0000 - val_mse: 6092633910804480.0000\n",
            "Epoch 1007/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 908171505827840.0000 - mse: 908171505827840.0000 - val_loss: 6090782779899904.0000 - val_mse: 6090782779899904.0000\n",
            "Epoch 1008/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 906077172400128.0000 - mse: 906077172400128.0000 - val_loss: 6088912321642496.0000 - val_mse: 6088912321642496.0000\n",
            "Epoch 1009/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 903987335266304.0000 - mse: 903987335266304.0000 - val_loss: 6087057969512448.0000 - val_mse: 6087057969512448.0000\n",
            "Epoch 1010/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 901901793099776.0000 - mse: 901901793099776.0000 - val_loss: 6085216502284288.0000 - val_mse: 6085216502284288.0000\n",
            "Epoch 1011/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 899815512735744.0000 - mse: 899815512735744.0000 - val_loss: 6083372350701568.0000 - val_mse: 6083372350701568.0000\n",
            "Epoch 1012/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 897730977202176.0000 - mse: 897730977202176.0000 - val_loss: 6081506187411456.0000 - val_mse: 6081506187411456.0000\n",
            "Epoch 1013/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 895650669527040.0000 - mse: 895650669527040.0000 - val_loss: 6079650224668672.0000 - val_mse: 6079650224668672.0000\n",
            "Epoch 1014/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 893579086004224.0000 - mse: 893579086004224.0000 - val_loss: 6077794798796800.0000 - val_mse: 6077794798796800.0000\n",
            "Epoch 1015/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 891504885235712.0000 - mse: 891504885235712.0000 - val_loss: 6075946889117696.0000 - val_mse: 6075946889117696.0000\n",
            "Epoch 1016/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 889434509672448.0000 - mse: 889434509672448.0000 - val_loss: 6074107569373184.0000 - val_mse: 6074107569373184.0000\n",
            "Epoch 1017/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 887370375233536.0000 - mse: 887370375233536.0000 - val_loss: 6072252143501312.0000 - val_mse: 6072252143501312.0000\n",
            "Epoch 1018/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 885302080045056.0000 - mse: 885302080045056.0000 - val_loss: 6070399401984000.0000 - val_mse: 6070399401984000.0000\n",
            "Epoch 1019/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 883244790710272.0000 - mse: 883244790710272.0000 - val_loss: 6068552029175808.0000 - val_mse: 6068552029175808.0000\n",
            "Epoch 1020/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 881184145932288.0000 - mse: 881184145932288.0000 - val_loss: 6066737942364160.0000 - val_mse: 6066737942364160.0000\n",
            "Epoch 1021/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 879130413367296.0000 - mse: 879130413367296.0000 - val_loss: 6064882516492288.0000 - val_mse: 6064882516492288.0000\n",
            "Epoch 1022/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 877078492741632.0000 - mse: 877078492741632.0000 - val_loss: 6063030848716800.0000 - val_mse: 6063030848716800.0000\n",
            "Epoch 1023/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 875029122252800.0000 - mse: 875029122252800.0000 - val_loss: 6061185086521344.0000 - val_mse: 6061185086521344.0000\n",
            "Epoch 1024/2000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 872985053364224.0000 - mse: 872985053364224.0000 - val_loss: 6059337713713152.0000 - val_mse: 6059337713713152.0000\n",
            "Epoch 1025/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 870943400394752.0000 - mse: 870943400394752.0000 - val_loss: 6057518795063296.0000 - val_mse: 6057518795063296.0000\n",
            "Epoch 1026/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 868900740792320.0000 - mse: 868900740792320.0000 - val_loss: 6055697728929792.0000 - val_mse: 6055697728929792.0000\n",
            "Epoch 1027/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 866865664491520.0000 - mse: 866865664491520.0000 - val_loss: 6053859482927104.0000 - val_mse: 6053859482927104.0000\n",
            "Epoch 1028/2000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 864834480504832.0000 - mse: 864834480504832.0000 - val_loss: 6052053449179136.0000 - val_mse: 6052053449179136.0000\n",
            "Epoch 1029/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 862806450634752.0000 - mse: 862806450634752.0000 - val_loss: 6050238825496576.0000 - val_mse: 6050238825496576.0000\n",
            "Epoch 1030/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 860776474607616.0000 - mse: 860776474607616.0000 - val_loss: 6048372662206464.0000 - val_mse: 6048372662206464.0000\n",
            "Epoch 1031/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 858751397527552.0000 - mse: 858751397527552.0000 - val_loss: 6046571460296704.0000 - val_mse: 6046571460296704.0000\n",
            "Epoch 1032/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 856732897116160.0000 - mse: 856732897116160.0000 - val_loss: 6044745025454080.0000 - val_mse: 6044745025454080.0000\n",
            "Epoch 1033/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 854710974152704.0000 - mse: 854710974152704.0000 - val_loss: 6042933622996992.0000 - val_mse: 6042933622996992.0000\n",
            "Epoch 1034/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 852695225204736.0000 - mse: 852695225204736.0000 - val_loss: 6041105040670720.0000 - val_mse: 6041105040670720.0000\n",
            "Epoch 1035/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 850683704115200.0000 - mse: 850683704115200.0000 - val_loss: 6039292564471808.0000 - val_mse: 6039292564471808.0000\n",
            "Epoch 1036/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 848676008230912.0000 - mse: 848676008230912.0000 - val_loss: 6037461834661888.0000 - val_mse: 6037461834661888.0000\n",
            "Epoch 1037/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 846668714999808.0000 - mse: 846668714999808.0000 - val_loss: 6035643989753856.0000 - val_mse: 6035643989753856.0000\n",
            "Epoch 1038/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 844665649627136.0000 - mse: 844665649627136.0000 - val_loss: 6033823460491264.0000 - val_mse: 6033823460491264.0000\n",
            "Epoch 1039/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 842671174189056.0000 - mse: 842671174189056.0000 - val_loss: 6032032459128832.0000 - val_mse: 6032032459128832.0000\n",
            "Epoch 1040/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 840670591844352.0000 - mse: 840670591844352.0000 - val_loss: 6030202266189824.0000 - val_mse: 6030202266189824.0000\n",
            "Epoch 1041/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 838672492527616.0000 - mse: 838672492527616.0000 - val_loss: 6028394084958208.0000 - val_mse: 6028394084958208.0000\n",
            "Epoch 1042/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 836684727975936.0000 - mse: 836684727975936.0000 - val_loss: 6026588588081152.0000 - val_mse: 6026588588081152.0000\n",
            "Epoch 1043/2000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 834699781996544.0000 - mse: 834699781996544.0000 - val_loss: 6024762690109440.0000 - val_mse: 6024762690109440.0000\n",
            "Epoch 1044/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 832711480573952.0000 - mse: 832711480573952.0000 - val_loss: 6022967930650624.0000 - val_mse: 6022967930650624.0000\n",
            "Epoch 1045/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 830732373065728.0000 - mse: 830732373065728.0000 - val_loss: 6021159749419008.0000 - val_mse: 6021159749419008.0000\n",
            "Epoch 1046/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 828752057597952.0000 - mse: 828752057597952.0000 - val_loss: 6019396128473088.0000 - val_mse: 6019396128473088.0000\n",
            "Epoch 1047/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 826776506859520.0000 - mse: 826776506859520.0000 - val_loss: 6017601369014272.0000 - val_mse: 6017601369014272.0000\n",
            "Epoch 1048/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 824801627209728.0000 - mse: 824801627209728.0000 - val_loss: 6015758291173376.0000 - val_mse: 6015758291173376.0000\n",
            "Epoch 1049/2000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 822831042527232.0000 - mse: 822831042527232.0000 - val_loss: 6013972658520064.0000 - val_mse: 6013972658520064.0000\n",
            "Epoch 1050/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 820865222574080.0000 - mse: 820865222574080.0000 - val_loss: 6012164477288448.0000 - val_mse: 6012164477288448.0000\n",
            "Epoch 1051/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 818903630479360.0000 - mse: 818903630479360.0000 - val_loss: 6010377234022400.0000 - val_mse: 6010377234022400.0000\n",
            "Epoch 1052/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 816941300187136.0000 - mse: 816941300187136.0000 - val_loss: 6008545430470656.0000 - val_mse: 6008545430470656.0000\n",
            "Epoch 1053/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 814981855576064.0000 - mse: 814981855576064.0000 - val_loss: 6006803284361216.0000 - val_mse: 6006803284361216.0000\n",
            "Epoch 1054/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 813029390286848.0000 - mse: 813029390286848.0000 - val_loss: 6004965038358528.0000 - val_mse: 6004965038358528.0000\n",
            "Epoch 1055/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 811077730304000.0000 - mse: 811077730304000.0000 - val_loss: 6003218060410880.0000 - val_mse: 6003218060410880.0000\n",
            "Epoch 1056/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 809128553349120.0000 - mse: 809128553349120.0000 - val_loss: 6001420616597504.0000 - val_mse: 6001420616597504.0000\n",
            "Epoch 1057/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 807184006905856.0000 - mse: 807184006905856.0000 - val_loss: 5999627467751424.0000 - val_mse: 5999627467751424.0000\n",
            "Epoch 1058/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 805241809272832.0000 - mse: 805241809272832.0000 - val_loss: 5997823044616192.0000 - val_mse: 5997823044616192.0000\n",
            "Epoch 1059/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 803302698647552.0000 - mse: 803302698647552.0000 - val_loss: 5996048686252032.0000 - val_mse: 5996048686252032.0000\n",
            "Epoch 1060/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 801364997308416.0000 - mse: 801364997308416.0000 - val_loss: 5994263053598720.0000 - val_mse: 5994263053598720.0000\n",
            "Epoch 1061/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 799428839473152.0000 - mse: 799428839473152.0000 - val_loss: 5992504801361920.0000 - val_mse: 5992504801361920.0000\n",
            "Epoch 1062/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 797498520109056.0000 - mse: 797498520109056.0000 - val_loss: 5990678903390208.0000 - val_mse: 5990678903390208.0000\n",
            "Epoch 1063/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 795574643195904.0000 - mse: 795574643195904.0000 - val_loss: 5988880385835008.0000 - val_mse: 5988880385835008.0000\n",
            "Epoch 1064/2000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 793648283254784.0000 - mse: 793648283254784.0000 - val_loss: 5987147366531072.0000 - val_mse: 5987147366531072.0000\n",
            "Epoch 1065/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 791726889369600.0000 - mse: 791726889369600.0000 - val_loss: 5985372471296000.0000 - val_mse: 5985372471296000.0000\n",
            "Epoch 1066/2000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 789806770552832.0000 - mse: 789806770552832.0000 - val_loss: 5983634620153856.0000 - val_mse: 5983634620153856.0000\n",
            "Epoch 1067/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 787891148029952.0000 - mse: 787891148029952.0000 - val_loss: 5981845229404160.0000 - val_mse: 5981845229404160.0000\n",
            "Epoch 1068/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 785978075643904.0000 - mse: 785978075643904.0000 - val_loss: 5980104157036544.0000 - val_mse: 5980104157036544.0000\n",
            "Epoch 1069/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 784072183906304.0000 - mse: 784072183906304.0000 - val_loss: 5978285238386688.0000 - val_mse: 5978285238386688.0000\n",
            "Epoch 1070/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 782161661657088.0000 - mse: 782161661657088.0000 - val_loss: 5976530207375360.0000 - val_mse: 5976530207375360.0000\n",
            "Epoch 1071/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 780259326689280.0000 - mse: 780259326689280.0000 - val_loss: 5974739206012928.0000 - val_mse: 5974739206012928.0000\n",
            "Epoch 1072/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 778358803660800.0000 - mse: 778358803660800.0000 - val_loss: 5973002965483520.0000 - val_mse: 5973002965483520.0000\n",
            "Epoch 1073/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 776463112470528.0000 - mse: 776463112470528.0000 - val_loss: 5971243102633984.0000 - val_mse: 5971243102633984.0000\n",
            "Epoch 1074/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 774567891042304.0000 - mse: 774567891042304.0000 - val_loss: 5969489682235392.0000 - val_mse: 5969489682235392.0000\n",
            "Epoch 1075/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 772676763254784.0000 - mse: 772676763254784.0000 - val_loss: 5967702438969344.0000 - val_mse: 5967702438969344.0000\n",
            "Epoch 1076/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 770789863325696.0000 - mse: 770789863325696.0000 - val_loss: 5965928080605184.0000 - val_mse: 5965928080605184.0000\n",
            "Epoch 1077/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 768906989928448.0000 - mse: 768906989928448.0000 - val_loss: 5964192913817600.0000 - val_mse: 5964192913817600.0000\n",
            "Epoch 1078/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 767021163741184.0000 - mse: 767021163741184.0000 - val_loss: 5962444325257216.0000 - val_mse: 5962444325257216.0000\n",
            "Epoch 1079/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 765139699630080.0000 - mse: 765139699630080.0000 - val_loss: 5960684462407680.0000 - val_mse: 5960684462407680.0000\n",
            "Epoch 1080/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 763267228106752.0000 - mse: 763267228106752.0000 - val_loss: 5958906345947136.0000 - val_mse: 5958906345947136.0000\n",
            "Epoch 1081/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 761392273555456.0000 - mse: 761392273555456.0000 - val_loss: 5957142725001216.0000 - val_mse: 5957142725001216.0000\n",
            "Epoch 1082/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 759524499652608.0000 - mse: 759524499652608.0000 - val_loss: 5955423664340992.0000 - val_mse: 5955423664340992.0000\n",
            "Epoch 1083/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 757654645374976.0000 - mse: 757654645374976.0000 - val_loss: 5953688497553408.0000 - val_mse: 5953688497553408.0000\n",
            "Epoch 1084/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 755793649467392.0000 - mse: 755793649467392.0000 - val_loss: 5951913602318336.0000 - val_mse: 5951913602318336.0000\n",
            "Epoch 1085/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 753930707402752.0000 - mse: 753930707402752.0000 - val_loss: 5950181656756224.0000 - val_mse: 5950181656756224.0000\n",
            "Epoch 1086/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 752070919454720.0000 - mse: 752070919454720.0000 - val_loss: 5948416425197568.0000 - val_mse: 5948416425197568.0000\n",
            "Epoch 1087/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 750221063618560.0000 - mse: 750221063618560.0000 - val_loss: 5946668373508096.0000 - val_mse: 5946668373508096.0000\n",
            "Epoch 1088/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 748364094242816.0000 - mse: 748364094242816.0000 - val_loss: 5944902068207616.0000 - val_mse: 5944902068207616.0000\n",
            "Epoch 1089/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 746514976604160.0000 - mse: 746514976604160.0000 - val_loss: 5943183007547392.0000 - val_mse: 5943183007547392.0000\n",
            "Epoch 1090/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 744666865598464.0000 - mse: 744666865598464.0000 - val_loss: 5941448914501632.0000 - val_mse: 5941448914501632.0000\n",
            "Epoch 1091/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 742824928608256.0000 - mse: 742824928608256.0000 - val_loss: 5939679387975680.0000 - val_mse: 5939679387975680.0000\n",
            "Epoch 1092/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 740984803557376.0000 - mse: 740984803557376.0000 - val_loss: 5937961401057280.0000 - val_mse: 5937961401057280.0000\n",
            "Epoch 1093/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 739147765514240.0000 - mse: 739147765514240.0000 - val_loss: 5936249319718912.0000 - val_mse: 5936249319718912.0000\n",
            "Epoch 1094/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 737313680261120.0000 - mse: 737313680261120.0000 - val_loss: 5934471740129280.0000 - val_mse: 5934471740129280.0000\n",
            "Epoch 1095/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 735481138511872.0000 - mse: 735481138511872.0000 - val_loss: 5932736573341696.0000 - val_mse: 5932736573341696.0000\n",
            "Epoch 1096/2000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 733656314281984.0000 - mse: 733656314281984.0000 - val_loss: 5930994427232256.0000 - val_mse: 5930994427232256.0000\n",
            "Epoch 1097/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 731829812330496.0000 - mse: 731829812330496.0000 - val_loss: 5929301136375808.0000 - val_mse: 5929301136375808.0000\n",
            "Epoch 1098/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 730005524971520.0000 - mse: 730005524971520.0000 - val_loss: 5927577243877376.0000 - val_mse: 5927577243877376.0000\n",
            "Epoch 1099/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 728189022240768.0000 - mse: 728189022240768.0000 - val_loss: 5925854425120768.0000 - val_mse: 5925854425120768.0000\n",
            "Epoch 1100/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 726371714203648.0000 - mse: 726371714203648.0000 - val_loss: 5924138585686016.0000 - val_mse: 5924138585686016.0000\n",
            "Epoch 1101/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 724557426065408.0000 - mse: 724557426065408.0000 - val_loss: 5922405029511168.0000 - val_mse: 5922405029511168.0000\n",
            "Epoch 1102/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 722748909289472.0000 - mse: 722748909289472.0000 - val_loss: 5920650535370752.0000 - val_mse: 5920650535370752.0000\n",
            "Epoch 1103/2000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 720938714791936.0000 - mse: 720938714791936.0000 - val_loss: 5918900336197632.0000 - val_mse: 5918900336197632.0000\n",
            "Epoch 1104/2000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 719134492983296.0000 - mse: 719134492983296.0000 - val_loss: 5917210266566656.0000 - val_mse: 5917210266566656.0000\n",
            "Epoch 1105/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 717332150222848.0000 - mse: 717332150222848.0000 - val_loss: 5915520196935680.0000 - val_mse: 5915520196935680.0000\n",
            "Epoch 1106/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 715534370865152.0000 - mse: 715534370865152.0000 - val_loss: 5913802746888192.0000 - val_mse: 5913802746888192.0000\n",
            "Epoch 1107/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 713738604773376.0000 - mse: 713738604773376.0000 - val_loss: 5912075633164288.0000 - val_mse: 5912075633164288.0000\n",
            "Epoch 1108/2000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 711948140281856.0000 - mse: 711948140281856.0000 - val_loss: 5910307180380160.0000 - val_mse: 5910307180380160.0000\n",
            "Epoch 1109/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 710159286403072.0000 - mse: 710159286403072.0000 - val_loss: 5908599930880000.0000 - val_mse: 5908599930880000.0000\n",
            "Epoch 1110/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 708370969395200.0000 - mse: 708370969395200.0000 - val_loss: 5906901808185344.0000 - val_mse: 5906901808185344.0000\n",
            "Epoch 1111/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 706589094838272.0000 - mse: 706589094838272.0000 - val_loss: 5905202611748864.0000 - val_mse: 5905202611748864.0000\n",
            "Epoch 1112/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 704808830894080.0000 - mse: 704808830894080.0000 - val_loss: 5903511468376064.0000 - val_mse: 5903511468376064.0000\n",
            "Epoch 1113/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 703032861917184.0000 - mse: 703032861917184.0000 - val_loss: 5901793481457664.0000 - val_mse: 5901793481457664.0000\n",
            "Epoch 1114/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 701258302226432.0000 - mse: 701258302226432.0000 - val_loss: 5900043282284544.0000 - val_mse: 5900043282284544.0000\n",
            "Epoch 1115/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 699484547842048.0000 - mse: 699484547842048.0000 - val_loss: 5898349454557184.0000 - val_mse: 5898349454557184.0000\n",
            "Epoch 1116/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 697717571452928.0000 - mse: 697717571452928.0000 - val_loss: 5896629320155136.0000 - val_mse: 5896629320155136.0000\n",
            "Epoch 1117/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 695951534587904.0000 - mse: 695951534587904.0000 - val_loss: 5894949451071488.0000 - val_mse: 5894949451071488.0000\n",
            "Epoch 1118/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 694186101702656.0000 - mse: 694186101702656.0000 - val_loss: 5893237906604032.0000 - val_mse: 5893237906604032.0000\n",
            "Epoch 1119/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 692427513921536.0000 - mse: 692427513921536.0000 - val_loss: 5891578975485952.0000 - val_mse: 5891578975485952.0000\n",
            "Epoch 1120/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 690673221107712.0000 - mse: 690673221107712.0000 - val_loss: 5889881389662208.0000 - val_mse: 5889881389662208.0000\n",
            "Epoch 1121/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 688917653225472.0000 - mse: 688917653225472.0000 - val_loss: 5888185951322112.0000 - val_mse: 5888185951322112.0000\n",
            "Epoch 1122/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 687166380310528.0000 - mse: 687166380310528.0000 - val_loss: 5886486218014720.0000 - val_mse: 5886486218014720.0000\n",
            "Epoch 1123/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 685419066818560.0000 - mse: 685419066818560.0000 - val_loss: 5884766620483584.0000 - val_mse: 5884766620483584.0000\n",
            "Epoch 1124/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 683674437681152.0000 - mse: 683674437681152.0000 - val_loss: 5883085677658112.0000 - val_mse: 5883085677658112.0000\n",
            "Epoch 1125/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 681932560007168.0000 - mse: 681932560007168.0000 - val_loss: 5881390239318016.0000 - val_mse: 5881390239318016.0000\n",
            "Epoch 1126/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 680192225837056.0000 - mse: 680192225837056.0000 - val_loss: 5879700706557952.0000 - val_mse: 5879700706557952.0000\n",
            "Epoch 1127/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 678458065682432.0000 - mse: 678458065682432.0000 - val_loss: 5878028353667072.0000 - val_mse: 5878028353667072.0000\n",
            "Epoch 1128/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 676727059644416.0000 - mse: 676727059644416.0000 - val_loss: 5876309829877760.0000 - val_mse: 5876309829877760.0000\n",
            "Epoch 1129/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 674994644320256.0000 - mse: 674994644320256.0000 - val_loss: 5874649288146944.0000 - val_mse: 5874649288146944.0000\n",
            "Epoch 1130/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 673268604338176.0000 - mse: 673268604338176.0000 - val_loss: 5872938817421312.0000 - val_mse: 5872938817421312.0000\n",
            "Epoch 1131/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 671542497247232.0000 - mse: 671542497247232.0000 - val_loss: 5871226199212032.0000 - val_mse: 5871226199212032.0000\n",
            "Epoch 1132/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 669823369478144.0000 - mse: 669823369478144.0000 - val_loss: 5869584447963136.0000 - val_mse: 5869584447963136.0000\n",
            "Epoch 1133/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 668104040382464.0000 - mse: 668104040382464.0000 - val_loss: 5867910484459520.0000 - val_mse: 5867910484459520.0000\n",
            "Epoch 1134/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 666388133838848.0000 - mse: 666388133838848.0000 - val_loss: 5866205382443008.0000 - val_mse: 5866205382443008.0000\n",
            "Epoch 1135/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 664673636581376.0000 - mse: 664673636581376.0000 - val_loss: 5864506722877440.0000 - val_mse: 5864506722877440.0000\n",
            "Epoch 1136/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 662966454190080.0000 - mse: 662966454190080.0000 - val_loss: 5862840812437504.0000 - val_mse: 5862840812437504.0000\n",
            "Epoch 1137/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 661259942887424.0000 - mse: 661259942887424.0000 - val_loss: 5861172217643008.0000 - val_mse: 5861172217643008.0000\n",
            "Epoch 1138/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 659557189681152.0000 - mse: 659557189681152.0000 - val_loss: 5859488590462976.0000 - val_mse: 5859488590462976.0000\n",
            "Epoch 1139/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 657857993244672.0000 - mse: 657857993244672.0000 - val_loss: 5857824290635776.0000 - val_mse: 5857824290635776.0000\n",
            "Epoch 1140/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 656160273203200.0000 - mse: 656160273203200.0000 - val_loss: 5856147642777600.0000 - val_mse: 5856147642777600.0000\n",
            "Epoch 1141/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 654465237516288.0000 - mse: 654465237516288.0000 - val_loss: 5854457036275712.0000 - val_mse: 5854457036275712.0000\n",
            "Epoch 1142/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 652775033667584.0000 - mse: 652775033667584.0000 - val_loss: 5852783609643008.0000 - val_mse: 5852783609643008.0000\n",
            "Epoch 1143/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 651083152097280.0000 - mse: 651083152097280.0000 - val_loss: 5851098371850240.0000 - val_mse: 5851098371850240.0000\n",
            "Epoch 1144/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 649398451175424.0000 - mse: 649398451175424.0000 - val_loss: 5849439977603072.0000 - val_mse: 5849439977603072.0000\n",
            "Epoch 1145/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 647717307023360.0000 - mse: 647717307023360.0000 - val_loss: 5847784804581376.0000 - val_mse: 5847784804581376.0000\n",
            "Epoch 1146/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 646037907701760.0000 - mse: 646037907701760.0000 - val_loss: 5846109767335936.0000 - val_mse: 5846109767335936.0000\n",
            "Epoch 1147/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 644358374162432.0000 - mse: 644358374162432.0000 - val_loss: 5844452446830592.0000 - val_mse: 5844452446830592.0000\n",
            "Epoch 1148/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 642686960795648.0000 - mse: 642686960795648.0000 - val_loss: 5842801031905280.0000 - val_mse: 5842801031905280.0000\n",
            "Epoch 1149/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 641018634436608.0000 - mse: 641018634436608.0000 - val_loss: 5841121699692544.0000 - val_mse: 5841121699692544.0000\n",
            "Epoch 1150/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 639346549981184.0000 - mse: 639346549981184.0000 - val_loss: 5839438072512512.0000 - val_mse: 5839438072512512.0000\n",
            "Epoch 1151/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 637683189678080.0000 - mse: 637683189678080.0000 - val_loss: 5837792563167232.0000 - val_mse: 5837792563167232.0000\n",
            "Epoch 1152/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 636016138387456.0000 - mse: 636016138387456.0000 - val_loss: 5836140611371008.0000 - val_mse: 5836140611371008.0000\n",
            "Epoch 1153/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 634359287644160.0000 - mse: 634359287644160.0000 - val_loss: 5834488122703872.0000 - val_mse: 5834488122703872.0000\n",
            "Epoch 1154/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 632704181731328.0000 - mse: 632704181731328.0000 - val_loss: 5832846371454976.0000 - val_mse: 5832846371454976.0000\n",
            "Epoch 1155/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 631051424628736.0000 - mse: 631051424628736.0000 - val_loss: 5831187440336896.0000 - val_mse: 5831187440336896.0000\n",
            "Epoch 1156/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 629400949227520.0000 - mse: 629400949227520.0000 - val_loss: 5829559110860800.0000 - val_mse: 5829559110860800.0000\n",
            "Epoch 1157/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 627749467193344.0000 - mse: 627749467193344.0000 - val_loss: 5827891052937216.0000 - val_mse: 5827891052937216.0000\n",
            "Epoch 1158/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 626108252815360.0000 - mse: 626108252815360.0000 - val_loss: 5826249301688320.0000 - val_mse: 5826249301688320.0000\n",
            "Epoch 1159/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 624466904219648.0000 - mse: 624466904219648.0000 - val_loss: 5824569969475584.0000 - val_mse: 5824569969475584.0000\n",
            "Epoch 1160/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 622825220079616.0000 - mse: 622825220079616.0000 - val_loss: 5822915333324800.0000 - val_mse: 5822915333324800.0000\n",
            "Epoch 1161/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 621192461418496.0000 - mse: 621192461418496.0000 - val_loss: 5821280024526848.0000 - val_mse: 5821280024526848.0000\n",
            "Epoch 1162/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 619558964559872.0000 - mse: 619558964559872.0000 - val_loss: 5819628609601536.0000 - val_mse: 5819628609601536.0000\n",
            "Epoch 1163/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 617930635083776.0000 - mse: 617930635083776.0000 - val_loss: 5818020681220096.0000 - val_mse: 5818020681220096.0000\n",
            "Epoch 1164/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 616299017273344.0000 - mse: 616299017273344.0000 - val_loss: 5816394499227648.0000 - val_mse: 5816394499227648.0000\n",
            "Epoch 1165/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 614676257832960.0000 - mse: 614676257832960.0000 - val_loss: 5814689397211136.0000 - val_mse: 5814689397211136.0000\n",
            "Epoch 1166/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 613055847202816.0000 - mse: 613055847202816.0000 - val_loss: 5813054088413184.0000 - val_mse: 5813054088413184.0000\n",
            "Epoch 1167/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 611438120927232.0000 - mse: 611438120927232.0000 - val_loss: 5811415558389760.0000 - val_mse: 5811415558389760.0000\n",
            "Epoch 1168/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 609819857780736.0000 - mse: 609819857780736.0000 - val_loss: 5809804945653760.0000 - val_mse: 5809804945653760.0000\n",
            "Epoch 1169/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 608209714806784.0000 - mse: 608209714806784.0000 - val_loss: 5808177689919488.0000 - val_mse: 5808177689919488.0000\n",
            "Epoch 1170/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 606599840268288.0000 - mse: 606599840268288.0000 - val_loss: 5806543454863360.0000 - val_mse: 5806543454863360.0000\n",
            "Epoch 1171/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 604992985628672.0000 - mse: 604992985628672.0000 - val_loss: 5804914588516352.0000 - val_mse: 5804914588516352.0000\n",
            "Epoch 1172/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 603389217996800.0000 - mse: 603389217996800.0000 - val_loss: 5803262636720128.0000 - val_mse: 5803262636720128.0000\n",
            "Epoch 1173/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 601787195195392.0000 - mse: 601787195195392.0000 - val_loss: 5801622496083968.0000 - val_mse: 5801622496083968.0000\n",
            "Epoch 1174/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 600190675320832.0000 - mse: 600190675320832.0000 - val_loss: 5799973228642304.0000 - val_mse: 5799973228642304.0000\n",
            "Epoch 1175/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 598595497623552.0000 - mse: 598595497623552.0000 - val_loss: 5798349731004416.0000 - val_mse: 5798349731004416.0000\n",
            "Epoch 1176/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 597001460776960.0000 - mse: 597001460776960.0000 - val_loss: 5796720327786496.0000 - val_mse: 5796720327786496.0000\n",
            "Epoch 1177/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 595409437196288.0000 - mse: 595409437196288.0000 - val_loss: 5795136558596096.0000 - val_mse: 5795136558596096.0000\n",
            "Epoch 1178/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 593827144400896.0000 - mse: 593827144400896.0000 - val_loss: 5793494807347200.0000 - val_mse: 5793494807347200.0000\n",
            "Epoch 1179/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 592242569904128.0000 - mse: 592242569904128.0000 - val_loss: 5791856814194688.0000 - val_mse: 5791856814194688.0000\n",
            "Epoch 1180/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 590660746870784.0000 - mse: 590660746870784.0000 - val_loss: 5790254254522368.0000 - val_mse: 5790254254522368.0000\n",
            "Epoch 1181/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 589084963635200.0000 - mse: 589084963635200.0000 - val_loss: 5788611429531648.0000 - val_mse: 5788611429531648.0000\n",
            "Epoch 1182/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 587506227609600.0000 - mse: 587506227609600.0000 - val_loss: 5786991689990144.0000 - val_mse: 5786991689990144.0000\n",
            "Epoch 1183/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 585935007776768.0000 - mse: 585935007776768.0000 - val_loss: 5785378392899584.0000 - val_mse: 5785378392899584.0000\n",
            "Epoch 1184/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 584370230394880.0000 - mse: 584370230394880.0000 - val_loss: 5783789791870976.0000 - val_mse: 5783789791870976.0000\n",
            "Epoch 1185/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 582803104202752.0000 - mse: 582803104202752.0000 - val_loss: 5782184010973184.0000 - val_mse: 5782184010973184.0000\n",
            "Epoch 1186/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 581239736107008.0000 - mse: 581239736107008.0000 - val_loss: 5780550849658880.0000 - val_mse: 5780550849658880.0000\n",
            "Epoch 1187/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 579678112841728.0000 - mse: 579678112841728.0000 - val_loss: 5778921983311872.0000 - val_mse: 5778921983311872.0000\n",
            "Epoch 1188/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 578121589850112.0000 - mse: 578121589850112.0000 - val_loss: 5777318886768640.0000 - val_mse: 5777318886768640.0000\n",
            "Epoch 1189/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 576567549886464.0000 - mse: 576567549886464.0000 - val_loss: 5775674451165184.0000 - val_mse: 5775674451165184.0000\n",
            "Epoch 1190/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 575014382338048.0000 - mse: 575014382338048.0000 - val_loss: 5774090145103872.0000 - val_mse: 5774090145103872.0000\n",
            "Epoch 1191/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 573465107103744.0000 - mse: 573465107103744.0000 - val_loss: 5772509597138944.0000 - val_mse: 5772509597138944.0000\n",
            "Epoch 1192/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 571919321530368.0000 - mse: 571919321530368.0000 - val_loss: 5770902742499328.0000 - val_mse: 5770902742499328.0000\n",
            "Epoch 1193/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 570377562488832.0000 - mse: 570377562488832.0000 - val_loss: 5769303940923392.0000 - val_mse: 5769303940923392.0000\n",
            "Epoch 1194/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 568835333685248.0000 - mse: 568835333685248.0000 - val_loss: 5767693865058304.0000 - val_mse: 5767693865058304.0000\n",
            "Epoch 1195/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 567301090836480.0000 - mse: 567301090836480.0000 - val_loss: 5766032786456576.0000 - val_mse: 5766032786456576.0000\n",
            "Epoch 1196/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 565765975572480.0000 - mse: 565765975572480.0000 - val_loss: 5764482303262720.0000 - val_mse: 5764482303262720.0000\n",
            "Epoch 1197/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 564233947316224.0000 - mse: 564233947316224.0000 - val_loss: 5762869006172160.0000 - val_mse: 5762869006172160.0000\n",
            "Epoch 1198/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 562703361900544.0000 - mse: 562703361900544.0000 - val_loss: 5761309396172800.0000 - val_mse: 5761309396172800.0000\n",
            "Epoch 1199/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 561176937234432.0000 - mse: 561176937234432.0000 - val_loss: 5759671939891200.0000 - val_mse: 5759671939891200.0000\n",
            "Epoch 1200/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 559656149712896.0000 - mse: 559656149712896.0000 - val_loss: 5758109645537280.0000 - val_mse: 5758109645537280.0000\n",
            "Epoch 1201/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 558135194419200.0000 - mse: 558135194419200.0000 - val_loss: 5756500106543104.0000 - val_mse: 5756500106543104.0000\n",
            "Epoch 1202/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 556616386609152.0000 - mse: 556616386609152.0000 - val_loss: 5754878756388864.0000 - val_mse: 5754878756388864.0000\n",
            "Epoch 1203/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 555102981062656.0000 - mse: 555102981062656.0000 - val_loss: 5753287471005696.0000 - val_mse: 5753287471005696.0000\n",
            "Epoch 1204/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 553590213050368.0000 - mse: 553590213050368.0000 - val_loss: 5751719271071744.0000 - val_mse: 5751719271071744.0000\n",
            "Epoch 1205/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 552079223422976.0000 - mse: 552079223422976.0000 - val_loss: 5750118858883072.0000 - val_mse: 5750118858883072.0000\n",
            "Epoch 1206/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 550574206484480.0000 - mse: 550574206484480.0000 - val_loss: 5748538310918144.0000 - val_mse: 5748538310918144.0000\n",
            "Epoch 1207/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 549070598832128.0000 - mse: 549070598832128.0000 - val_loss: 5746930919407616.0000 - val_mse: 5746930919407616.0000\n",
            "Epoch 1208/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 547571554582528.0000 - mse: 547571554582528.0000 - val_loss: 5745328896606208.0000 - val_mse: 5745328896606208.0000\n",
            "Epoch 1209/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 546076973072384.0000 - mse: 546076973072384.0000 - val_loss: 5743741369319424.0000 - val_mse: 5743741369319424.0000\n",
            "Epoch 1210/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 544580378296320.0000 - mse: 544580378296320.0000 - val_loss: 5742177464352768.0000 - val_mse: 5742177464352768.0000\n",
            "Epoch 1211/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 543087239626752.0000 - mse: 543087239626752.0000 - val_loss: 5740616780611584.0000 - val_mse: 5740616780611584.0000\n",
            "Epoch 1212/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 541601482932224.0000 - mse: 541601482932224.0000 - val_loss: 5739025495228416.0000 - val_mse: 5739025495228416.0000\n",
            "Epoch 1213/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 540114484723712.0000 - mse: 540114484723712.0000 - val_loss: 5737437967941632.0000 - val_mse: 5737437967941632.0000\n",
            "Epoch 1214/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 538631211057152.0000 - mse: 538631211057152.0000 - val_loss: 5735850977525760.0000 - val_mse: 5735850977525760.0000\n",
            "Epoch 1215/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 537148574924800.0000 - mse: 537148574924800.0000 - val_loss: 5734245733498880.0000 - val_mse: 5734245733498880.0000\n",
            "Epoch 1216/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 535670804185088.0000 - mse: 535670804185088.0000 - val_loss: 5732687734112256.0000 - val_mse: 5732687734112256.0000\n",
            "Epoch 1217/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 534198368600064.0000 - mse: 534198368600064.0000 - val_loss: 5731134566563840.0000 - val_mse: 5731134566563840.0000\n",
            "Epoch 1218/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 532724859273216.0000 - mse: 532724859273216.0000 - val_loss: 5729546502406144.0000 - val_mse: 5729546502406144.0000\n",
            "Epoch 1219/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 531255779131392.0000 - mse: 531255779131392.0000 - val_loss: 5727953606410240.0000 - val_mse: 5727953606410240.0000\n",
            "Epoch 1220/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 529790121541632.0000 - mse: 529790121541632.0000 - val_loss: 5726398828249088.0000 - val_mse: 5726398828249088.0000\n",
            "Epoch 1221/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 528325973901312.0000 - mse: 528325973901312.0000 - val_loss: 5724825796476928.0000 - val_mse: 5724825796476928.0000\n",
            "Epoch 1222/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 526864779051008.0000 - mse: 526864779051008.0000 - val_loss: 5723235584835584.0000 - val_mse: 5723235584835584.0000\n",
            "Epoch 1223/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 525405664575488.0000 - mse: 525405664575488.0000 - val_loss: 5721647520677888.0000 - val_mse: 5721647520677888.0000\n",
            "Epoch 1224/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 523951985917952.0000 - mse: 523951985917952.0000 - val_loss: 5720122807287808.0000 - val_mse: 5720122807287808.0000\n",
            "Epoch 1225/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 522501763366912.0000 - mse: 522501763366912.0000 - val_loss: 5718540111839232.0000 - val_mse: 5718540111839232.0000\n",
            "Epoch 1226/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 521049695322112.0000 - mse: 521049695322112.0000 - val_loss: 5716968153808896.0000 - val_mse: 5716968153808896.0000\n",
            "Epoch 1227/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 519603734183936.0000 - mse: 519603734183936.0000 - val_loss: 5715441829806080.0000 - val_mse: 5715441829806080.0000\n",
            "Epoch 1228/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 518161665359872.0000 - mse: 518161665359872.0000 - val_loss: 5713855376261120.0000 - val_mse: 5713855376261120.0000\n",
            "Epoch 1229/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 516717381943296.0000 - mse: 516717381943296.0000 - val_loss: 5712297376874496.0000 - val_mse: 5712297376874496.0000\n",
            "Epoch 1230/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 515284473479168.0000 - mse: 515284473479168.0000 - val_loss: 5710739377487872.0000 - val_mse: 5710739377487872.0000\n",
            "Epoch 1231/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 513843981713408.0000 - mse: 513843981713408.0000 - val_loss: 5709162587619328.0000 - val_mse: 5709162587619328.0000\n",
            "Epoch 1232/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 512416072859648.0000 - mse: 512416072859648.0000 - val_loss: 5707628747423744.0000 - val_mse: 5707628747423744.0000\n",
            "Epoch 1233/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 510983734820864.0000 - mse: 510983734820864.0000 - val_loss: 5706083632939008.0000 - val_mse: 5706083632939008.0000\n",
            "Epoch 1234/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 509559584063488.0000 - mse: 509559584063488.0000 - val_loss: 5704537444712448.0000 - val_mse: 5704537444712448.0000\n",
            "Epoch 1235/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 508130265923584.0000 - mse: 508130265923584.0000 - val_loss: 5702996625195008.0000 - val_mse: 5702996625195008.0000\n",
            "Epoch 1236/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 506711282548736.0000 - mse: 506711282548736.0000 - val_loss: 5701421445939200.0000 - val_mse: 5701421445939200.0000\n",
            "Epoch 1237/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 505296090824704.0000 - mse: 505296090824704.0000 - val_loss: 5699838750490624.0000 - val_mse: 5699838750490624.0000\n",
            "Epoch 1238/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 503875261956096.0000 - mse: 503875261956096.0000 - val_loss: 5698317795196928.0000 - val_mse: 5698317795196928.0000\n",
            "Epoch 1239/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 502466009366528.0000 - mse: 502466009366528.0000 - val_loss: 5696812409159680.0000 - val_mse: 5696812409159680.0000\n",
            "Epoch 1240/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 501054273748992.0000 - mse: 501054273748992.0000 - val_loss: 5695279642705920.0000 - val_mse: 5695279642705920.0000\n",
            "Epoch 1241/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 499645692248064.0000 - mse: 499645692248064.0000 - val_loss: 5693679767388160.0000 - val_mse: 5693679767388160.0000\n",
            "Epoch 1242/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 498241707704320.0000 - mse: 498241707704320.0000 - val_loss: 5692122841743360.0000 - val_mse: 5692122841743360.0000\n",
            "Epoch 1243/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 496843360305152.0000 - mse: 496843360305152.0000 - val_loss: 5690551420583936.0000 - val_mse: 5690551420583936.0000\n",
            "Epoch 1244/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 495444274708480.0000 - mse: 495444274708480.0000 - val_loss: 5689047645159424.0000 - val_mse: 5689047645159424.0000\n",
            "Epoch 1245/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 494046430625792.0000 - mse: 494046430625792.0000 - val_loss: 5687515952447488.0000 - val_mse: 5687515952447488.0000\n",
            "Epoch 1246/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 492652814401536.0000 - mse: 492652814401536.0000 - val_loss: 5686001439604736.0000 - val_mse: 5686001439604736.0000\n",
            "Epoch 1247/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 491262855610368.0000 - mse: 491262855610368.0000 - val_loss: 5684443440218112.0000 - val_mse: 5684443440218112.0000\n",
            "Epoch 1248/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 489872896819200.0000 - mse: 489872896819200.0000 - val_loss: 5682884367089664.0000 - val_mse: 5682884367089664.0000\n",
            "Epoch 1249/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 488490689101824.0000 - mse: 488490689101824.0000 - val_loss: 5681311872188416.0000 - val_mse: 5681311872188416.0000\n",
            "Epoch 1250/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 487107172761600.0000 - mse: 487107172761600.0000 - val_loss: 5679813465473024.0000 - val_mse: 5679813465473024.0000\n",
            "Epoch 1251/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 485727078973440.0000 - mse: 485727078973440.0000 - val_loss: 5678294120792064.0000 - val_mse: 5678294120792064.0000\n",
            "Epoch 1252/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 484347555610624.0000 - mse: 484347555610624.0000 - val_loss: 5676743100727296.0000 - val_mse: 5676743100727296.0000\n",
            "Epoch 1253/2000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 482976957726720.0000 - mse: 482976957726720.0000 - val_loss: 5675219461079040.0000 - val_mse: 5675219461079040.0000\n",
            "Epoch 1254/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 481603105062912.0000 - mse: 481603105062912.0000 - val_loss: 5673652871757824.0000 - val_mse: 5673652871757824.0000\n",
            "Epoch 1255/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 480236298829824.0000 - mse: 480236298829824.0000 - val_loss: 5672156612526080.0000 - val_mse: 5672156612526080.0000\n",
            "Epoch 1256/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 478866372034560.0000 - mse: 478866372034560.0000 - val_loss: 5670627604168704.0000 - val_mse: 5670627604168704.0000\n",
            "Epoch 1257/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 477506612232192.0000 - mse: 477506612232192.0000 - val_loss: 5669108796358656.0000 - val_mse: 5669108796358656.0000\n",
            "Epoch 1258/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 476146147786752.0000 - mse: 476146147786752.0000 - val_loss: 5667598041612288.0000 - val_mse: 5667598041612288.0000\n",
            "Epoch 1259/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 474787260399616.0000 - mse: 474787260399616.0000 - val_loss: 5666081918156800.0000 - val_mse: 5666081918156800.0000\n",
            "Epoch 1260/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 473431460020224.0000 - mse: 473431460020224.0000 - val_loss: 5664543782993920.0000 - val_mse: 5664543782993920.0000\n",
            "Epoch 1261/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 472080692805632.0000 - mse: 472080692805632.0000 - val_loss: 5662983636123648.0000 - val_mse: 5662983636123648.0000\n",
            "Epoch 1262/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 470732005965824.0000 - mse: 470732005965824.0000 - val_loss: 5661466975797248.0000 - val_mse: 5661466975797248.0000\n",
            "Epoch 1263/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 469384829075456.0000 - mse: 469384829075456.0000 - val_loss: 5659966421598208.0000 - val_mse: 5659966421598208.0000\n",
            "Epoch 1264/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 468042517577728.0000 - mse: 468042517577728.0000 - val_loss: 5658451908755456.0000 - val_mse: 5658451908755456.0000\n",
            "Epoch 1265/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 466699132338176.0000 - mse: 466699132338176.0000 - val_loss: 5656950817685504.0000 - val_mse: 5656950817685504.0000\n",
            "Epoch 1266/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 465362860638208.0000 - mse: 465362860638208.0000 - val_loss: 5655428788649984.0000 - val_mse: 5655428788649984.0000\n",
            "Epoch 1267/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 464026119176192.0000 - mse: 464026119176192.0000 - val_loss: 5653920718258176.0000 - val_mse: 5653920718258176.0000\n",
            "Epoch 1268/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 462693068701696.0000 - mse: 462693068701696.0000 - val_loss: 5652396541739008.0000 - val_mse: 5652396541739008.0000\n",
            "Epoch 1269/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 461363776323584.0000 - mse: 461363776323584.0000 - val_loss: 5650915851763712.0000 - val_mse: 5650915851763712.0000\n",
            "Epoch 1270/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 460033343094784.0000 - mse: 460033343094784.0000 - val_loss: 5649368589795328.0000 - val_mse: 5649368589795328.0000\n",
            "Epoch 1271/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 458711801790464.0000 - mse: 458711801790464.0000 - val_loss: 5647885752336384.0000 - val_mse: 5647885752336384.0000\n",
            "Epoch 1272/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 457386099736576.0000 - mse: 457386099736576.0000 - val_loss: 5646370165751808.0000 - val_mse: 5646370165751808.0000\n",
            "Epoch 1273/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 456070564675584.0000 - mse: 456070564675584.0000 - val_loss: 5644841694265344.0000 - val_mse: 5644841694265344.0000\n",
            "Epoch 1274/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 454751338627072.0000 - mse: 454751338627072.0000 - val_loss: 5643372815450112.0000 - val_mse: 5643372815450112.0000\n",
            "Epoch 1275/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 453438487920640.0000 - mse: 453438487920640.0000 - val_loss: 5641862597574656.0000 - val_mse: 5641862597574656.0000\n",
            "Epoch 1276/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 452126174085120.0000 - mse: 452126174085120.0000 - val_loss: 5640352916570112.0000 - val_mse: 5640352916570112.0000\n",
            "Epoch 1277/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 450819296067584.0000 - mse: 450819296067584.0000 - val_loss: 5638849678016512.0000 - val_mse: 5638849678016512.0000\n",
            "Epoch 1278/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 449514129326080.0000 - mse: 449514129326080.0000 - val_loss: 5637370061783040.0000 - val_mse: 5637370061783040.0000\n",
            "Epoch 1279/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 448209868554240.0000 - mse: 448209868554240.0000 - val_loss: 5635871118196736.0000 - val_mse: 5635871118196736.0000\n",
            "Epoch 1280/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 446908325691392.0000 - mse: 446908325691392.0000 - val_loss: 5634368953384960.0000 - val_mse: 5634368953384960.0000\n",
            "Epoch 1281/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 445610171826176.0000 - mse: 445610171826176.0000 - val_loss: 5632877525991424.0000 - val_mse: 5632877525991424.0000\n",
            "Epoch 1282/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 444317252452352.0000 - mse: 444317252452352.0000 - val_loss: 5631374287437824.0000 - val_mse: 5631374287437824.0000\n",
            "Epoch 1283/2000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 443024064643072.0000 - mse: 443024064643072.0000 - val_loss: 5629864606433280.0000 - val_mse: 5629864606433280.0000\n",
            "Epoch 1284/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 441734903365632.0000 - mse: 441734903365632.0000 - val_loss: 5628363515363328.0000 - val_mse: 5628363515363328.0000\n",
            "Epoch 1285/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 440446413176832.0000 - mse: 440446413176832.0000 - val_loss: 5626897320902656.0000 - val_mse: 5626897320902656.0000\n",
            "Epoch 1286/2000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 439163526578176.0000 - mse: 439163526578176.0000 - val_loss: 5625427368345600.0000 - val_mse: 5625427368345600.0000\n",
            "Epoch 1287/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 437882653245440.0000 - mse: 437882653245440.0000 - val_loss: 5623920371695616.0000 - val_mse: 5623920371695616.0000\n",
            "Epoch 1288/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 436604833366016.0000 - mse: 436604833366016.0000 - val_loss: 5622433776140288.0000 - val_mse: 5622433776140288.0000\n",
            "Epoch 1289/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 435326174625792.0000 - mse: 435326174625792.0000 - val_loss: 5620915505201152.0000 - val_mse: 5620915505201152.0000\n",
            "Epoch 1290/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 434053253693440.0000 - mse: 434053253693440.0000 - val_loss: 5619444478902272.0000 - val_mse: 5619444478902272.0000\n",
            "Epoch 1291/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 432784191520768.0000 - mse: 432784191520768.0000 - val_loss: 5617970231377920.0000 - val_mse: 5617970231377920.0000\n",
            "Epoch 1292/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 431513954942976.0000 - mse: 431513954942976.0000 - val_loss: 5616498131337216.0000 - val_mse: 5616498131337216.0000\n",
            "Epoch 1293/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 430247912669184.0000 - mse: 430247912669184.0000 - val_loss: 5615021199458304.0000 - val_mse: 5615021199458304.0000\n",
            "Epoch 1294/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 428984118542336.0000 - mse: 428984118542336.0000 - val_loss: 5613524403355648.0000 - val_mse: 5613524403355648.0000\n",
            "Epoch 1295/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 427726464876544.0000 - mse: 427726464876544.0000 - val_loss: 5612029754736640.0000 - val_mse: 5612029754736640.0000\n",
            "Epoch 1296/2000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 426468576329728.0000 - mse: 426468576329728.0000 - val_loss: 5610587182596096.0000 - val_mse: 5610587182596096.0000\n",
            "Epoch 1297/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 425214680760320.0000 - mse: 425214680760320.0000 - val_loss: 5609088239009792.0000 - val_mse: 5609088239009792.0000\n",
            "Epoch 1298/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 423961758269440.0000 - mse: 423961758269440.0000 - val_loss: 5607619360194560.0000 - val_mse: 5607619360194560.0000\n",
            "Epoch 1299/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 422712392548352.0000 - mse: 422712392548352.0000 - val_loss: 5606132764639232.0000 - val_mse: 5606132764639232.0000\n",
            "Epoch 1300/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 421464670994432.0000 - mse: 421464670994432.0000 - val_loss: 5604673012629504.0000 - val_mse: 5604673012629504.0000\n",
            "Epoch 1301/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 420221210853376.0000 - mse: 420221210853376.0000 - val_loss: 5603188564557824.0000 - val_mse: 5603188564557824.0000\n",
            "Epoch 1302/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 418979159998464.0000 - mse: 418979159998464.0000 - val_loss: 5601729886289920.0000 - val_mse: 5601729886289920.0000\n",
            "Epoch 1303/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 417740833685504.0000 - mse: 417740833685504.0000 - val_loss: 5600250806927360.0000 - val_mse: 5600250806927360.0000\n",
            "Epoch 1304/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 416506533904384.0000 - mse: 416506533904384.0000 - val_loss: 5598774948790272.0000 - val_mse: 5598774948790272.0000\n",
            "Epoch 1305/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 415271361708032.0000 - mse: 415271361708032.0000 - val_loss: 5597328618553344.0000 - val_mse: 5597328618553344.0000\n",
            "Epoch 1306/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 414040585142272.0000 - mse: 414040585142272.0000 - val_loss: 5595859202867200.0000 - val_mse: 5595859202867200.0000\n",
            "Epoch 1307/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 412811486298112.0000 - mse: 412811486298112.0000 - val_loss: 5594388713439232.0000 - val_mse: 5594388713439232.0000\n",
            "Epoch 1308/2000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 411585608679424.0000 - mse: 411585608679424.0000 - val_loss: 5592896212303872.0000 - val_mse: 5592896212303872.0000\n",
            "Epoch 1309/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 410363086503936.0000 - mse: 410363086503936.0000 - val_loss: 5591453103292416.0000 - val_mse: 5591453103292416.0000\n",
            "Epoch 1310/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 409143215128576.0000 - mse: 409143215128576.0000 - val_loss: 5589998183120896.0000 - val_mse: 5589998183120896.0000\n",
            "Epoch 1311/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 407923511525376.0000 - mse: 407923511525376.0000 - val_loss: 5588525009338368.0000 - val_mse: 5588525009338368.0000\n",
            "Epoch 1312/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 406707331137536.0000 - mse: 406707331137536.0000 - val_loss: 5587083510939648.0000 - val_mse: 5587083510939648.0000\n",
            "Epoch 1313/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 405495311499264.0000 - mse: 405495311499264.0000 - val_loss: 5585614095253504.0000 - val_mse: 5585614095253504.0000\n",
            "Epoch 1314/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 404285942661120.0000 - mse: 404285942661120.0000 - val_loss: 5584132868407296.0000 - val_mse: 5584132868407296.0000\n",
            "Epoch 1315/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 403076775149568.0000 - mse: 403076775149568.0000 - val_loss: 5582696738717696.0000 - val_mse: 5582696738717696.0000\n",
            "Epoch 1316/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 401872473030656.0000 - mse: 401872473030656.0000 - val_loss: 5581231081127936.0000 - val_mse: 5581231081127936.0000\n",
            "Epoch 1317/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 400671861899264.0000 - mse: 400671861899264.0000 - val_loss: 5579771865989120.0000 - val_mse: 5579771865989120.0000\n",
            "Epoch 1318/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 399472693608448.0000 - mse: 399472693608448.0000 - val_loss: 5578363653586944.0000 - val_mse: 5578363653586944.0000\n",
            "Epoch 1319/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 398274229960704.0000 - mse: 398274229960704.0000 - val_loss: 5576941482541056.0000 - val_mse: 5576941482541056.0000\n",
            "Epoch 1320/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 397080497487872.0000 - mse: 397080497487872.0000 - val_loss: 5575451128889344.0000 - val_mse: 5575451128889344.0000\n",
            "Epoch 1321/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 395890086903808.0000 - mse: 395890086903808.0000 - val_loss: 5574017683554304.0000 - val_mse: 5574017683554304.0000\n",
            "Epoch 1322/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 394700045418496.0000 - mse: 394700045418496.0000 - val_loss: 5572518203097088.0000 - val_mse: 5572518203097088.0000\n",
            "Epoch 1323/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 393515439751168.0000 - mse: 393515439751168.0000 - val_loss: 5571076167827456.0000 - val_mse: 5571076167827456.0000\n",
            "Epoch 1324/2000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 392330699866112.0000 - mse: 392330699866112.0000 - val_loss: 5569659365490688.0000 - val_mse: 5569659365490688.0000\n",
            "Epoch 1325/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 391145959981056.0000 - mse: 391145959981056.0000 - val_loss: 5568254911184896.0000 - val_mse: 5568254911184896.0000\n",
            "Epoch 1326/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 389970313347072.0000 - mse: 389970313347072.0000 - val_loss: 5566811802173440.0000 - val_mse: 5566811802173440.0000\n",
            "Epoch 1327/2000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 388795706900480.0000 - mse: 388795706900480.0000 - val_loss: 5565377283096576.0000 - val_mse: 5565377283096576.0000\n",
            "Epoch 1328/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 387619959603200.0000 - mse: 387619959603200.0000 - val_loss: 5563889613799424.0000 - val_mse: 5563889613799424.0000\n",
            "Epoch 1329/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 386449010589696.0000 - mse: 386449010589696.0000 - val_loss: 5562429324918784.0000 - val_mse: 5562429324918784.0000\n",
            "Epoch 1330/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 385282390097920.0000 - mse: 385282390097920.0000 - val_loss: 5561027554967552.0000 - val_mse: 5561027554967552.0000\n",
            "Epoch 1331/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 384113890557952.0000 - mse: 384113890557952.0000 - val_loss: 5559603236438016.0000 - val_mse: 5559603236438016.0000\n",
            "Epoch 1332/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 382950289965056.0000 - mse: 382950289965056.0000 - val_loss: 5558168180490240.0000 - val_mse: 5558168180490240.0000\n",
            "Epoch 1333/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 381790447468544.0000 - mse: 381790447468544.0000 - val_loss: 5556759968088064.0000 - val_mse: 5556759968088064.0000\n",
            "Epoch 1334/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 380633255772160.0000 - mse: 380633255772160.0000 - val_loss: 5555309342883840.0000 - val_mse: 5555309342883840.0000\n",
            "Epoch 1335/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 379477473361920.0000 - mse: 379477473361920.0000 - val_loss: 5553843685294080.0000 - val_mse: 5553843685294080.0000\n",
            "Epoch 1336/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 378324677296128.0000 - mse: 378324677296128.0000 - val_loss: 5552405408120832.0000 - val_mse: 5552405408120832.0000\n",
            "Epoch 1337/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 377176444633088.0000 - mse: 377176444633088.0000 - val_loss: 5551015986200576.0000 - val_mse: 5551015986200576.0000\n",
            "Epoch 1338/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 376027272445952.0000 - mse: 376027272445952.0000 - val_loss: 5549560529158144.0000 - val_mse: 5549560529158144.0000\n",
            "Epoch 1339/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 374882562998272.0000 - mse: 374882562998272.0000 - val_loss: 5548171644108800.0000 - val_mse: 5548171644108800.0000\n",
            "Epoch 1340/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 373736075165696.0000 - mse: 373736075165696.0000 - val_loss: 5546733903806464.0000 - val_mse: 5546733903806464.0000\n",
            "Epoch 1341/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 372596902199296.0000 - mse: 372596902199296.0000 - val_loss: 5545302605955072.0000 - val_mse: 5545302605955072.0000\n",
            "Epoch 1342/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 371461587992576.0000 - mse: 371461587992576.0000 - val_loss: 5543905667842048.0000 - val_mse: 5543905667842048.0000\n",
            "Epoch 1343/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 370324361183232.0000 - mse: 370324361183232.0000 - val_loss: 5542445378961408.0000 - val_mse: 5542445378961408.0000\n",
            "Epoch 1344/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 369193878814720.0000 - mse: 369193878814720.0000 - val_loss: 5541069915684864.0000 - val_mse: 5541069915684864.0000\n",
            "Epoch 1345/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 368063731990528.0000 - mse: 368063731990528.0000 - val_loss: 5539634322866176.0000 - val_mse: 5539634322866176.0000\n",
            "Epoch 1346/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 366935095115776.0000 - mse: 366935095115776.0000 - val_loss: 5538224499851264.0000 - val_mse: 5538224499851264.0000\n",
            "Epoch 1347/2000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 365811860504576.0000 - mse: 365811860504576.0000 - val_loss: 5536779243356160.0000 - val_mse: 5536779243356160.0000\n",
            "Epoch 1348/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 364688760111104.0000 - mse: 364688760111104.0000 - val_loss: 5535364051632128.0000 - val_mse: 5535364051632128.0000\n",
            "Epoch 1349/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 363568344072192.0000 - mse: 363568344072192.0000 - val_loss: 5533982145904640.0000 - val_mse: 5533982145904640.0000\n",
            "Epoch 1350/2000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 362449807081472.0000 - mse: 362449807081472.0000 - val_loss: 5532535815667712.0000 - val_mse: 5532535815667712.0000\n",
            "Epoch 1351/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 361333954445312.0000 - mse: 361333954445312.0000 - val_loss: 5531185585324032.0000 - val_mse: 5531185585324032.0000\n",
            "Epoch 1352/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 360222296113152.0000 - mse: 360222296113152.0000 - val_loss: 5529744086925312.0000 - val_mse: 5529744086925312.0000\n",
            "Epoch 1353/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 359114395877376.0000 - mse: 359114395877376.0000 - val_loss: 5528327284588544.0000 - val_mse: 5528327284588544.0000\n",
            "Epoch 1354/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 358006764077056.0000 - mse: 358006764077056.0000 - val_loss: 5526939473281024.0000 - val_mse: 5526939473281024.0000\n",
            "Epoch 1355/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 356902219284480.0000 - mse: 356902219284480.0000 - val_loss: 5525516765364224.0000 - val_mse: 5525516765364224.0000\n",
            "Epoch 1356/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 355800996380672.0000 - mse: 355800996380672.0000 - val_loss: 5524103721123840.0000 - val_mse: 5524103721123840.0000\n",
            "Epoch 1357/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 354700713000960.0000 - mse: 354700713000960.0000 - val_loss: 5522693361238016.0000 - val_mse: 5522693361238016.0000\n",
            "Epoch 1358/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 353601738244096.0000 - mse: 353601738244096.0000 - val_loss: 5521300181221376.0000 - val_mse: 5521300181221376.0000\n",
            "Epoch 1359/2000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 352508434186240.0000 - mse: 352508434186240.0000 - val_loss: 5519912906784768.0000 - val_mse: 5519912906784768.0000\n",
            "Epoch 1360/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 351414559703040.0000 - mse: 351414559703040.0000 - val_loss: 5518511673704448.0000 - val_mse: 5518511673704448.0000\n",
            "Epoch 1361/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 350325751939072.0000 - mse: 350325751939072.0000 - val_loss: 5517102924431360.0000 - val_mse: 5517102924431360.0000\n",
            "Epoch 1362/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 349238957441024.0000 - mse: 349238957441024.0000 - val_loss: 5515732829863936.0000 - val_mse: 5515732829863936.0000\n",
            "Epoch 1363/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 348154075545600.0000 - mse: 348154075545600.0000 - val_loss: 5514320322494464.0000 - val_mse: 5514320322494464.0000\n",
            "Epoch 1364/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 347070066065408.0000 - mse: 347070066065408.0000 - val_loss: 5512928216219648.0000 - val_mse: 5512928216219648.0000\n",
            "Epoch 1365/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 345992264155136.0000 - mse: 345992264155136.0000 - val_loss: 5511531278106624.0000 - val_mse: 5511531278106624.0000\n",
            "Epoch 1366/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 344913254285312.0000 - mse: 344913254285312.0000 - val_loss: 5510129508155392.0000 - val_mse: 5510129508155392.0000\n",
            "Epoch 1367/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 343839948668928.0000 - mse: 343839948668928.0000 - val_loss: 5508740623106048.0000 - val_mse: 5508740623106048.0000\n",
            "Epoch 1368/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 342768287219712.0000 - mse: 342768287219712.0000 - val_loss: 5507347979960320.0000 - val_mse: 5507347979960320.0000\n",
            "Epoch 1369/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 341697397522432.0000 - mse: 341697397522432.0000 - val_loss: 5505963926749184.0000 - val_mse: 5505963926749184.0000\n",
            "Epoch 1370/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 340632178524160.0000 - mse: 340632178524160.0000 - val_loss: 5504606180212736.0000 - val_mse: 5504606180212736.0000\n",
            "Epoch 1371/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 339564577161216.0000 - mse: 339564577161216.0000 - val_loss: 5503193135972352.0000 - val_mse: 5503193135972352.0000\n",
            "Epoch 1372/2000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 338501807636480.0000 - mse: 338501807636480.0000 - val_loss: 5501811767115776.0000 - val_mse: 5501811767115776.0000\n",
            "Epoch 1373/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 337441454030848.0000 - mse: 337441454030848.0000 - val_loss: 5500420197711872.0000 - val_mse: 5500420197711872.0000\n",
            "Epoch 1374/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 336385361838080.0000 - mse: 336385361838080.0000 - val_loss: 5499005542858752.0000 - val_mse: 5499005542858752.0000\n",
            "Epoch 1375/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 335330712485888.0000 - mse: 335330712485888.0000 - val_loss: 5497667123675136.0000 - val_mse: 5497667123675136.0000\n",
            "Epoch 1376/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 334275157164032.0000 - mse: 334275157164032.0000 - val_loss: 5496290586656768.0000 - val_mse: 5496290586656768.0000\n",
            "Epoch 1377/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 333226849599488.0000 - mse: 333226849599488.0000 - val_loss: 5494890427318272.0000 - val_mse: 5494890427318272.0000\n",
            "Epoch 1378/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 332180689518592.0000 - mse: 332180689518592.0000 - val_loss: 5493529996427264.0000 - val_mse: 5493529996427264.0000\n",
            "Epoch 1379/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 331134126784512.0000 - mse: 331134126784512.0000 - val_loss: 5492157217505280.0000 - val_mse: 5492157217505280.0000\n",
            "Epoch 1380/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 330091859017728.0000 - mse: 330091859017728.0000 - val_loss: 5490749005103104.0000 - val_mse: 5490749005103104.0000\n",
            "Epoch 1381/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 329049725468672.0000 - mse: 329049725468672.0000 - val_loss: 5489386426728448.0000 - val_mse: 5489386426728448.0000\n",
            "Epoch 1382/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 328012289540096.0000 - mse: 328012289540096.0000 - val_loss: 5488025458966528.0000 - val_mse: 5488025458966528.0000\n",
            "Epoch 1383/2000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 326977403748352.0000 - mse: 326977403748352.0000 - val_loss: 5486669859913728.0000 - val_mse: 5486669859913728.0000\n",
            "Epoch 1384/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 325944799657984.0000 - mse: 325944799657984.0000 - val_loss: 5485280974864384.0000 - val_mse: 5485280974864384.0000\n",
            "Epoch 1385/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 324911893577728.0000 - mse: 324911893577728.0000 - val_loss: 5483915712135168.0000 - val_mse: 5483915712135168.0000\n",
            "Epoch 1386/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 323885832601600.0000 - mse: 323885832601600.0000 - val_loss: 5482525216473088.0000 - val_mse: 5482525216473088.0000\n",
            "Epoch 1387/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 322858597220352.0000 - mse: 322858597220352.0000 - val_loss: 5481162638098432.0000 - val_mse: 5481162638098432.0000\n",
            "Epoch 1388/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 321836529221632.0000 - mse: 321836529221632.0000 - val_loss: 5479810797142016.0000 - val_mse: 5479810797142016.0000\n",
            "Epoch 1389/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 320814863876096.0000 - mse: 320814863876096.0000 - val_loss: 5478442850058240.0000 - val_mse: 5478442850058240.0000\n",
            "Epoch 1390/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 319797258616832.0000 - mse: 319797258616832.0000 - val_loss: 5477077050458112.0000 - val_mse: 5477077050458112.0000\n",
            "Epoch 1391/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 318780559327232.0000 - mse: 318780559327232.0000 - val_loss: 5475680649216000.0000 - val_mse: 5475680649216000.0000\n",
            "Epoch 1392/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 317766242402304.0000 - mse: 317766242402304.0000 - val_loss: 5474355114934272.0000 - val_mse: 5474355114934272.0000\n",
            "Epoch 1393/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 316754374950912.0000 - mse: 316754374950912.0000 - val_loss: 5472996831526912.0000 - val_mse: 5472996831526912.0000\n",
            "Epoch 1394/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 315744789200896.0000 - mse: 315744789200896.0000 - val_loss: 5471652506763264.0000 - val_mse: 5471652506763264.0000\n",
            "Epoch 1395/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 314738760220672.0000 - mse: 314738760220672.0000 - val_loss: 5470300128935936.0000 - val_mse: 5470300128935936.0000\n",
            "Epoch 1396/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 313736959098880.0000 - mse: 313736959098880.0000 - val_loss: 5468926276272128.0000 - val_mse: 5468926276272128.0000\n",
            "Epoch 1397/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 312735392858112.0000 - mse: 312735392858112.0000 - val_loss: 5467574435315712.0000 - val_mse: 5467574435315712.0000\n",
            "Epoch 1398/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 311735001022464.0000 - mse: 311735001022464.0000 - val_loss: 5466231184293888.0000 - val_mse: 5466231184293888.0000\n",
            "Epoch 1399/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 310738568609792.0000 - mse: 310738568609792.0000 - val_loss: 5464873974628352.0000 - val_mse: 5464873974628352.0000\n",
            "Epoch 1400/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 309742840840192.0000 - mse: 309742840840192.0000 - val_loss: 5463507101286400.0000 - val_mse: 5463507101286400.0000\n",
            "Epoch 1401/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 308751240265728.0000 - mse: 308751240265728.0000 - val_loss: 5462168145231872.0000 - val_mse: 5462168145231872.0000\n",
            "Epoch 1402/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 307760881205248.0000 - mse: 307760881205248.0000 - val_loss: 5460831336660992.0000 - val_mse: 5460831336660992.0000\n",
            "Epoch 1403/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 306774649339904.0000 - mse: 306774649339904.0000 - val_loss: 5459463389577216.0000 - val_mse: 5459463389577216.0000\n",
            "Epoch 1404/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 305788786573312.0000 - mse: 305788786573312.0000 - val_loss: 5458113696104448.0000 - val_mse: 5458113696104448.0000\n",
            "Epoch 1405/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 304806648348672.0000 - mse: 304806648348672.0000 - val_loss: 5456758633922560.0000 - val_mse: 5456758633922560.0000\n",
            "Epoch 1406/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 303826926043136.0000 - mse: 303826926043136.0000 - val_loss: 5455423972835328.0000 - val_mse: 5455423972835328.0000\n",
            "Epoch 1407/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 302849082785792.0000 - mse: 302849082785792.0000 - val_loss: 5454119376519168.0000 - val_mse: 5454119376519168.0000\n",
            "Epoch 1408/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 301872413933568.0000 - mse: 301872413933568.0000 - val_loss: 5452756798144512.0000 - val_mse: 5452756798144512.0000\n",
            "Epoch 1409/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 300898496544768.0000 - mse: 300898496544768.0000 - val_loss: 5451391535415296.0000 - val_mse: 5451391535415296.0000\n",
            "Epoch 1410/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 299928505024512.0000 - mse: 299928505024512.0000 - val_loss: 5450076738551808.0000 - val_mse: 5450076738551808.0000\n",
            "Epoch 1411/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 298960224780288.0000 - mse: 298960224780288.0000 - val_loss: 5448746372431872.0000 - val_mse: 5448746372431872.0000\n",
            "Epoch 1412/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 297993286713344.0000 - mse: 297993286713344.0000 - val_loss: 5447407953248256.0000 - val_mse: 5447407953248256.0000\n",
            "Epoch 1413/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 297029670535168.0000 - mse: 297029670535168.0000 - val_loss: 5446091008901120.0000 - val_mse: 5446091008901120.0000\n",
            "Epoch 1414/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 296066792554496.0000 - mse: 296066792554496.0000 - val_loss: 5444729504268288.0000 - val_mse: 5444729504268288.0000\n",
            "Epoch 1415/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 295109887262720.0000 - mse: 295109887262720.0000 - val_loss: 5443400211890176.0000 - val_mse: 5443400211890176.0000\n",
            "Epoch 1416/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 294152579317760.0000 - mse: 294152579317760.0000 - val_loss: 5442054813384704.0000 - val_mse: 5442054813384704.0000\n",
            "Epoch 1417/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 293197418856448.0000 - mse: 293197418856448.0000 - val_loss: 5440746458972160.0000 - val_mse: 5440746458972160.0000\n",
            "Epoch 1418/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 292244103888896.0000 - mse: 292244103888896.0000 - val_loss: 5439429514625024.0000 - val_mse: 5439429514625024.0000\n",
            "Epoch 1419/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 291295922749440.0000 - mse: 291295922749440.0000 - val_loss: 5438095927279616.0000 - val_mse: 5438095927279616.0000\n",
            "Epoch 1420/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 290348278480896.0000 - mse: 290348278480896.0000 - val_loss: 5436768782385152.0000 - val_mse: 5436768782385152.0000\n",
            "Epoch 1421/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 289404090318848.0000 - mse: 289404090318848.0000 - val_loss: 5435428215717888.0000 - val_mse: 5435428215717888.0000\n",
            "Epoch 1422/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 288461479215104.0000 - mse: 288461479215104.0000 - val_loss: 5434080132857856.0000 - val_mse: 5434080132857856.0000\n",
            "Epoch 1423/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 287520210288640.0000 - mse: 287520210288640.0000 - val_loss: 5432786273959936.0000 - val_mse: 5432786273959936.0000\n",
            "Epoch 1424/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 286580954628096.0000 - mse: 286580954628096.0000 - val_loss: 5431443559809024.0000 - val_mse: 5431443559809024.0000\n",
            "Epoch 1425/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 285646463696896.0000 - mse: 285646463696896.0000 - val_loss: 5430144332201984.0000 - val_mse: 5430144332201984.0000\n",
            "Epoch 1426/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 284712408973312.0000 - mse: 284712408973312.0000 - val_loss: 5428829535338496.0000 - val_mse: 5428829535338496.0000\n",
            "Epoch 1427/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 283780635951104.0000 - mse: 283780635951104.0000 - val_loss: 5427513127862272.0000 - val_mse: 5427513127862272.0000\n",
            "Epoch 1428/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 282852117708800.0000 - mse: 282852117708800.0000 - val_loss: 5426175245549568.0000 - val_mse: 5426175245549568.0000\n",
            "Epoch 1429/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 281926116048896.0000 - mse: 281926116048896.0000 - val_loss: 5424863133040640.0000 - val_mse: 5424863133040640.0000\n",
            "Epoch 1430/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 281000483487744.0000 - mse: 281000483487744.0000 - val_loss: 5423577327206400.0000 - val_mse: 5423577327206400.0000\n",
            "Epoch 1431/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 280078609022976.0000 - mse: 280078609022976.0000 - val_loss: 5422271657148416.0000 - val_mse: 5422271657148416.0000\n",
            "Epoch 1432/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 279158143844352.0000 - mse: 279158143844352.0000 - val_loss: 5420948270350336.0000 - val_mse: 5420948270350336.0000\n",
            "Epoch 1433/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 278241570979840.0000 - mse: 278241570979840.0000 - val_loss: 5419623809810432.0000 - val_mse: 5419623809810432.0000\n",
            "Epoch 1434/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 277325014892544.0000 - mse: 277325014892544.0000 - val_loss: 5418322971590656.0000 - val_mse: 5418322971590656.0000\n",
            "Epoch 1435/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 276414263721984.0000 - mse: 276414263721984.0000 - val_loss: 5417004416630784.0000 - val_mse: 5417004416630784.0000\n",
            "Epoch 1436/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 275503411888128.0000 - mse: 275503411888128.0000 - val_loss: 5415690693509120.0000 - val_mse: 5415690693509120.0000\n",
            "Epoch 1437/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 274594002894848.0000 - mse: 274594002894848.0000 - val_loss: 5414409182642176.0000 - val_mse: 5414409182642176.0000\n",
            "Epoch 1438/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 273687798349824.0000 - mse: 273687798349824.0000 - val_loss: 5413063247265792.0000 - val_mse: 5413063247265792.0000\n",
            "Epoch 1439/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 272784160718848.0000 - mse: 272784160718848.0000 - val_loss: 5411794084429824.0000 - val_mse: 5411794084429824.0000\n",
            "Epoch 1440/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 271881630384128.0000 - mse: 271881630384128.0000 - val_loss: 5410463181438976.0000 - val_mse: 5410463181438976.0000\n",
            "Epoch 1441/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 270982287720448.0000 - mse: 270982287720448.0000 - val_loss: 5409166638186496.0000 - val_mse: 5409166638186496.0000\n",
            "Epoch 1442/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 270085428084736.0000 - mse: 270085428084736.0000 - val_loss: 5407884053577728.0000 - val_mse: 5407884053577728.0000\n",
            "Epoch 1443/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 269189323423744.0000 - mse: 269189323423744.0000 - val_loss: 5406584825970688.0000 - val_mse: 5406584825970688.0000\n",
            "Epoch 1444/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 268298604249088.0000 - mse: 268298604249088.0000 - val_loss: 5405283450880000.0000 - val_mse: 5405283450880000.0000\n",
            "Epoch 1445/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 267406761000960.0000 - mse: 267406761000960.0000 - val_loss: 5403982075789312.0000 - val_mse: 5403982075789312.0000\n",
            "Epoch 1446/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 266519397269504.0000 - mse: 266519397269504.0000 - val_loss: 5402699491180544.0000 - val_mse: 5402699491180544.0000\n",
            "Epoch 1447/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 265634902441984.0000 - mse: 265634902441984.0000 - val_loss: 5401383083704320.0000 - val_mse: 5401383083704320.0000\n",
            "Epoch 1448/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 264750407614464.0000 - mse: 264750407614464.0000 - val_loss: 5400119289577472.0000 - val_mse: 5400119289577472.0000\n",
            "Epoch 1449/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 263867791835136.0000 - mse: 263867791835136.0000 - val_loss: 5398830262517760.0000 - val_mse: 5398830262517760.0000\n",
            "Epoch 1450/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 262989672349696.0000 - mse: 262989672349696.0000 - val_loss: 5397524055588864.0000 - val_mse: 5397524055588864.0000\n",
            "Epoch 1451/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 262113029259264.0000 - mse: 262113029259264.0000 - val_loss: 5396256503365632.0000 - val_mse: 5396256503365632.0000\n",
            "Epoch 1452/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 261238734979072.0000 - mse: 261238734979072.0000 - val_loss: 5394959960113152.0000 - val_mse: 5394959960113152.0000\n",
            "Epoch 1453/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 260366286192640.0000 - mse: 260366286192640.0000 - val_loss: 5393675764891648.0000 - val_mse: 5393675764891648.0000\n",
            "Epoch 1454/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 259496186216448.0000 - mse: 259496186216448.0000 - val_loss: 5392379221639168.0000 - val_mse: 5392379221639168.0000\n",
            "Epoch 1455/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 258630179880960.0000 - mse: 258630179880960.0000 - val_loss: 5391132607381504.0000 - val_mse: 5391132607381504.0000\n",
            "Epoch 1456/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 257761489190912.0000 - mse: 257761489190912.0000 - val_loss: 5389817273647104.0000 - val_mse: 5389817273647104.0000\n",
            "Epoch 1457/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 256898670526464.0000 - mse: 256898670526464.0000 - val_loss: 5388535225909248.0000 - val_mse: 5388535225909248.0000\n",
            "Epoch 1458/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 256037261148160.0000 - mse: 256037261148160.0000 - val_loss: 5387272505524224.0000 - val_mse: 5387272505524224.0000\n",
            "Epoch 1459/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 255177747595264.0000 - mse: 255177747595264.0000 - val_loss: 5386008711397376.0000 - val_mse: 5386008711397376.0000\n",
            "Epoch 1460/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 254319878209536.0000 - mse: 254319878209536.0000 - val_loss: 5384686935212032.0000 - val_mse: 5384686935212032.0000\n",
            "Epoch 1461/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 253466052132864.0000 - mse: 253466052132864.0000 - val_loss: 5383421530472448.0000 - val_mse: 5383421530472448.0000\n",
            "Epoch 1462/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 252612846813184.0000 - mse: 252612846813184.0000 - val_loss: 5382113176059904.0000 - val_mse: 5382113176059904.0000\n",
            "Epoch 1463/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 251763600916480.0000 - mse: 251763600916480.0000 - val_loss: 5380835423289344.0000 - val_mse: 5380835423289344.0000\n",
            "Epoch 1464/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 250913868480512.0000 - mse: 250913868480512.0000 - val_loss: 5379583440322560.0000 - val_mse: 5379583440322560.0000\n",
            "Epoch 1465/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 250068196130816.0000 - mse: 250068196130816.0000 - val_loss: 5378341121032192.0000 - val_mse: 5378341121032192.0000\n",
            "Epoch 1466/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 249223362641920.0000 - mse: 249223362641920.0000 - val_loss: 5377097728000000.0000 - val_mse: 5377097728000000.0000\n",
            "Epoch 1467/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 248384401178624.0000 - mse: 248384401178624.0000 - val_loss: 5375780246781952.0000 - val_mse: 5375780246781952.0000\n",
            "Epoch 1468/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 247543610998784.0000 - mse: 247543610998784.0000 - val_loss: 5374518063267840.0000 - val_mse: 5374518063267840.0000\n",
            "Epoch 1469/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 246706193039360.0000 - mse: 246706193039360.0000 - val_loss: 5373240847368192.0000 - val_mse: 5373240847368192.0000\n",
            "Epoch 1470/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 245871341993984.0000 - mse: 245871341993984.0000 - val_loss: 5371987790659584.0000 - val_mse: 5371987790659584.0000\n",
            "Epoch 1471/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 245038520991744.0000 - mse: 245038520991744.0000 - val_loss: 5370719164694528.0000 - val_mse: 5370719164694528.0000\n",
            "Epoch 1472/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 244207243493376.0000 - mse: 244207243493376.0000 - val_loss: 5369466107985920.0000 - val_mse: 5369466107985920.0000\n",
            "Epoch 1473/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 243379908640768.0000 - mse: 243379908640768.0000 - val_loss: 5368187818344448.0000 - val_mse: 5368187818344448.0000\n",
            "Epoch 1474/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 242552993218560.0000 - mse: 242552993218560.0000 - val_loss: 5366943351570432.0000 - val_mse: 5366943351570432.0000\n",
            "Epoch 1475/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 241727201869824.0000 - mse: 241727201869824.0000 - val_loss: 5365679020572672.0000 - val_mse: 5365679020572672.0000\n",
            "Epoch 1476/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 240906544349184.0000 - mse: 240906544349184.0000 - val_loss: 5364406099640320.0000 - val_mse: 5364406099640320.0000\n",
            "Epoch 1477/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 240086339813376.0000 - mse: 240086339813376.0000 - val_loss: 5363164317220864.0000 - val_mse: 5363164317220864.0000\n",
            "Epoch 1478/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 239266319826944.0000 - mse: 239266319826944.0000 - val_loss: 5361928977252352.0000 - val_mse: 5361928977252352.0000\n",
            "Epoch 1479/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 238452020871168.0000 - mse: 238452020871168.0000 - val_loss: 5360696321638400.0000 - val_mse: 5360696321638400.0000\n",
            "Epoch 1480/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 237638795657216.0000 - mse: 237638795657216.0000 - val_loss: 5359429306286080.0000 - val_mse: 5359429306286080.0000\n",
            "Epoch 1481/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 236827281719296.0000 - mse: 236827281719296.0000 - val_loss: 5358151016644608.0000 - val_mse: 5358151016644608.0000\n",
            "Epoch 1482/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 236017546166272.0000 - mse: 236017546166272.0000 - val_loss: 5356883464421376.0000 - val_mse: 5356883464421376.0000\n",
            "Epoch 1483/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 235209538666496.0000 - mse: 235209538666496.0000 - val_loss: 5355624502132736.0000 - val_mse: 5355624502132736.0000\n",
            "Epoch 1484/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 234403796090880.0000 - mse: 234403796090880.0000 - val_loss: 5354414931968000.0000 - val_mse: 5354414931968000.0000\n",
            "Epoch 1485/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 233602365259776.0000 - mse: 233602365259776.0000 - val_loss: 5353180128870400.0000 - val_mse: 5353180128870400.0000\n",
            "Epoch 1486/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 232801286750208.0000 - mse: 232801286750208.0000 - val_loss: 5351935662096384.0000 - val_mse: 5351935662096384.0000\n",
            "Epoch 1487/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 232002003402752.0000 - mse: 232002003402752.0000 - val_loss: 5350686900355072.0000 - val_mse: 5350686900355072.0000\n",
            "Epoch 1488/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 231204934647808.0000 - mse: 231204934647808.0000 - val_loss: 5349403778875392.0000 - val_mse: 5349403778875392.0000\n",
            "Epoch 1489/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 230412378963968.0000 - mse: 230412378963968.0000 - val_loss: 5348178639454208.0000 - val_mse: 5348178639454208.0000\n",
            "Epoch 1490/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 229618128781312.0000 - mse: 229618128781312.0000 - val_loss: 5346947057582080.0000 - val_mse: 5346947057582080.0000\n",
            "Epoch 1491/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 228829113090048.0000 - mse: 228829113090048.0000 - val_loss: 5345732655579136.0000 - val_mse: 5345732655579136.0000\n",
            "Epoch 1492/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 228041993224192.0000 - mse: 228041993224192.0000 - val_loss: 5344509126770688.0000 - val_mse: 5344509126770688.0000\n",
            "Epoch 1493/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 227253212413952.0000 - mse: 227253212413952.0000 - val_loss: 5343236742709248.0000 - val_mse: 5343236742709248.0000\n",
            "Epoch 1494/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 226469380882432.0000 - mse: 226469380882432.0000 - val_loss: 5341998181515264.0000 - val_mse: 5341998181515264.0000\n",
            "Epoch 1495/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 225688049156096.0000 - mse: 225688049156096.0000 - val_loss: 5340748346032128.0000 - val_mse: 5340748346032128.0000\n",
            "Epoch 1496/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 224909619888128.0000 - mse: 224909619888128.0000 - val_loss: 5339536091512832.0000 - val_mse: 5339536091512832.0000\n",
            "Epoch 1497/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 224131022848000.0000 - mse: 224131022848000.0000 - val_loss: 5338283571675136.0000 - val_mse: 5338283571675136.0000\n",
            "Epoch 1498/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 223355210825728.0000 - mse: 223355210825728.0000 - val_loss: 5337045010481152.0000 - val_mse: 5337045010481152.0000\n",
            "Epoch 1499/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 222580925530112.0000 - mse: 222580925530112.0000 - val_loss: 5335818797318144.0000 - val_mse: 5335818797318144.0000\n",
            "Epoch 1500/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 221809458806784.0000 - mse: 221809458806784.0000 - val_loss: 5334576478027776.0000 - val_mse: 5334576478027776.0000\n",
            "Epoch 1501/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 221040609329152.0000 - mse: 221040609329152.0000 - val_loss: 5333370129088512.0000 - val_mse: 5333370129088512.0000\n",
            "Epoch 1502/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 220272145727488.0000 - mse: 220272145727488.0000 - val_loss: 5332163780149248.0000 - val_mse: 5332163780149248.0000\n",
            "Epoch 1503/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 219506416812032.0000 - mse: 219506416812032.0000 - val_loss: 5330917702762496.0000 - val_mse: 5330917702762496.0000\n",
            "Epoch 1504/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 218745200967680.0000 - mse: 218745200967680.0000 - val_loss: 5329724775596032.0000 - val_mse: 5329724775596032.0000\n",
            "Epoch 1505/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 217981602758656.0000 - mse: 217981602758656.0000 - val_loss: 5328475476983808.0000 - val_mse: 5328475476983808.0000\n",
            "Epoch 1506/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 217223742357504.0000 - mse: 217223742357504.0000 - val_loss: 5327261611851776.0000 - val_mse: 5327261611851776.0000\n",
            "Epoch 1507/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 216465093427200.0000 - mse: 216465093427200.0000 - val_loss: 5326058484137984.0000 - val_mse: 5326058484137984.0000\n",
            "Epoch 1508/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 215711947423744.0000 - mse: 215711947423744.0000 - val_loss: 5324837102813184.0000 - val_mse: 5324837102813184.0000\n",
            "Epoch 1509/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 214957090144256.0000 - mse: 214957090144256.0000 - val_loss: 5323579214266368.0000 - val_mse: 5323579214266368.0000\n",
            "Epoch 1510/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 214208289439744.0000 - mse: 214208289439744.0000 - val_loss: 5322397561389056.0000 - val_mse: 5322397561389056.0000\n",
            "Epoch 1511/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 213459018973184.0000 - mse: 213459018973184.0000 - val_loss: 5321207318577152.0000 - val_mse: 5321207318577152.0000\n",
            "Epoch 1512/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 212710537035776.0000 - mse: 212710537035776.0000 - val_loss: 5319991842832384.0000 - val_mse: 5319991842832384.0000\n",
            "Epoch 1513/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 211966635278336.0000 - mse: 211966635278336.0000 - val_loss: 5318764019056640.0000 - val_mse: 5318764019056640.0000\n",
            "Epoch 1514/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 211224042143744.0000 - mse: 211224042143744.0000 - val_loss: 5317507204251648.0000 - val_mse: 5317507204251648.0000\n",
            "Epoch 1515/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 210483059621888.0000 - mse: 210483059621888.0000 - val_loss: 5316314277085184.0000 - val_mse: 5316314277085184.0000\n",
            "Epoch 1516/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 209743285059584.0000 - mse: 209743285059584.0000 - val_loss: 5315121349918720.0000 - val_mse: 5315121349918720.0000\n",
            "Epoch 1517/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 209006429732864.0000 - mse: 209006429732864.0000 - val_loss: 5313903726690304.0000 - val_mse: 5313903726690304.0000\n",
            "Epoch 1518/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 208271973548032.0000 - mse: 208271973548032.0000 - val_loss: 5312703283331072.0000 - val_mse: 5312703283331072.0000\n",
            "Epoch 1519/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 207539429965824.0000 - mse: 207539429965824.0000 - val_loss: 5311508745551872.0000 - val_mse: 5311508745551872.0000\n",
            "Epoch 1520/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 206809553960960.0000 - mse: 206809553960960.0000 - val_loss: 5310313134030848.0000 - val_mse: 5310313134030848.0000\n",
            "Epoch 1521/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 206079040421888.0000 - mse: 206079040421888.0000 - val_loss: 5309090678964224.0000 - val_mse: 5309090678964224.0000\n",
            "Epoch 1522/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 205352586969088.0000 - mse: 205352586969088.0000 - val_loss: 5307884330024960.0000 - val_mse: 5307884330024960.0000\n",
            "Epoch 1523/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 204629321187328.0000 - mse: 204629321187328.0000 - val_loss: 5306696771567616.0000 - val_mse: 5306696771567616.0000\n",
            "Epoch 1524/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 203905686306816.0000 - mse: 203905686306816.0000 - val_loss: 5305494717595648.0000 - val_mse: 5305494717595648.0000\n",
            "Epoch 1525/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 203184735780864.0000 - mse: 203184735780864.0000 - val_loss: 5304323265265664.0000 - val_mse: 5304323265265664.0000\n",
            "Epoch 1526/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 202464758333440.0000 - mse: 202464758333440.0000 - val_loss: 5303064302977024.0000 - val_mse: 5303064302977024.0000\n",
            "Epoch 1527/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 201749260402688.0000 - mse: 201749260402688.0000 - val_loss: 5301887481937920.0000 - val_mse: 5301887481937920.0000\n",
            "Epoch 1528/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 201033041051648.0000 - mse: 201033041051648.0000 - val_loss: 5300724619542528.0000 - val_mse: 5300724619542528.0000\n",
            "Epoch 1529/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 200320495910912.0000 - mse: 200320495910912.0000 - val_loss: 5299529008021504.0000 - val_mse: 5299529008021504.0000\n",
            "Epoch 1530/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 199609578160128.0000 - mse: 199609578160128.0000 - val_loss: 5298353260724224.0000 - val_mse: 5298353260724224.0000\n",
            "Epoch 1531/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 198901445427200.0000 - mse: 198901445427200.0000 - val_loss: 5297136174366720.0000 - val_mse: 5297136174366720.0000\n",
            "Epoch 1532/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 198195225296896.0000 - mse: 198195225296896.0000 - val_loss: 5295951837134848.0000 - val_mse: 5295951837134848.0000\n",
            "Epoch 1533/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 197487511994368.0000 - mse: 197487511994368.0000 - val_loss: 5294754615001088.0000 - val_mse: 5294754615001088.0000\n",
            "Epoch 1534/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 196785821712384.0000 - mse: 196785821712384.0000 - val_loss: 5293586383896576.0000 - val_mse: 5293586383896576.0000\n",
            "Epoch 1535/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 196084450197504.0000 - mse: 196084450197504.0000 - val_loss: 5292391846117376.0000 - val_mse: 5292391846117376.0000\n",
            "Epoch 1536/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 195384437637120.0000 - mse: 195384437637120.0000 - val_loss: 5291209119498240.0000 - val_mse: 5291209119498240.0000\n",
            "Epoch 1537/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 194688149618688.0000 - mse: 194688149618688.0000 - val_loss: 5290042499006464.0000 - val_mse: 5290042499006464.0000\n",
            "Epoch 1538/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 193993639985152.0000 - mse: 193993639985152.0000 - val_loss: 5288852793065472.0000 - val_mse: 5288852793065472.0000\n",
            "Epoch 1539/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 193300153761792.0000 - mse: 193300153761792.0000 - val_loss: 5287656644673536.0000 - val_mse: 5287656644673536.0000\n",
            "Epoch 1540/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 192607758057472.0000 - mse: 192607758057472.0000 - val_loss: 5286478213021696.0000 - val_mse: 5286478213021696.0000\n",
            "Epoch 1541/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 191918667464704.0000 - mse: 191918667464704.0000 - val_loss: 5285328772399104.0000 - val_mse: 5285328772399104.0000\n",
            "Epoch 1542/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 191232127008768.0000 - mse: 191232127008768.0000 - val_loss: 5284140677070848.0000 - val_mse: 5284140677070848.0000\n",
            "Epoch 1543/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 190545368449024.0000 - mse: 190545368449024.0000 - val_loss: 5282933791260672.0000 - val_mse: 5282933791260672.0000\n",
            "Epoch 1544/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 189863341064192.0000 - mse: 189863341064192.0000 - val_loss: 5281797772410880.0000 - val_mse: 5281797772410880.0000\n",
            "Epoch 1545/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 189181062021120.0000 - mse: 189181062021120.0000 - val_loss: 5280623098855424.0000 - val_mse: 5280623098855424.0000\n",
            "Epoch 1546/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 188500527808512.0000 - mse: 188500527808512.0000 - val_loss: 5279432319172608.0000 - val_mse: 5279432319172608.0000\n",
            "Epoch 1547/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 187823298707456.0000 - mse: 187823298707456.0000 - val_loss: 5278268383035392.0000 - val_mse: 5278268383035392.0000\n",
            "Epoch 1548/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 187146908467200.0000 - mse: 187146908467200.0000 - val_loss: 5277095856963584.0000 - val_mse: 5277095856963584.0000\n",
            "Epoch 1549/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 186472447606784.0000 - mse: 186472447606784.0000 - val_loss: 5275920109666304.0000 - val_mse: 5275920109666304.0000\n",
            "Epoch 1550/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 185800738209792.0000 - mse: 185800738209792.0000 - val_loss: 5274747583594496.0000 - val_mse: 5274747583594496.0000\n",
            "Epoch 1551/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 185131209850880.0000 - mse: 185131209850880.0000 - val_loss: 5273592774262784.0000 - val_mse: 5273592774262784.0000\n",
            "Epoch 1552/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 184463040446464.0000 - mse: 184463040446464.0000 - val_loss: 5272460513509376.0000 - val_mse: 5272460513509376.0000\n",
            "Epoch 1553/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 183795475021824.0000 - mse: 183795475021824.0000 - val_loss: 5271276176277504.0000 - val_mse: 5271276176277504.0000\n",
            "Epoch 1554/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 183131902574592.0000 - mse: 183131902574592.0000 - val_loss: 5270111703269376.0000 - val_mse: 5270111703269376.0000\n",
            "Epoch 1555/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 182468682448896.0000 - mse: 182468682448896.0000 - val_loss: 5268957967679488.0000 - val_mse: 5268957967679488.0000\n",
            "Epoch 1556/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 181808817766400.0000 - mse: 181808817766400.0000 - val_loss: 5267775777931264.0000 - val_mse: 5267775777931264.0000\n",
            "Epoch 1557/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 181148969861120.0000 - mse: 181148969861120.0000 - val_loss: 5266600567504896.0000 - val_mse: 5266600567504896.0000\n",
            "Epoch 1558/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 180492242518016.0000 - mse: 180492242518016.0000 - val_loss: 5265471527976960.0000 - val_mse: 5265471527976960.0000\n",
            "Epoch 1559/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 179836890906624.0000 - mse: 179836890906624.0000 - val_loss: 5264322624225280.0000 - val_mse: 5264322624225280.0000\n",
            "Epoch 1560/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 179182176829440.0000 - mse: 179182176829440.0000 - val_loss: 5263168351764480.0000 - val_mse: 5263168351764480.0000\n",
            "Epoch 1561/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 178531287957504.0000 - mse: 178531287957504.0000 - val_loss: 5262030185431040.0000 - val_mse: 5262030185431040.0000\n",
            "Epoch 1562/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 177882613678080.0000 - mse: 177882613678080.0000 - val_loss: 5260838332006400.0000 - val_mse: 5260838332006400.0000\n",
            "Epoch 1563/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 177235902332928.0000 - mse: 177235902332928.0000 - val_loss: 5259700702543872.0000 - val_mse: 5259700702543872.0000\n",
            "Epoch 1564/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 176589828521984.0000 - mse: 176589828521984.0000 - val_loss: 5258536766406656.0000 - val_mse: 5258536766406656.0000\n",
            "Epoch 1565/2000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 175944526462976.0000 - mse: 175944526462976.0000 - val_loss: 5257402358169600.0000 - val_mse: 5257402358169600.0000\n",
            "Epoch 1566/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 175302881837056.0000 - mse: 175302881837056.0000 - val_loss: 5256267949932544.0000 - val_mse: 5256267949932544.0000\n",
            "Epoch 1567/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 174663183368192.0000 - mse: 174663183368192.0000 - val_loss: 5255093276377088.0000 - val_mse: 5255093276377088.0000\n",
            "Epoch 1568/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 174022864142336.0000 - mse: 174022864142336.0000 - val_loss: 5253948130721792.0000 - val_mse: 5253948130721792.0000\n",
            "Epoch 1569/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 173387678744576.0000 - mse: 173387678744576.0000 - val_loss: 5252784731455488.0000 - val_mse: 5252784731455488.0000\n",
            "Epoch 1570/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 172753097326592.0000 - mse: 172753097326592.0000 - val_loss: 5251636901445632.0000 - val_mse: 5251636901445632.0000\n",
            "Epoch 1571/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 172119790977024.0000 - mse: 172119790977024.0000 - val_loss: 5250526115528704.0000 - val_mse: 5250526115528704.0000\n",
            "Epoch 1572/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 171487944245248.0000 - mse: 171487944245248.0000 - val_loss: 5249400834097152.0000 - val_mse: 5249400834097152.0000\n",
            "Epoch 1573/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 170858748313600.0000 - mse: 170858748313600.0000 - val_loss: 5248269110214656.0000 - val_mse: 5248269110214656.0000\n",
            "Epoch 1574/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 170232840716288.0000 - mse: 170232840716288.0000 - val_loss: 5247128796397568.0000 - val_mse: 5247128796397568.0000\n",
            "Epoch 1575/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 169607352549376.0000 - mse: 169607352549376.0000 - val_loss: 5245973450194944.0000 - val_mse: 5245973450194944.0000\n",
            "Epoch 1576/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 168982904569856.0000 - mse: 168982904569856.0000 - val_loss: 5244843873796096.0000 - val_mse: 5244843873796096.0000\n",
            "Epoch 1577/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 168360067203072.0000 - mse: 168360067203072.0000 - val_loss: 5243689064464384.0000 - val_mse: 5243689064464384.0000\n",
            "Epoch 1578/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 167739914190848.0000 - mse: 167739914190848.0000 - val_loss: 5242574520451072.0000 - val_mse: 5242574520451072.0000\n",
            "Epoch 1579/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 167122260983808.0000 - mse: 167122260983808.0000 - val_loss: 5241477693177856.0000 - val_mse: 5241477693177856.0000\n",
            "Epoch 1580/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 166506453270528.0000 - mse: 166506453270528.0000 - val_loss: 5240321273233408.0000 - val_mse: 5240321273233408.0000\n",
            "Epoch 1581/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 165889722810368.0000 - mse: 165889722810368.0000 - val_loss: 5239211024187392.0000 - val_mse: 5239211024187392.0000\n",
            "Epoch 1582/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 165276918218752.0000 - mse: 165276918218752.0000 - val_loss: 5238072320983040.0000 - val_mse: 5238072320983040.0000\n",
            "Epoch 1583/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 164667670396928.0000 - mse: 164667670396928.0000 - val_loss: 5236948650164224.0000 - val_mse: 5236948650164224.0000\n",
            "Epoch 1584/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 164057013288960.0000 - mse: 164057013288960.0000 - val_loss: 5235827663699968.0000 - val_mse: 5235827663699968.0000\n",
            "Epoch 1585/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 163450651148288.0000 - mse: 163450651148288.0000 - val_loss: 5234699697913856.0000 - val_mse: 5234699697913856.0000\n",
            "Epoch 1586/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 162843852800000.0000 - mse: 162843852800000.0000 - val_loss: 5233588911996928.0000 - val_mse: 5233588911996928.0000\n",
            "Epoch 1587/2000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 162241550745600.0000 - mse: 162241550745600.0000 - val_loss: 5232456114372608.0000 - val_mse: 5232456114372608.0000\n",
            "Epoch 1588/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 161638141394944.0000 - mse: 161638141394944.0000 - val_loss: 5231327611715584.0000 - val_mse: 5231327611715584.0000\n",
            "Epoch 1589/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 161036627869696.0000 - mse: 161036627869696.0000 - val_loss: 5230208772734976.0000 - val_mse: 5230208772734976.0000\n",
            "Epoch 1590/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 160439056990208.0000 - mse: 160439056990208.0000 - val_loss: 5229092081238016.0000 - val_mse: 5229092081238016.0000\n",
            "Epoch 1591/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 159840529809408.0000 - mse: 159840529809408.0000 - val_loss: 5227987200901120.0000 - val_mse: 5227987200901120.0000\n",
            "Epoch 1592/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 159246297595904.0000 - mse: 159246297595904.0000 - val_loss: 5226866214436864.0000 - val_mse: 5226866214436864.0000\n",
            "Epoch 1593/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 158653239787520.0000 - mse: 158653239787520.0000 - val_loss: 5225731269328896.0000 - val_mse: 5225731269328896.0000\n",
            "Epoch 1594/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 158064560832512.0000 - mse: 158064560832512.0000 - val_loss: 5224650011312128.0000 - val_mse: 5224650011312128.0000\n",
            "Epoch 1595/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 157471603687424.0000 - mse: 157471603687424.0000 - val_loss: 5223522582396928.0000 - val_mse: 5223522582396928.0000\n",
            "Epoch 1596/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 156884367572992.0000 - mse: 156884367572992.0000 - val_loss: 5222427365736448.0000 - val_mse: 5222427365736448.0000\n",
            "Epoch 1597/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 156296309374976.0000 - mse: 156296309374976.0000 - val_loss: 5221292420628480.0000 - val_mse: 5221292420628480.0000\n",
            "Epoch 1598/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 155714089648128.0000 - mse: 155714089648128.0000 - val_loss: 5220177876615168.0000 - val_mse: 5220177876615168.0000\n",
            "Epoch 1599/2000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 155129621774336.0000 - mse: 155129621774336.0000 - val_loss: 5219069775052800.0000 - val_mse: 5219069775052800.0000\n",
            "Epoch 1600/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 154548542898176.0000 - mse: 154548542898176.0000 - val_loss: 5217983685197824.0000 - val_mse: 5217983685197824.0000\n",
            "Epoch 1601/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 153969712168960.0000 - mse: 153969712168960.0000 - val_loss: 5216891152891904.0000 - val_mse: 5216891152891904.0000\n",
            "Epoch 1602/2000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 153393045700608.0000 - mse: 153393045700608.0000 - val_loss: 5215801841811456.0000 - val_mse: 5215801841811456.0000\n",
            "Epoch 1603/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 152815523594240.0000 - mse: 152815523594240.0000 - val_loss: 5214672802283520.0000 - val_mse: 5214672802283520.0000\n",
            "Epoch 1604/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 152241793138688.0000 - mse: 152241793138688.0000 - val_loss: 5213585101815808.0000 - val_mse: 5213585101815808.0000\n",
            "Epoch 1605/2000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 151668683440128.0000 - mse: 151668683440128.0000 - val_loss: 5212456599158784.0000 - val_mse: 5212456599158784.0000\n",
            "Epoch 1606/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 151098174210048.0000 - mse: 151098174210048.0000 - val_loss: 5211398963462144.0000 - val_mse: 5211398963462144.0000\n",
            "Epoch 1607/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 150529929904128.0000 - mse: 150529929904128.0000 - val_loss: 5210308578639872.0000 - val_mse: 5210308578639872.0000\n",
            "Epoch 1608/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 149961685598208.0000 - mse: 149961685598208.0000 - val_loss: 5209178465370112.0000 - val_mse: 5209178465370112.0000\n",
            "Epoch 1609/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 149395655884800.0000 - mse: 149395655884800.0000 - val_loss: 5208111702867968.0000 - val_mse: 5208111702867968.0000\n",
            "Epoch 1610/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 148832948060160.0000 - mse: 148832948060160.0000 - val_loss: 5206995011371008.0000 - val_mse: 5206995011371008.0000\n",
            "Epoch 1611/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 148269753696256.0000 - mse: 148269753696256.0000 - val_loss: 5205930396352512.0000 - val_mse: 5205930396352512.0000\n",
            "Epoch 1612/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 147710267097088.0000 - mse: 147710267097088.0000 - val_loss: 5204830347853824.0000 - val_mse: 5204830347853824.0000\n",
            "Epoch 1613/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 147150428176384.0000 - mse: 147150428176384.0000 - val_loss: 5203781838962688.0000 - val_mse: 5203781838962688.0000\n",
            "Epoch 1614/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 146593307164672.0000 - mse: 146593307164672.0000 - val_loss: 5202667294949376.0000 - val_mse: 5202667294949376.0000\n",
            "Epoch 1615/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 146036689469440.0000 - mse: 146036689469440.0000 - val_loss: 5201544697872384.0000 - val_mse: 5201544697872384.0000\n",
            "Epoch 1616/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 145483913756672.0000 - mse: 145483913756672.0000 - val_loss: 5200426395762688.0000 - val_mse: 5200426395762688.0000\n",
            "Epoch 1617/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 144932010459136.0000 - mse: 144932010459136.0000 - val_loss: 5199405267288064.0000 - val_mse: 5199405267288064.0000\n",
            "Epoch 1618/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 144382288199680.0000 - mse: 144382288199680.0000 - val_loss: 5198334209818624.0000 - val_mse: 5198334209818624.0000\n",
            "Epoch 1619/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 143833706790912.0000 - mse: 143833706790912.0000 - val_loss: 5197259931123712.0000 - val_mse: 5197259931123712.0000\n",
            "Epoch 1620/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 143285746139136.0000 - mse: 143285746139136.0000 - val_loss: 5196143239626752.0000 - val_mse: 5196143239626752.0000\n",
            "Epoch 1621/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 142740251738112.0000 - mse: 142740251738112.0000 - val_loss: 5195039433031680.0000 - val_mse: 5195039433031680.0000\n",
            "Epoch 1622/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 142196669939712.0000 - mse: 142196669939712.0000 - val_loss: 5193979649851392.0000 - val_mse: 5193979649851392.0000\n",
            "Epoch 1623/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 141653708898304.0000 - mse: 141653708898304.0000 - val_loss: 5192910202994688.0000 - val_mse: 5192910202994688.0000\n",
            "Epoch 1624/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 141115227373568.0000 - mse: 141115227373568.0000 - val_loss: 5191836998041600.0000 - val_mse: 5191836998041600.0000\n",
            "Epoch 1625/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 140575554666496.0000 - mse: 140575554666496.0000 - val_loss: 5190776141119488.0000 - val_mse: 5190776141119488.0000\n",
            "Epoch 1626/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 140039421952000.0000 - mse: 140039421952000.0000 - val_loss: 5189719042293760.0000 - val_mse: 5189719042293760.0000\n",
            "Epoch 1627/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 139502844641280.0000 - mse: 139502844641280.0000 - val_loss: 5188571212283904.0000 - val_mse: 5188571212283904.0000\n",
            "Epoch 1628/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 138969522110464.0000 - mse: 138969522110464.0000 - val_loss: 5187507134136320.0000 - val_mse: 5187507134136320.0000\n",
            "Epoch 1629/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 138436996497408.0000 - mse: 138436996497408.0000 - val_loss: 5186441982246912.0000 - val_mse: 5186441982246912.0000\n",
            "Epoch 1630/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 137906140217344.0000 - mse: 137906140217344.0000 - val_loss: 5185398305193984.0000 - val_mse: 5185398305193984.0000\n",
            "Epoch 1631/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 137378370945024.0000 - mse: 137378370945024.0000 - val_loss: 5184371808010240.0000 - val_mse: 5184371808010240.0000\n",
            "Epoch 1632/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 136849922195456.0000 - mse: 136849922195456.0000 - val_loss: 5183283033800704.0000 - val_mse: 5183283033800704.0000\n",
            "Epoch 1633/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 136324627562496.0000 - mse: 136324627562496.0000 - val_loss: 5182170100400128.0000 - val_mse: 5182170100400128.0000\n",
            "Epoch 1634/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 135799752359936.0000 - mse: 135799752359936.0000 - val_loss: 5181126960218112.0000 - val_mse: 5181126960218112.0000\n",
            "Epoch 1635/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 135277553123328.0000 - mse: 135277553123328.0000 - val_loss: 5180046775943168.0000 - val_mse: 5180046775943168.0000\n",
            "Epoch 1636/2000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 134757283266560.0000 - mse: 134757283266560.0000 - val_loss: 5179026721210368.0000 - val_mse: 5179026721210368.0000\n",
            "Epoch 1637/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 134236921135104.0000 - mse: 134236921135104.0000 - val_loss: 5177985728512000.0000 - val_mse: 5177985728512000.0000\n",
            "Epoch 1638/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 133719058808832.0000 - mse: 133719058808832.0000 - val_loss: 5176885680013312.0000 - val_mse: 5176885680013312.0000\n",
            "Epoch 1639/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 133203687899136.0000 - mse: 133203687899136.0000 - val_loss: 5175834486767616.0000 - val_mse: 5175834486767616.0000\n",
            "Epoch 1640/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 132688946135040.0000 - mse: 132688946135040.0000 - val_loss: 5174736048881664.0000 - val_mse: 5174736048881664.0000\n",
            "Epoch 1641/2000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 132176326688768.0000 - mse: 132176326688768.0000 - val_loss: 5173693445570560.0000 - val_mse: 5173693445570560.0000\n",
            "Epoch 1642/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 131667079462912.0000 - mse: 131667079462912.0000 - val_loss: 5172676075192320.0000 - val_mse: 5172676075192320.0000\n",
            "Epoch 1643/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 131156087406592.0000 - mse: 131156087406592.0000 - val_loss: 5171650114879488.0000 - val_mse: 5171650114879488.0000\n",
            "Epoch 1644/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 130646815014912.0000 - mse: 130646815014912.0000 - val_loss: 5170575299313664.0000 - val_mse: 5170575299313664.0000\n",
            "Epoch 1645/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 130141451714560.0000 - mse: 130141451714560.0000 - val_loss: 5169511221166080.0000 - val_mse: 5169511221166080.0000\n",
            "Epoch 1646/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 129635912253440.0000 - mse: 129635912253440.0000 - val_loss: 5168428889407488.0000 - val_mse: 5168428889407488.0000\n",
            "Epoch 1647/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 129133182976000.0000 - mse: 129133182976000.0000 - val_loss: 5167407224061952.0000 - val_mse: 5167407224061952.0000\n",
            "Epoch 1648/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 128631787487232.0000 - mse: 128631787487232.0000 - val_loss: 5166376431910912.0000 - val_mse: 5166376431910912.0000\n",
            "Epoch 1649/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 128131826450432.0000 - mse: 128131826450432.0000 - val_loss: 5165353155952640.0000 - val_mse: 5165353155952640.0000\n",
            "Epoch 1650/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 127633006264320.0000 - mse: 127633006264320.0000 - val_loss: 5164305720803328.0000 - val_mse: 5164305720803328.0000\n",
            "Epoch 1651/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 127134160912384.0000 - mse: 127134160912384.0000 - val_loss: 5163204061691904.0000 - val_mse: 5163204061691904.0000\n",
            "Epoch 1652/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 126640147398656.0000 - mse: 126640147398656.0000 - val_loss: 5162188301926400.0000 - val_mse: 5162188301926400.0000\n",
            "Epoch 1653/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 126146226159616.0000 - mse: 126146226159616.0000 - val_loss: 5161137645551616.0000 - val_mse: 5161137645551616.0000\n",
            "Epoch 1654/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 125654636953600.0000 - mse: 125654636953600.0000 - val_loss: 5160112222109696.0000 - val_mse: 5160112222109696.0000\n",
            "Epoch 1655/2000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 125163819499520.0000 - mse: 125163819499520.0000 - val_loss: 5159116326567936.0000 - val_mse: 5159116326567936.0000\n",
            "Epoch 1656/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 124673908015104.0000 - mse: 124673908015104.0000 - val_loss: 5158026478616576.0000 - val_mse: 5158026478616576.0000\n",
            "Epoch 1657/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 124186764771328.0000 - mse: 124186764771328.0000 - val_loss: 5156955958018048.0000 - val_mse: 5156955958018048.0000\n",
            "Epoch 1658/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 123701659959296.0000 - mse: 123701659959296.0000 - val_loss: 5155960062476288.0000 - val_mse: 5155960062476288.0000\n",
            "Epoch 1659/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 123217284956160.0000 - mse: 123217284956160.0000 - val_loss: 5154948597678080.0000 - val_mse: 5154948597678080.0000\n",
            "Epoch 1660/2000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 122733471989760.0000 - mse: 122733471989760.0000 - val_loss: 5153951628394496.0000 - val_mse: 5153951628394496.0000\n",
            "Epoch 1661/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 122250741153792.0000 - mse: 122250741153792.0000 - val_loss: 5152888623988736.0000 - val_mse: 5152888623988736.0000\n",
            "Epoch 1662/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 121771919409152.0000 - mse: 121771919409152.0000 - val_loss: 5151867495514112.0000 - val_mse: 5151867495514112.0000\n",
            "Epoch 1663/2000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 121292938280960.0000 - mse: 121292938280960.0000 - val_loss: 5150816302268416.0000 - val_mse: 5150816302268416.0000\n",
            "Epoch 1664/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 120815953641472.0000 - mse: 120815953641472.0000 - val_loss: 5149784436375552.0000 - val_mse: 5149784436375552.0000\n",
            "Epoch 1665/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 120340915159040.0000 - mse: 120340915159040.0000 - val_loss: 5148760086675456.0000 - val_mse: 5148760086675456.0000\n",
            "Epoch 1666/2000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 119866740703232.0000 - mse: 119866740703232.0000 - val_loss: 5147744326909952.0000 - val_mse: 5147744326909952.0000\n",
            "Epoch 1667/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 119394210414592.0000 - mse: 119394210414592.0000 - val_loss: 5146736620208128.0000 - val_mse: 5146736620208128.0000\n",
            "Epoch 1668/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 118923550785536.0000 - mse: 118923550785536.0000 - val_loss: 5145717102346240.0000 - val_mse: 5145717102346240.0000\n",
            "Epoch 1669/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 118454946365440.0000 - mse: 118454946365440.0000 - val_loss: 5144689531420672.0000 - val_mse: 5144689531420672.0000\n",
            "Epoch 1670/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 117987298246656.0000 - mse: 117987298246656.0000 - val_loss: 5143650686205952.0000 - val_mse: 5143650686205952.0000\n",
            "Epoch 1671/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 117520883253248.0000 - mse: 117520883253248.0000 - val_loss: 5142624189022208.0000 - val_mse: 5142624189022208.0000\n",
            "Epoch 1672/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 117054594088960.0000 - mse: 117054594088960.0000 - val_loss: 5141634735931392.0000 - val_mse: 5141634735931392.0000\n",
            "Epoch 1673/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 116591408709632.0000 - mse: 116591408709632.0000 - val_loss: 5140612533714944.0000 - val_mse: 5140612533714944.0000\n",
            "Epoch 1674/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 116130236596224.0000 - mse: 116130236596224.0000 - val_loss: 5139588720885760.0000 - val_mse: 5139588720885760.0000\n",
            "Epoch 1675/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 115668661829632.0000 - mse: 115668661829632.0000 - val_loss: 5138573497991168.0000 - val_mse: 5138573497991168.0000\n",
            "Epoch 1676/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 115209528147968.0000 - mse: 115209528147968.0000 - val_loss: 5137539484614656.0000 - val_mse: 5137539484614656.0000\n",
            "Epoch 1677/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 114753523417088.0000 - mse: 114753523417088.0000 - val_loss: 5136563453296640.0000 - val_mse: 5136563453296640.0000\n",
            "Epoch 1678/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 114297854230528.0000 - mse: 114297854230528.0000 - val_loss: 5135564873400320.0000 - val_mse: 5135564873400320.0000\n",
            "Epoch 1679/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 113842713526272.0000 - mse: 113842713526272.0000 - val_loss: 5134546966151168.0000 - val_mse: 5134546966151168.0000\n",
            "Epoch 1680/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 113389770637312.0000 - mse: 113389770637312.0000 - val_loss: 5133535501352960.0000 - val_mse: 5133535501352960.0000\n",
            "Epoch 1681/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 112937775661056.0000 - mse: 112937775661056.0000 - val_loss: 5132497193009152.0000 - val_mse: 5132497193009152.0000\n",
            "Epoch 1682/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 112487768784896.0000 - mse: 112487768784896.0000 - val_loss: 5131487875694592.0000 - val_mse: 5131487875694592.0000\n",
            "Epoch 1683/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 112038760153088.0000 - mse: 112038760153088.0000 - val_loss: 5130507549409280.0000 - val_mse: 5130507549409280.0000\n",
            "Epoch 1684/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 111592226160640.0000 - mse: 111592226160640.0000 - val_loss: 5129555140411392.0000 - val_mse: 5129555140411392.0000\n",
            "Epoch 1685/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 111147009179648.0000 - mse: 111147009179648.0000 - val_loss: 5128538306904064.0000 - val_mse: 5128538306904064.0000\n",
            "Epoch 1686/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 110702740111360.0000 - mse: 110702740111360.0000 - val_loss: 5127505367269376.0000 - val_mse: 5127505367269376.0000\n",
            "Epoch 1687/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 110259351846912.0000 - mse: 110259351846912.0000 - val_loss: 5126477259472896.0000 - val_mse: 5126477259472896.0000\n",
            "Epoch 1688/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 109817918128128.0000 - mse: 109817918128128.0000 - val_loss: 5125485122027520.0000 - val_mse: 5125485122027520.0000\n",
            "Epoch 1689/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 109378069856256.0000 - mse: 109378069856256.0000 - val_loss: 5124521438740480.0000 - val_mse: 5124521438740480.0000\n",
            "Epoch 1690/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 108940176130048.0000 - mse: 108940176130048.0000 - val_loss: 5123540575584256.0000 - val_mse: 5123540575584256.0000\n",
            "Epoch 1691/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 108503716855808.0000 - mse: 108503716855808.0000 - val_loss: 5122527500173312.0000 - val_mse: 5122527500173312.0000\n",
            "Epoch 1692/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 108066158673920.0000 - mse: 108066158673920.0000 - val_loss: 5121506371698688.0000 - val_mse: 5121506371698688.0000\n",
            "Epoch 1693/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 107633423941632.0000 - mse: 107633423941632.0000 - val_loss: 5120508865544192.0000 - val_mse: 5120508865544192.0000\n",
            "Epoch 1694/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 107199766462464.0000 - mse: 107199766462464.0000 - val_loss: 5119544645386240.0000 - val_mse: 5119544645386240.0000\n",
            "Epoch 1695/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 106768743006208.0000 - mse: 106768743006208.0000 - val_loss: 5118572909035520.0000 - val_mse: 5118572909035520.0000\n",
            "Epoch 1696/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 106338919120896.0000 - mse: 106338919120896.0000 - val_loss: 5117593656492032.0000 - val_mse: 5117593656492032.0000\n",
            "Epoch 1697/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 105909799878656.0000 - mse: 105909799878656.0000 - val_loss: 5116569306791936.0000 - val_mse: 5116569306791936.0000\n",
            "Epoch 1698/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 105483876696064.0000 - mse: 105483876696064.0000 - val_loss: 5115591127990272.0000 - val_mse: 5115591127990272.0000\n",
            "Epoch 1699/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 105057886404608.0000 - mse: 105057886404608.0000 - val_loss: 5114629592186880.0000 - val_mse: 5114629592186880.0000\n",
            "Epoch 1700/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 104632869191680.0000 - mse: 104632869191680.0000 - val_loss: 5113664835158016.0000 - val_mse: 5113664835158016.0000\n",
            "Epoch 1701/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 104210267897856.0000 - mse: 104210267897856.0000 - val_loss: 5112653370359808.0000 - val_mse: 5112653370359808.0000\n",
            "Epoch 1702/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 103788388024320.0000 - mse: 103788388024320.0000 - val_loss: 5111691297685504.0000 - val_mse: 5111691297685504.0000\n",
            "Epoch 1703/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 103368588525568.0000 - mse: 103368588525568.0000 - val_loss: 5110699160240128.0000 - val_mse: 5110699160240128.0000\n",
            "Epoch 1704/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 102950315753472.0000 - mse: 102950315753472.0000 - val_loss: 5109682326732800.0000 - val_mse: 5109682326732800.0000\n",
            "Epoch 1705/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 102532512743424.0000 - mse: 102532512743424.0000 - val_loss: 5108738507669504.0000 - val_mse: 5108738507669504.0000\n",
            "Epoch 1706/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 102117469585408.0000 - mse: 102117469585408.0000 - val_loss: 5107780729962496.0000 - val_mse: 5107780729962496.0000\n",
            "Epoch 1707/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 101701612732416.0000 - mse: 101701612732416.0000 - val_loss: 5106797182451712.0000 - val_mse: 5106797182451712.0000\n",
            "Epoch 1708/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 101288918384640.0000 - mse: 101288918384640.0000 - val_loss: 5105822761746432.0000 - val_mse: 5105822761746432.0000\n",
            "Epoch 1709/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 100875779440640.0000 - mse: 100875779440640.0000 - val_loss: 5104819350011904.0000 - val_mse: 5104819350011904.0000\n",
            "Epoch 1710/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 100466398593024.0000 - mse: 100466398593024.0000 - val_loss: 5103829360050176.0000 - val_mse: 5103829360050176.0000\n",
            "Epoch 1711/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 100056229216256.0000 - mse: 100056229216256.0000 - val_loss: 5102881246019584.0000 - val_mse: 5102881246019584.0000\n",
            "Epoch 1712/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 99649935376384.0000 - mse: 99649935376384.0000 - val_loss: 5101918636474368.0000 - val_mse: 5101918636474368.0000\n",
            "Epoch 1713/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 99243054333952.0000 - mse: 99243054333952.0000 - val_loss: 5100928109641728.0000 - val_mse: 5100928109641728.0000\n",
            "Epoch 1714/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 98838530490368.0000 - mse: 98838530490368.0000 - val_loss: 5099977311256576.0000 - val_mse: 5099977311256576.0000\n",
            "Epoch 1715/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 98435072000000.0000 - mse: 98435072000000.0000 - val_loss: 5099011480485888.0000 - val_mse: 5099011480485888.0000\n",
            "Epoch 1716/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 98033240899584.0000 - mse: 98033240899584.0000 - val_loss: 5098063366455296.0000 - val_mse: 5098063366455296.0000\n",
            "Epoch 1717/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 97631602737152.0000 - mse: 97631602737152.0000 - val_loss: 5097106125619200.0000 - val_mse: 5097106125619200.0000\n",
            "Epoch 1718/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 97232120446976.0000 - mse: 97232120446976.0000 - val_loss: 5096140294848512.0000 - val_mse: 5096140294848512.0000\n",
            "Epoch 1719/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 96833099530240.0000 - mse: 96833099530240.0000 - val_loss: 5095181980270592.0000 - val_mse: 5095181980270592.0000\n",
            "Epoch 1720/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 96436435812352.0000 - mse: 96436435812352.0000 - val_loss: 5094211317661696.0000 - val_mse: 5094211317661696.0000\n",
            "Epoch 1721/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 96042288676864.0000 - mse: 96042288676864.0000 - val_loss: 5093261593018368.0000 - val_mse: 5093261593018368.0000\n",
            "Epoch 1722/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 95646933581824.0000 - mse: 95646933581824.0000 - val_loss: 5092300057214976.0000 - val_mse: 5092300057214976.0000\n",
            "Epoch 1723/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 95253860188160.0000 - mse: 95253860188160.0000 - val_loss: 5091350332571648.0000 - val_mse: 5091350332571648.0000\n",
            "Epoch 1724/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 94862036697088.0000 - mse: 94862036697088.0000 - val_loss: 5090412419088384.0000 - val_mse: 5090412419088384.0000\n",
            "Epoch 1725/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 94471580549120.0000 - mse: 94471580549120.0000 - val_loss: 5089469136896000.0000 - val_mse: 5089469136896000.0000\n",
            "Epoch 1726/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 94083573874688.0000 - mse: 94083573874688.0000 - val_loss: 5088490958094336.0000 - val_mse: 5088490958094336.0000\n",
            "Epoch 1727/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 93695709806592.0000 - mse: 93695709806592.0000 - val_loss: 5087570224480256.0000 - val_mse: 5087570224480256.0000\n",
            "Epoch 1728/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 93309699620864.0000 - mse: 93309699620864.0000 - val_loss: 5086622647320576.0000 - val_mse: 5086622647320576.0000\n",
            "Epoch 1729/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 92925761421312.0000 - mse: 92925761421312.0000 - val_loss: 5085648763486208.0000 - val_mse: 5085648763486208.0000\n",
            "Epoch 1730/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 92540657205248.0000 - mse: 92540657205248.0000 - val_loss: 5084703870681088.0000 - val_mse: 5084703870681088.0000\n",
            "Epoch 1731/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 92159780847616.0000 - mse: 92159780847616.0000 - val_loss: 5083784747679744.0000 - val_mse: 5083784747679744.0000\n",
            "Epoch 1732/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 91778300510208.0000 - mse: 91778300510208.0000 - val_loss: 5082829654327296.0000 - val_mse: 5082829654327296.0000\n",
            "Epoch 1733/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 91398095241216.0000 - mse: 91398095241216.0000 - val_loss: 5081879392813056.0000 - val_mse: 5081879392813056.0000\n",
            "Epoch 1734/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 91019232149504.0000 - mse: 91019232149504.0000 - val_loss: 5080915172655104.0000 - val_mse: 5080915172655104.0000\n",
            "Epoch 1735/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 90641392467968.0000 - mse: 90641392467968.0000 - val_loss: 5080007323942912.0000 - val_mse: 5080007323942912.0000\n",
            "Epoch 1736/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 90266329415680.0000 - mse: 90266329415680.0000 - val_loss: 5079057062428672.0000 - val_mse: 5079057062428672.0000\n",
            "Epoch 1737/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 89891232808960.0000 - mse: 89891232808960.0000 - val_loss: 5078130960105472.0000 - val_mse: 5078130960105472.0000\n",
            "Epoch 1738/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 89518636007424.0000 - mse: 89518636007424.0000 - val_loss: 5077183919816704.0000 - val_mse: 5077183919816704.0000\n",
            "Epoch 1739/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 89145141624832.0000 - mse: 89145141624832.0000 - val_loss: 5076229900206080.0000 - val_mse: 5076229900206080.0000\n",
            "Epoch 1740/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 88775011074048.0000 - mse: 88775011074048.0000 - val_loss: 5075297892302848.0000 - val_mse: 5075297892302848.0000\n",
            "Epoch 1741/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 88406038151168.0000 - mse: 88406038151168.0000 - val_loss: 5074357294465024.0000 - val_mse: 5074357294465024.0000\n",
            "Epoch 1742/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 88035999875072.0000 - mse: 88035999875072.0000 - val_loss: 5073470920589312.0000 - val_mse: 5073470920589312.0000\n",
            "Epoch 1743/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 87670550167552.0000 - mse: 87670550167552.0000 - val_loss: 5072513679753216.0000 - val_mse: 5072513679753216.0000\n",
            "Epoch 1744/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 87303917666304.0000 - mse: 87303917666304.0000 - val_loss: 5071589724913664.0000 - val_mse: 5071589724913664.0000\n",
            "Epoch 1745/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 86940514779136.0000 - mse: 86940514779136.0000 - val_loss: 5070645368979456.0000 - val_mse: 5070645368979456.0000\n",
            "Epoch 1746/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 86577229332480.0000 - mse: 86577229332480.0000 - val_loss: 5069698328690688.0000 - val_mse: 5069698328690688.0000\n",
            "Epoch 1747/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 86214958907392.0000 - mse: 86214958907392.0000 - val_loss: 5068780816302080.0000 - val_mse: 5068780816302080.0000\n",
            "Epoch 1748/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 85854835965952.0000 - mse: 85854835965952.0000 - val_loss: 5067854713978880.0000 - val_mse: 5067854713978880.0000\n",
            "Epoch 1749/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 85495434444800.0000 - mse: 85495434444800.0000 - val_loss: 5066976393166848.0000 - val_mse: 5066976393166848.0000\n",
            "Epoch 1750/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 85136989224960.0000 - mse: 85136989224960.0000 - val_loss: 5066034721587200.0000 - val_mse: 5066034721587200.0000\n",
            "Epoch 1751/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 84779961679872.0000 - mse: 84779961679872.0000 - val_loss: 5065091439394816.0000 - val_mse: 5065091439394816.0000\n",
            "Epoch 1752/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 84423739441152.0000 - mse: 84423739441152.0000 - val_loss: 5064172316393472.0000 - val_mse: 5064172316393472.0000\n",
            "Epoch 1753/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 84070168002560.0000 - mse: 84070168002560.0000 - val_loss: 5063229571072000.0000 - val_mse: 5063229571072000.0000\n",
            "Epoch 1754/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 83717166989312.0000 - mse: 83717166989312.0000 - val_loss: 5062349639647232.0000 - val_mse: 5062349639647232.0000\n",
            "Epoch 1755/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 83364853841920.0000 - mse: 83364853841920.0000 - val_loss: 5061458433933312.0000 - val_mse: 5061458433933312.0000\n",
            "Epoch 1756/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 83015241826304.0000 - mse: 83015241826304.0000 - val_loss: 5060545216512000.0000 - val_mse: 5060545216512000.0000\n",
            "Epoch 1757/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 82663775928320.0000 - mse: 82663775928320.0000 - val_loss: 5059604618674176.0000 - val_mse: 5059604618674176.0000\n",
            "Epoch 1758/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 82316437225472.0000 - mse: 82316437225472.0000 - val_loss: 5058648451579904.0000 - val_mse: 5058648451579904.0000\n",
            "Epoch 1759/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 81968771366912.0000 - mse: 81968771366912.0000 - val_loss: 5057737918513152.0000 - val_mse: 5057737918513152.0000\n",
            "Epoch 1760/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 81622607069184.0000 - mse: 81622607069184.0000 - val_loss: 5056854228992000.0000 - val_mse: 5056854228992000.0000\n",
            "Epoch 1761/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 81278346985472.0000 - mse: 81278346985472.0000 - val_loss: 5055971613212672.0000 - val_mse: 5055971613212672.0000\n",
            "Epoch 1762/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 80935286472704.0000 - mse: 80935286472704.0000 - val_loss: 5055061080145920.0000 - val_mse: 5055061080145920.0000\n",
            "Epoch 1763/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 80592049799168.0000 - mse: 80592049799168.0000 - val_loss: 5054096859987968.0000 - val_mse: 5054096859987968.0000\n",
            "Epoch 1764/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 80250658619392.0000 - mse: 80250658619392.0000 - val_loss: 5053163778342912.0000 - val_mse: 5053163778342912.0000\n",
            "Epoch 1765/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 79911809187840.0000 - mse: 79911809187840.0000 - val_loss: 5052294047465472.0000 - val_mse: 5052294047465472.0000\n",
            "Epoch 1766/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 79573278523392.0000 - mse: 79573278523392.0000 - val_loss: 5051416263524352.0000 - val_mse: 5051416263524352.0000\n",
            "Epoch 1767/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 79234924019712.0000 - mse: 79234924019712.0000 - val_loss: 5050515931004928.0000 - val_mse: 5050515931004928.0000\n",
            "Epoch 1768/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 78898473730048.0000 - mse: 78898473730048.0000 - val_loss: 5049612377260032.0000 - val_mse: 5049612377260032.0000\n",
            "Epoch 1769/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 78563155902464.0000 - mse: 78563155902464.0000 - val_loss: 5048687348678656.0000 - val_mse: 5048687348678656.0000\n",
            "Epoch 1770/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 78229557739520.0000 - mse: 78229557739520.0000 - val_loss: 5047767151935488.0000 - val_mse: 5047767151935488.0000\n",
            "Epoch 1771/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 77896630665216.0000 - mse: 77896630665216.0000 - val_loss: 5046899031670784.0000 - val_mse: 5046899031670784.0000\n",
            "Epoch 1772/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 77565817520128.0000 - mse: 77565817520128.0000 - val_loss: 5046027690180608.0000 - val_mse: 5046027690180608.0000\n",
            "Epoch 1773/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 77235297976320.0000 - mse: 77235297976320.0000 - val_loss: 5045149906239488.0000 - val_mse: 5045149906239488.0000\n",
            "Epoch 1774/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 76906925916160.0000 - mse: 76906925916160.0000 - val_loss: 5044243131269120.0000 - val_mse: 5044243131269120.0000\n",
            "Epoch 1775/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 76577949876224.0000 - mse: 76577949876224.0000 - val_loss: 5043311123365888.0000 - val_mse: 5043311123365888.0000\n",
            "Epoch 1776/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 76250114686976.0000 - mse: 76250114686976.0000 - val_loss: 5042398442815488.0000 - val_mse: 5042398442815488.0000\n",
            "Epoch 1777/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 75924770914304.0000 - mse: 75924770914304.0000 - val_loss: 5041540523098112.0000 - val_mse: 5041540523098112.0000\n",
            "Epoch 1778/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 75600710598656.0000 - mse: 75600710598656.0000 - val_loss: 5040676697800704.0000 - val_mse: 5040676697800704.0000\n",
            "Epoch 1779/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 75276734169088.0000 - mse: 75276734169088.0000 - val_loss: 5039815019986944.0000 - val_mse: 5039815019986944.0000\n",
            "Epoch 1780/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 74955148492800.0000 - mse: 74955148492800.0000 - val_loss: 5038920593047552.0000 - val_mse: 5038920593047552.0000\n",
            "Epoch 1781/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 74634141630464.0000 - mse: 74634141630464.0000 - val_loss: 5038016502431744.0000 - val_mse: 5038016502431744.0000\n",
            "Epoch 1782/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 74313831022592.0000 - mse: 74313831022592.0000 - val_loss: 5037088789495808.0000 - val_mse: 5037088789495808.0000\n",
            "Epoch 1783/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 73995223302144.0000 - mse: 73995223302144.0000 - val_loss: 5036205636845568.0000 - val_mse: 5036205636845568.0000\n",
            "Epoch 1784/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 73677035012096.0000 - mse: 73677035012096.0000 - val_loss: 5035350938353664.0000 - val_mse: 5035350938353664.0000\n",
            "Epoch 1785/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 73360583163904.0000 - mse: 73360583163904.0000 - val_loss: 5034496776732672.0000 - val_mse: 5034496776732672.0000\n",
            "Epoch 1786/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 73044760461312.0000 - mse: 73044760461312.0000 - val_loss: 5033632951435264.0000 - val_mse: 5033632951435264.0000\n",
            "Epoch 1787/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 72731009744896.0000 - mse: 72731009744896.0000 - val_loss: 5032714902175744.0000 - val_mse: 5032714902175744.0000\n",
            "Epoch 1788/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 72416881541120.0000 - mse: 72416881541120.0000 - val_loss: 5031846245040128.0000 - val_mse: 5031846245040128.0000\n",
            "Epoch 1789/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 72105471246336.0000 - mse: 72105471246336.0000 - val_loss: 5030941617553408.0000 - val_mse: 5030941617553408.0000\n",
            "Epoch 1790/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 71793859624960.0000 - mse: 71793859624960.0000 - val_loss: 5030089066545152.0000 - val_mse: 5030089066545152.0000\n",
            "Epoch 1791/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 71484781363200.0000 - mse: 71484781363200.0000 - val_loss: 5029205377024000.0000 - val_mse: 5029205377024000.0000\n",
            "Epoch 1792/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 71176114143232.0000 - mse: 71176114143232.0000 - val_loss: 5028371079626752.0000 - val_mse: 5028371079626752.0000\n",
            "Epoch 1793/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 70867681804288.0000 - mse: 70867681804288.0000 - val_loss: 5027480410783744.0000 - val_mse: 5027480410783744.0000\n",
            "Epoch 1794/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 70562160312320.0000 - mse: 70562160312320.0000 - val_loss: 5026631617871872.0000 - val_mse: 5026631617871872.0000\n",
            "Epoch 1795/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 70255892234240.0000 - mse: 70255892234240.0000 - val_loss: 5025711421128704.0000 - val_mse: 5025711421128704.0000\n",
            "Epoch 1796/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 69951884886016.0000 - mse: 69951884886016.0000 - val_loss: 5024835247800320.0000 - val_mse: 5024835247800320.0000\n",
            "Epoch 1797/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 69648557015040.0000 - mse: 69648557015040.0000 - val_loss: 5024004171628544.0000 - val_mse: 5024004171628544.0000\n",
            "Epoch 1798/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 69346382577664.0000 - mse: 69346382577664.0000 - val_loss: 5023118871494656.0000 - val_mse: 5023118871494656.0000\n",
            "Epoch 1799/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 69046506618880.0000 - mse: 69046506618880.0000 - val_loss: 5022275447291904.0000 - val_mse: 5022275447291904.0000\n",
            "Epoch 1800/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 68745682747392.0000 - mse: 68745682747392.0000 - val_loss: 5021353103065088.0000 - val_mse: 5021353103065088.0000\n",
            "Epoch 1801/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 68446956027904.0000 - mse: 68446956027904.0000 - val_loss: 5020520416280576.0000 - val_mse: 5020520416280576.0000\n",
            "Epoch 1802/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 68149856698368.0000 - mse: 68149856698368.0000 - val_loss: 5019684508270592.0000 - val_mse: 5019684508270592.0000\n",
            "Epoch 1803/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 67852484739072.0000 - mse: 67852484739072.0000 - val_loss: 5018805113716736.0000 - val_mse: 5018805113716736.0000\n",
            "Epoch 1804/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 67558233341952.0000 - mse: 67558233341952.0000 - val_loss: 5017956857675776.0000 - val_mse: 5017956857675776.0000\n",
            "Epoch 1805/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 67263382159360.0000 - mse: 67263382159360.0000 - val_loss: 5017087126798336.0000 - val_mse: 5017087126798336.0000\n",
            "Epoch 1806/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 66969768296448.0000 - mse: 66969768296448.0000 - val_loss: 5016213100953600.0000 - val_mse: 5016213100953600.0000\n",
            "Epoch 1807/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 66677286895616.0000 - mse: 66677286895616.0000 - val_loss: 5015360549945344.0000 - val_mse: 5015360549945344.0000\n",
            "Epoch 1808/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 66385711464448.0000 - mse: 66385711464448.0000 - val_loss: 5014516588871680.0000 - val_mse: 5014516588871680.0000\n",
            "Epoch 1809/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 66095889252352.0000 - mse: 66095889252352.0000 - val_loss: 5013688197054464.0000 - val_mse: 5013688197054464.0000\n",
            "Epoch 1810/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 65806897512448.0000 - mse: 65806897512448.0000 - val_loss: 5012833498562560.0000 - val_mse: 5012833498562560.0000\n",
            "Epoch 1811/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 65518899822592.0000 - mse: 65518899822592.0000 - val_loss: 5011990074359808.0000 - val_mse: 5011990074359808.0000\n",
            "Epoch 1812/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 65231837462528.0000 - mse: 65231837462528.0000 - val_loss: 5011142355189760.0000 - val_mse: 5011142355189760.0000\n",
            "Epoch 1813/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 64944959651840.0000 - mse: 64944959651840.0000 - val_loss: 5010269939957760.0000 - val_mse: 5010269939957760.0000\n",
            "Epoch 1814/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 64660623589376.0000 - mse: 64660623589376.0000 - val_loss: 5009410946498560.0000 - val_mse: 5009410946498560.0000\n",
            "Epoch 1815/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 64377105416192.0000 - mse: 64377105416192.0000 - val_loss: 5008580944068608.0000 - val_mse: 5008580944068608.0000\n",
            "Epoch 1816/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 64094140891136.0000 - mse: 64094140891136.0000 - val_loss: 5007740204220416.0000 - val_mse: 5007740204220416.0000\n",
            "Epoch 1817/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 63812166221824.0000 - mse: 63812166221824.0000 - val_loss: 5006924160434176.0000 - val_mse: 5006924160434176.0000\n",
            "Epoch 1818/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 63531332403200.0000 - mse: 63531332403200.0000 - val_loss: 5006023291043840.0000 - val_mse: 5006023291043840.0000\n",
            "Epoch 1819/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 63251727515648.0000 - mse: 63251727515648.0000 - val_loss: 5005169666293760.0000 - val_mse: 5005169666293760.0000\n",
            "Epoch 1820/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 62973158621184.0000 - mse: 62973158621184.0000 - val_loss: 5004345569443840.0000 - val_mse: 5004345569443840.0000\n",
            "Epoch 1821/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 62696355528704.0000 - mse: 62696355528704.0000 - val_loss: 5003537041850368.0000 - val_mse: 5003537041850368.0000\n",
            "Epoch 1822/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 62419753762816.0000 - mse: 62419753762816.0000 - val_loss: 5002741936029696.0000 - val_mse: 5002741936029696.0000\n",
            "Epoch 1823/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 62143714033664.0000 - mse: 62143714033664.0000 - val_loss: 5001875963248640.0000 - val_mse: 5001875963248640.0000\n",
            "Epoch 1824/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 61869863731200.0000 - mse: 61869863731200.0000 - val_loss: 5000982610051072.0000 - val_mse: 5000982610051072.0000\n",
            "Epoch 1825/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 61595996651520.0000 - mse: 61595996651520.0000 - val_loss: 5000160660684800.0000 - val_mse: 5000160660684800.0000\n",
            "Epoch 1826/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 61323375280128.0000 - mse: 61323375280128.0000 - val_loss: 4999325289545728.0000 - val_mse: 4999325289545728.0000\n",
            "Epoch 1827/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 61051764736000.0000 - mse: 61051764736000.0000 - val_loss: 4998516761952256.0000 - val_mse: 4998516761952256.0000\n",
            "Epoch 1828/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 60781370540032.0000 - mse: 60781370540032.0000 - val_loss: 4997695349456896.0000 - val_mse: 4997695349456896.0000\n",
            "Epoch 1829/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 60511982977024.0000 - mse: 60511982977024.0000 - val_loss: 4996859441446912.0000 - val_mse: 4996859441446912.0000\n",
            "Epoch 1830/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 60242620579840.0000 - mse: 60242620579840.0000 - val_loss: 4995985415602176.0000 - val_mse: 4995985415602176.0000\n",
            "Epoch 1831/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 59975166590976.0000 - mse: 59975166590976.0000 - val_loss: 4995166687461376.0000 - val_mse: 4995166687461376.0000\n",
            "Epoch 1832/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 59708916367360.0000 - mse: 59708916367360.0000 - val_loss: 4994353864900608.0000 - val_mse: 4994353864900608.0000\n",
            "Epoch 1833/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 59444092207104.0000 - mse: 59444092207104.0000 - val_loss: 4993562517176320.0000 - val_mse: 4993562517176320.0000\n",
            "Epoch 1834/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 59179549065216.0000 - mse: 59179549065216.0000 - val_loss: 4992751842099200.0000 - val_mse: 4992751842099200.0000\n",
            "Epoch 1835/2000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 58916205494272.0000 - mse: 58916205494272.0000 - val_loss: 4991894996123648.0000 - val_mse: 4991894996123648.0000\n",
            "Epoch 1836/2000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 58653826613248.0000 - mse: 58653826613248.0000 - val_loss: 4991055330017280.0000 - val_mse: 4991055330017280.0000\n",
            "Epoch 1837/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 58391514841088.0000 - mse: 58391514841088.0000 - val_loss: 4990214053298176.0000 - val_mse: 4990214053298176.0000\n",
            "Epoch 1838/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 58130713018368.0000 - mse: 58130713018368.0000 - val_loss: 4989465655246848.0000 - val_mse: 4989465655246848.0000\n",
            "Epoch 1839/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 57872033513472.0000 - mse: 57872033513472.0000 - val_loss: 4988636189687808.0000 - val_mse: 4988636189687808.0000\n",
            "Epoch 1840/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 57613697941504.0000 - mse: 57613697941504.0000 - val_loss: 4987833567674368.0000 - val_mse: 4987833567674368.0000\n",
            "Epoch 1841/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 57355609833472.0000 - mse: 57355609833472.0000 - val_loss: 4986998733406208.0000 - val_mse: 4986998733406208.0000\n",
            "Epoch 1842/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 57098931011584.0000 - mse: 57098931011584.0000 - val_loss: 4986162825396224.0000 - val_mse: 4986162825396224.0000\n",
            "Epoch 1843/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 56842810032128.0000 - mse: 56842810032128.0000 - val_loss: 4985382751961088.0000 - val_mse: 4985382751961088.0000\n",
            "Epoch 1844/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 56588349997056.0000 - mse: 56588349997056.0000 - val_loss: 4984608584105984.0000 - val_mse: 4984608584105984.0000\n",
            "Epoch 1845/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 56334246477824.0000 - mse: 56334246477824.0000 - val_loss: 4983791466577920.0000 - val_mse: 4983791466577920.0000\n",
            "Epoch 1846/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 56082089115648.0000 - mse: 56082089115648.0000 - val_loss: 4983000118853632.0000 - val_mse: 4983000118853632.0000\n",
            "Epoch 1847/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 55831399759872.0000 - mse: 55831399759872.0000 - val_loss: 4982136830427136.0000 - val_mse: 4982136830427136.0000\n",
            "Epoch 1848/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 55579343060992.0000 - mse: 55579343060992.0000 - val_loss: 4981289648128000.0000 - val_mse: 4981289648128000.0000\n",
            "Epoch 1849/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 55329354153984.0000 - mse: 55329354153984.0000 - val_loss: 4980478973050880.0000 - val_mse: 4980478973050880.0000\n",
            "Epoch 1850/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 55079910506496.0000 - mse: 55079910506496.0000 - val_loss: 4979714468872192.0000 - val_mse: 4979714468872192.0000\n",
            "Epoch 1851/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 54833050550272.0000 - mse: 54833050550272.0000 - val_loss: 4978949427822592.0000 - val_mse: 4978949427822592.0000\n",
            "Epoch 1852/2000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 54585498533888.0000 - mse: 54585498533888.0000 - val_loss: 4978176870580224.0000 - val_mse: 4978176870580224.0000\n",
            "Epoch 1853/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 54338609217536.0000 - mse: 54338609217536.0000 - val_loss: 4977281369899008.0000 - val_mse: 4977281369899008.0000\n",
            "Epoch 1854/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 54094211317760.0000 - mse: 54094211317760.0000 - val_loss: 4976467473596416.0000 - val_mse: 4976467473596416.0000\n",
            "Epoch 1855/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 53850157350912.0000 - mse: 53850157350912.0000 - val_loss: 4975681494581248.0000 - val_mse: 4975681494581248.0000\n",
            "Epoch 1856/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 53606166298624.0000 - mse: 53606166298624.0000 - val_loss: 4974948128915456.0000 - val_mse: 4974948128915456.0000\n",
            "Epoch 1857/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 53363718750208.0000 - mse: 53363718750208.0000 - val_loss: 4974124032065536.0000 - val_mse: 4974124032065536.0000\n",
            "Epoch 1858/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 53123242524672.0000 - mse: 53123242524672.0000 - val_loss: 4973327852503040.0000 - val_mse: 4973327852503040.0000\n",
            "Epoch 1859/2000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 52881826775040.0000 - mse: 52881826775040.0000 - val_loss: 4972510198104064.0000 - val_mse: 4972510198104064.0000\n",
            "Epoch 1860/2000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 52642399125504.0000 - mse: 52642399125504.0000 - val_loss: 4971699523026944.0000 - val_mse: 4971699523026944.0000\n",
            "Epoch 1861/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 52403625787392.0000 - mse: 52403625787392.0000 - val_loss: 4970930723880960.0000 - val_mse: 4970930723880960.0000\n",
            "Epoch 1862/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 52166077186048.0000 - mse: 52166077186048.0000 - val_loss: 4970152797929472.0000 - val_mse: 4970152797929472.0000\n",
            "Epoch 1863/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 51928880906240.0000 - mse: 51928880906240.0000 - val_loss: 4969365208301568.0000 - val_mse: 4969365208301568.0000\n",
            "Epoch 1864/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 51693286850560.0000 - mse: 51693286850560.0000 - val_loss: 4968566344384512.0000 - val_mse: 4968566344384512.0000\n",
            "Epoch 1865/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 51458649096192.0000 - mse: 51458649096192.0000 - val_loss: 4967746542501888.0000 - val_mse: 4967746542501888.0000\n",
            "Epoch 1866/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 51223696769024.0000 - mse: 51223696769024.0000 - val_loss: 4966984185806848.0000 - val_mse: 4966984185806848.0000\n",
            "Epoch 1867/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 50989646217216.0000 - mse: 50989646217216.0000 - val_loss: 4966148814667776.0000 - val_mse: 4966148814667776.0000\n",
            "Epoch 1868/2000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 50757747343360.0000 - mse: 50757747343360.0000 - val_loss: 4965416522743808.0000 - val_mse: 4965416522743808.0000\n",
            "Epoch 1869/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 50526460837888.0000 - mse: 50526460837888.0000 - val_loss: 4964655776661504.0000 - val_mse: 4964655776661504.0000\n",
            "Epoch 1870/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 50296730419200.0000 - mse: 50296730419200.0000 - val_loss: 4963843490971648.0000 - val_mse: 4963843490971648.0000\n",
            "Epoch 1871/2000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 50066605735936.0000 - mse: 50066605735936.0000 - val_loss: 4963038184603648.0000 - val_mse: 4963038184603648.0000\n",
            "Epoch 1872/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 49837236027392.0000 - mse: 49837236027392.0000 - val_loss: 4962293544648704.0000 - val_mse: 4962293544648704.0000\n",
            "Epoch 1873/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 49610550673408.0000 - mse: 49610550673408.0000 - val_loss: 4961524208631808.0000 - val_mse: 4961524208631808.0000\n",
            "Epoch 1874/2000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 49383387168768.0000 - mse: 49383387168768.0000 - val_loss: 4960749503905792.0000 - val_mse: 4960749503905792.0000\n",
            "Epoch 1875/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 49157335154688.0000 - mse: 49157335154688.0000 - val_loss: 4959970504212480.0000 - val_mse: 4959970504212480.0000\n",
            "Epoch 1876/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 48931153117184.0000 - mse: 48931153117184.0000 - val_loss: 4959141575524352.0000 - val_mse: 4959141575524352.0000\n",
            "Epoch 1877/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 48707487662080.0000 - mse: 48707487662080.0000 - val_loss: 4958372776378368.0000 - val_mse: 4958372776378368.0000\n",
            "Epoch 1878/2000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 48483809624064.0000 - mse: 48483809624064.0000 - val_loss: 4957639947583488.0000 - val_mse: 4957639947583488.0000\n",
            "Epoch 1879/2000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 48261683478528.0000 - mse: 48261683478528.0000 - val_loss: 4956875443404800.0000 - val_mse: 4956875443404800.0000\n",
            "Epoch 1880/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 48039519584256.0000 - mse: 48039519584256.0000 - val_loss: 4956094296227840.0000 - val_mse: 4956094296227840.0000\n",
            "Epoch 1881/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 47818882416640.0000 - mse: 47818882416640.0000 - val_loss: 4955296506052608.0000 - val_mse: 4955296506052608.0000\n",
            "Epoch 1882/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 47598882783232.0000 - mse: 47598882783232.0000 - val_loss: 4954549181743104.0000 - val_mse: 4954549181743104.0000\n",
            "Epoch 1883/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 47379159973888.0000 - mse: 47379159973888.0000 - val_loss: 4953767497695232.0000 - val_mse: 4953767497695232.0000\n",
            "Epoch 1884/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 47161144246272.0000 - mse: 47161144246272.0000 - val_loss: 4953030373933056.0000 - val_mse: 4953030373933056.0000\n",
            "Epoch 1885/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 46944101597184.0000 - mse: 46944101597184.0000 - val_loss: 4952245468659712.0000 - val_mse: 4952245468659712.0000\n",
            "Epoch 1886/2000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 46727331577856.0000 - mse: 46727331577856.0000 - val_loss: 4951487406931968.0000 - val_mse: 4951487406931968.0000\n",
            "Epoch 1887/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 46511798878208.0000 - mse: 46511798878208.0000 - val_loss: 4950727734591488.0000 - val_mse: 4950727734591488.0000\n",
            "Epoch 1888/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 46296215846912.0000 - mse: 46296215846912.0000 - val_loss: 4949990073958400.0000 - val_mse: 4949990073958400.0000\n",
            "Epoch 1889/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 46082780299264.0000 - mse: 46082780299264.0000 - val_loss: 4949199799975936.0000 - val_mse: 4949199799975936.0000\n",
            "Epoch 1890/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 45869218922496.0000 - mse: 45869218922496.0000 - val_loss: 4948431537700864.0000 - val_mse: 4948431537700864.0000\n",
            "Epoch 1891/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 45656064393216.0000 - mse: 45656064393216.0000 - val_loss: 4947674549714944.0000 - val_mse: 4947674549714944.0000\n",
            "Epoch 1892/2000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 45445971705856.0000 - mse: 45445971705856.0000 - val_loss: 4946926151663616.0000 - val_mse: 4946926151663616.0000\n",
            "Epoch 1893/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 45234104827904.0000 - mse: 45234104827904.0000 - val_loss: 4946168626806784.0000 - val_mse: 4946168626806784.0000\n",
            "Epoch 1894/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 45024544817152.0000 - mse: 45024544817152.0000 - val_loss: 4945399827660800.0000 - val_mse: 4945399827660800.0000\n",
            "Epoch 1895/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 44815584591872.0000 - mse: 44815584591872.0000 - val_loss: 4944662167027712.0000 - val_mse: 4944662167027712.0000\n",
            "Epoch 1896/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 44608612466688.0000 - mse: 44608612466688.0000 - val_loss: 4943930948845568.0000 - val_mse: 4943930948845568.0000\n",
            "Epoch 1897/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 44399702573056.0000 - mse: 44399702573056.0000 - val_loss: 4943185235148800.0000 - val_mse: 4943185235148800.0000\n",
            "Epoch 1898/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 44193992933376.0000 - mse: 44193992933376.0000 - val_loss: 4942428247162880.0000 - val_mse: 4942428247162880.0000\n",
            "Epoch 1899/2000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 43987725451264.0000 - mse: 43987725451264.0000 - val_loss: 4941679849111552.0000 - val_mse: 4941679849111552.0000\n",
            "Epoch 1900/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 43782565265408.0000 - mse: 43782565265408.0000 - val_loss: 4940899775676416.0000 - val_mse: 4940899775676416.0000\n",
            "Epoch 1901/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 43578994720768.0000 - mse: 43578994720768.0000 - val_loss: 4940151914496000.0000 - val_mse: 4940151914496000.0000\n",
            "Epoch 1902/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 43375990407168.0000 - mse: 43375990407168.0000 - val_loss: 4939421770055680.0000 - val_mse: 4939421770055680.0000\n",
            "Epoch 1903/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 43172751212544.0000 - mse: 43172751212544.0000 - val_loss: 4938703973646336.0000 - val_mse: 4938703973646336.0000\n",
            "Epoch 1904/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 42971739193344.0000 - mse: 42971739193344.0000 - val_loss: 4937946448789504.0000 - val_mse: 4937946448789504.0000\n",
            "Epoch 1905/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 42770970443776.0000 - mse: 42770970443776.0000 - val_loss: 4937187313319936.0000 - val_mse: 4937187313319936.0000\n",
            "Epoch 1906/2000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 42570486906880.0000 - mse: 42570486906880.0000 - val_loss: 4936448042074112.0000 - val_mse: 4936448042074112.0000\n",
            "Epoch 1907/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 42371148414976.0000 - mse: 42371148414976.0000 - val_loss: 4935689443475456.0000 - val_mse: 4935689443475456.0000\n",
            "Epoch 1908/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 42173483450368.0000 - mse: 42173483450368.0000 - val_loss: 4934960372776960.0000 - val_mse: 4934960372776960.0000\n",
            "Epoch 1909/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 41974702800896.0000 - mse: 41974702800896.0000 - val_loss: 4934254387527680.0000 - val_mse: 4934254387527680.0000\n",
            "Epoch 1910/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 41778124161024.0000 - mse: 41778124161024.0000 - val_loss: 4933485588381696.0000 - val_mse: 4933485588381696.0000\n",
            "Epoch 1911/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 41582224998400.0000 - mse: 41582224998400.0000 - val_loss: 4932749538361344.0000 - val_mse: 4932749538361344.0000\n",
            "Epoch 1912/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 41387085004800.0000 - mse: 41387085004800.0000 - val_loss: 4931984497311744.0000 - val_mse: 4931984497311744.0000\n",
            "Epoch 1913/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 41192142143488.0000 - mse: 41192142143488.0000 - val_loss: 4931253816000512.0000 - val_mse: 4931253816000512.0000\n",
            "Epoch 1914/2000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 40999111884800.0000 - mse: 40999111884800.0000 - val_loss: 4930531724623872.0000 - val_mse: 4930531724623872.0000\n",
            "Epoch 1915/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 40806140346368.0000 - mse: 40806140346368.0000 - val_loss: 4929821444407296.0000 - val_mse: 4929821444407296.0000\n",
            "Epoch 1916/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 40613395300352.0000 - mse: 40613395300352.0000 - val_loss: 4929101500514304.0000 - val_mse: 4929101500514304.0000\n",
            "Epoch 1917/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 40422109872128.0000 - mse: 40422109872128.0000 - val_loss: 4928341828173824.0000 - val_mse: 4928341828173824.0000\n",
            "Epoch 1918/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 40231629750272.0000 - mse: 40231629750272.0000 - val_loss: 4927628326731776.0000 - val_mse: 4927628326731776.0000\n",
            "Epoch 1919/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 40041732636672.0000 - mse: 40041732636672.0000 - val_loss: 4926911067193344.0000 - val_mse: 4926911067193344.0000\n",
            "Epoch 1920/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 39852405948416.0000 - mse: 39852405948416.0000 - val_loss: 4926197028880384.0000 - val_mse: 4926197028880384.0000\n",
            "Epoch 1921/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 39664517906432.0000 - mse: 39664517906432.0000 - val_loss: 4925473863761920.0000 - val_mse: 4925473863761920.0000\n",
            "Epoch 1922/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 39476126547968.0000 - mse: 39476126547968.0000 - val_loss: 4924727613194240.0000 - val_mse: 4924727613194240.0000\n",
            "Epoch 1923/2000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 39289169641472.0000 - mse: 39289169641472.0000 - val_loss: 4924001226850304.0000 - val_mse: 4924001226850304.0000\n",
            "Epoch 1924/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 39103781404672.0000 - mse: 39103781404672.0000 - val_loss: 4923308663373824.0000 - val_mse: 4923308663373824.0000\n",
            "Epoch 1925/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 38918179258368.0000 - mse: 38918179258368.0000 - val_loss: 4922603751866368.0000 - val_mse: 4922603751866368.0000\n",
            "Epoch 1926/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 38733713768448.0000 - mse: 38733713768448.0000 - val_loss: 4921880586747904.0000 - val_mse: 4921880586747904.0000\n",
            "Epoch 1927/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 38549596405760.0000 - mse: 38549596405760.0000 - val_loss: 4921135409922048.0000 - val_mse: 4921135409922048.0000\n",
            "Epoch 1928/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 38366582145024.0000 - mse: 38366582145024.0000 - val_loss: 4920407412965376.0000 - val_mse: 4920407412965376.0000\n",
            "Epoch 1929/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 38184381579264.0000 - mse: 38184381579264.0000 - val_loss: 4919701964587008.0000 - val_mse: 4919701964587008.0000\n",
            "Epoch 1930/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 38002998902784.0000 - mse: 38002998902784.0000 - val_loss: 4918991684370432.0000 - val_mse: 4918991684370432.0000\n",
            "Epoch 1931/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 37822580916224.0000 - mse: 37822580916224.0000 - val_loss: 4918274961702912.0000 - val_mse: 4918274961702912.0000\n",
            "Epoch 1932/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 37641974185984.0000 - mse: 37641974185984.0000 - val_loss: 4917584008839168.0000 - val_mse: 4917584008839168.0000\n",
            "Epoch 1933/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 37462474752000.0000 - mse: 37462474752000.0000 - val_loss: 4916842590109696.0000 - val_mse: 4916842590109696.0000\n",
            "Epoch 1934/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 37284262969344.0000 - mse: 37284262969344.0000 - val_loss: 4916163448406016.0000 - val_mse: 4916163448406016.0000\n",
            "Epoch 1935/2000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 37105753391104.0000 - mse: 37105753391104.0000 - val_loss: 4915425787772928.0000 - val_mse: 4915425787772928.0000\n",
            "Epoch 1936/2000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 36928766345216.0000 - mse: 36928766345216.0000 - val_loss: 4914730003070976.0000 - val_mse: 4914730003070976.0000\n",
            "Epoch 1937/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 36752391667712.0000 - mse: 36752391667712.0000 - val_loss: 4913999321759744.0000 - val_mse: 4913999321759744.0000\n",
            "Epoch 1938/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 36576935542784.0000 - mse: 36576935542784.0000 - val_loss: 4913283672834048.0000 - val_mse: 4913283672834048.0000\n",
            "Epoch 1939/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 36401152262144.0000 - mse: 36401152262144.0000 - val_loss: 4912578761326592.0000 - val_mse: 4912578761326592.0000\n",
            "Epoch 1940/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 36227252224000.0000 - mse: 36227252224000.0000 - val_loss: 4911894787784704.0000 - val_mse: 4911894787784704.0000\n",
            "Epoch 1941/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 36054367207424.0000 - mse: 36054367207424.0000 - val_loss: 4911211351113728.0000 - val_mse: 4911211351113728.0000\n",
            "Epoch 1942/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 35881037594624.0000 - mse: 35881037594624.0000 - val_loss: 4910515029540864.0000 - val_mse: 4910515029540864.0000\n",
            "Epoch 1943/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 35709519921152.0000 - mse: 35709519921152.0000 - val_loss: 4909790253809664.0000 - val_mse: 4909790253809664.0000\n",
            "Epoch 1944/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 35537301798912.0000 - mse: 35537301798912.0000 - val_loss: 4909075678625792.0000 - val_mse: 4909075678625792.0000\n",
            "Epoch 1945/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 35366732038144.0000 - mse: 35366732038144.0000 - val_loss: 4908392241954816.0000 - val_mse: 4908392241954816.0000\n",
            "Epoch 1946/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 35197277962240.0000 - mse: 35197277962240.0000 - val_loss: 4907688941060096.0000 - val_mse: 4907688941060096.0000\n",
            "Epoch 1947/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 35027727417344.0000 - mse: 35027727417344.0000 - val_loss: 4907044695965696.0000 - val_mse: 4907044695965696.0000\n",
            "Epoch 1948/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 34859038801920.0000 - mse: 34859038801920.0000 - val_loss: 4906321530847232.0000 - val_mse: 4906321530847232.0000\n",
            "Epoch 1949/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 34692015325184.0000 - mse: 34692015325184.0000 - val_loss: 4905635409821696.0000 - val_mse: 4905635409821696.0000\n",
            "Epoch 1950/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 34524771647488.0000 - mse: 34524771647488.0000 - val_loss: 4904926740217856.0000 - val_mse: 4904926740217856.0000\n",
            "Epoch 1951/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 34357410529280.0000 - mse: 34357410529280.0000 - val_loss: 4904242229805056.0000 - val_mse: 4904242229805056.0000\n",
            "Epoch 1952/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 34191072821248.0000 - mse: 34191072821248.0000 - val_loss: 4903534097072128.0000 - val_mse: 4903534097072128.0000\n",
            "Epoch 1953/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 34026597384192.0000 - mse: 34026597384192.0000 - val_loss: 4902857102852096.0000 - val_mse: 4902857102852096.0000\n",
            "Epoch 1954/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 33862400868352.0000 - mse: 33862400868352.0000 - val_loss: 4902174203052032.0000 - val_mse: 4902174203052032.0000\n",
            "Epoch 1955/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 33698346958848.0000 - mse: 33698346958848.0000 - val_loss: 4901482713317376.0000 - val_mse: 4901482713317376.0000\n",
            "Epoch 1956/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 33534729256960.0000 - mse: 33534729256960.0000 - val_loss: 4900770285617152.0000 - val_mse: 4900770285617152.0000\n",
            "Epoch 1957/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 33372667641856.0000 - mse: 33372667641856.0000 - val_loss: 4900117987459072.0000 - val_mse: 4900117987459072.0000\n",
            "Epoch 1958/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 33211277115392.0000 - mse: 33211277115392.0000 - val_loss: 4899466226171904.0000 - val_mse: 4899466226171904.0000\n",
            "Epoch 1959/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 33049819480064.0000 - mse: 33049819480064.0000 - val_loss: 4898770441469952.0000 - val_mse: 4898770441469952.0000\n",
            "Epoch 1960/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 32889857114112.0000 - mse: 32889857114112.0000 - val_loss: 4898088078540800.0000 - val_mse: 4898088078540800.0000\n",
            "Epoch 1961/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 32730163183616.0000 - mse: 32730163183616.0000 - val_loss: 4897397125677056.0000 - val_mse: 4897397125677056.0000\n",
            "Epoch 1962/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 32571012415488.0000 - mse: 32571012415488.0000 - val_loss: 4896700267233280.0000 - val_mse: 4896700267233280.0000\n",
            "Epoch 1963/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 32412803268608.0000 - mse: 32412803268608.0000 - val_loss: 4896040452882432.0000 - val_mse: 4896040452882432.0000\n",
            "Epoch 1964/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 32255099535360.0000 - mse: 32255099535360.0000 - val_loss: 4895366679887872.0000 - val_mse: 4895366679887872.0000\n",
            "Epoch 1965/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 32097320304640.0000 - mse: 32097320304640.0000 - val_loss: 4894671968927744.0000 - val_mse: 4894671968927744.0000\n",
            "Epoch 1966/2000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 31941332041728.0000 - mse: 31941332041728.0000 - val_loss: 4893994437836800.0000 - val_mse: 4893994437836800.0000\n",
            "Epoch 1967/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 31785771597824.0000 - mse: 31785771597824.0000 - val_loss: 4893316369874944.0000 - val_mse: 4893316369874944.0000\n",
            "Epoch 1968/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 31630561378304.0000 - mse: 31630561378304.0000 - val_loss: 4892656018653184.0000 - val_mse: 4892656018653184.0000\n",
            "Epoch 1969/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 31476460552192.0000 - mse: 31476460552192.0000 - val_loss: 4891976340078592.0000 - val_mse: 4891976340078592.0000\n",
            "Epoch 1970/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 31322529595392.0000 - mse: 31322529595392.0000 - val_loss: 4891264449249280.0000 - val_mse: 4891264449249280.0000\n",
            "Epoch 1971/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 31169389264896.0000 - mse: 31169389264896.0000 - val_loss: 4890607856123904.0000 - val_mse: 4890607856123904.0000\n",
            "Epoch 1972/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 31016649490432.0000 - mse: 31016649490432.0000 - val_loss: 4889951262998528.0000 - val_mse: 4889951262998528.0000\n",
            "Epoch 1973/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 30864876503040.0000 - mse: 30864876503040.0000 - val_loss: 4889291985518592.0000 - val_mse: 4889291985518592.0000\n",
            "Epoch 1974/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 30713764118528.0000 - mse: 30713764118528.0000 - val_loss: 4888608548847616.0000 - val_mse: 4888608548847616.0000\n",
            "Epoch 1975/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 30563440263168.0000 - mse: 30563440263168.0000 - val_loss: 4887919743467520.0000 - val_mse: 4887919743467520.0000\n",
            "Epoch 1976/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 30414190149632.0000 - mse: 30414190149632.0000 - val_loss: 4887268519051264.0000 - val_mse: 4887268519051264.0000\n",
            "Epoch 1977/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 30264189255680.0000 - mse: 30264189255680.0000 - val_loss: 4886641990696960.0000 - val_mse: 4886641990696960.0000\n",
            "Epoch 1978/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 30115568287744.0000 - mse: 30115568287744.0000 - val_loss: 4885963922735104.0000 - val_mse: 4885963922735104.0000\n",
            "Epoch 1979/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 29967503065088.0000 - mse: 29967503065088.0000 - val_loss: 4885287465385984.0000 - val_mse: 4885287465385984.0000\n",
            "Epoch 1980/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 29819907604480.0000 - mse: 29819907604480.0000 - val_loss: 4884604565585920.0000 - val_mse: 4884604565585920.0000\n",
            "Epoch 1981/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 29673096478720.0000 - mse: 29673096478720.0000 - val_loss: 4883994143358976.0000 - val_mse: 4883994143358976.0000\n",
            "Epoch 1982/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 29526836903936.0000 - mse: 29526836903936.0000 - val_loss: 4883339697717248.0000 - val_mse: 4883339697717248.0000\n",
            "Epoch 1983/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 29381831426048.0000 - mse: 29381831426048.0000 - val_loss: 4882706726912000.0000 - val_mse: 4882706726912000.0000\n",
            "Epoch 1984/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 29236553318400.0000 - mse: 29236553318400.0000 - val_loss: 4882028658950144.0000 - val_mse: 4882028658950144.0000\n",
            "Epoch 1985/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 29092772577280.0000 - mse: 29092772577280.0000 - val_loss: 4881342001053696.0000 - val_mse: 4881342001053696.0000\n",
            "Epoch 1986/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 28949199454208.0000 - mse: 28949199454208.0000 - val_loss: 4880707956506624.0000 - val_mse: 4880707956506624.0000\n",
            "Epoch 1987/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 28806138036224.0000 - mse: 28806138036224.0000 - val_loss: 4880062637670400.0000 - val_mse: 4880062637670400.0000\n",
            "Epoch 1988/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 28663709958144.0000 - mse: 28663709958144.0000 - val_loss: 4879403360190464.0000 - val_mse: 4879403360190464.0000\n",
            "Epoch 1989/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 28521445457920.0000 - mse: 28521445457920.0000 - val_loss: 4878775758094336.0000 - val_mse: 4878775758094336.0000\n",
            "Epoch 1990/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 28380166619136.0000 - mse: 28380166619136.0000 - val_loss: 4878105743196160.0000 - val_mse: 4878105743196160.0000\n",
            "Epoch 1991/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 28240359981056.0000 - mse: 28240359981056.0000 - val_loss: 4877444318232576.0000 - val_mse: 4877444318232576.0000\n",
            "Epoch 1992/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 28099376840704.0000 - mse: 28099376840704.0000 - val_loss: 4876815642394624.0000 - val_mse: 4876815642394624.0000\n",
            "Epoch 1993/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 27960841076736.0000 - mse: 27960841076736.0000 - val_loss: 4876186429685760.0000 - val_mse: 4876186429685760.0000\n",
            "Epoch 1994/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 27821804093440.0000 - mse: 27821804093440.0000 - val_loss: 4875537889624064.0000 - val_mse: 4875537889624064.0000\n",
            "Epoch 1995/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27683626942464.0000 - mse: 27683626942464.0000 - val_loss: 4874908140044288.0000 - val_mse: 4874908140044288.0000\n",
            "Epoch 1996/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 27546362052608.0000 - mse: 27546362052608.0000 - val_loss: 4874237051404288.0000 - val_mse: 4874237051404288.0000\n",
            "Epoch 1997/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 27408254107648.0000 - mse: 27408254107648.0000 - val_loss: 4873580995149824.0000 - val_mse: 4873580995149824.0000\n",
            "Epoch 1998/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 27271855341568.0000 - mse: 27271855341568.0000 - val_loss: 4872957151150080.0000 - val_mse: 4872957151150080.0000\n",
            "Epoch 1999/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 27136119275520.0000 - mse: 27136119275520.0000 - val_loss: 4872307000475648.0000 - val_mse: 4872307000475648.0000\n",
            "Epoch 2000/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 27001431785472.0000 - mse: 27001431785472.0000 - val_loss: 4871686377701376.0000 - val_mse: 4871686377701376.0000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4871686377701376.0000 - mse: 4871686377701376.0000\n",
            "rmse: 69797466.84301212\n"
          ]
        }
      ],
      "source": [
        "# 모델 훈련\n",
        "model_dl.fit(x_train, y_train, epochs=2000, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "loss, mse = model_dl.evaluate(x_test, y_test)\n",
        "rmse=np.sqrt(mse)\n",
        "print(f\"rmse: {rmse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwgeuus6CXOl"
      },
      "source": [
        "## RNN : LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-vk6BWPKpXB",
        "outputId": "896cbaa3-ed8e-497f-c7b3-3b59e172b9fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((20, 123), (6, 123))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target='당월_매출_금액'\n",
        "x = data_s.drop(target, axis = 1)\n",
        "y = data_s.loc[:,target]\n",
        "x_train_s,x_test_s,y_train,y_test=train_test_split(x,y,test_size=.2,random_state=42)\n",
        "x_train.shape,x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FglT2hzxLYdG",
        "outputId": "2706e66e-cfc1-43f7-ec60-c90c6daae1f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((20, 123, 1), (6, 123, 1))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lstm input 차원 맞춰주기\n",
        "x_train_lstm = np.expand_dims(x_train_s, axis=-1)\n",
        "x_test_lstm = np.expand_dims(x_test_s, axis=-1)\n",
        "x_train_lstm.shape,x_test_lstm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1tdjzeNnF-C"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model_lstm = Sequential()\n",
        "\n",
        "model_lstm.add(LSTM(units=64, activation='relu', return_sequences=True, input_shape=(123, 1)))\n",
        "model_lstm.add(LSTM(units=32, activation='relu'))\n",
        "\n",
        "# 출력 레이어\n",
        "model_lstm.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model_lstm.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model_lstm.summary()\n",
        "\n",
        "# training\n",
        "model_lstm.fit(x_train_lstm, y_train, epochs=50, batch_size=32, validation_data=(x_test_lstm, y_test))\n",
        "\n",
        "loss, mse = model_dl.evaluate(x_test_lstm, y_test)\n",
        "rmse=np.sqrt(mse)\n",
        "print(f\"rmse: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdAw_iHgI5Aj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjvVwgWqI4-t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOXgfdGCI48W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RuHq9VII46H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AetBzPgSI43s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzwSBo5_I4lu"
      },
      "source": [
        "## Auto ML : AutoGluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtguqYFte8xN"
      },
      "outputs": [],
      "source": [
        "!pip install autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oR4ZN5yZa6P"
      },
      "outputs": [],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwsHDouJZa4P"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_data, y_data = data_s.drop(target,axis=1), data_s[target]\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_data, y_data, test_size = .2, random_state = 42)\n",
        "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJlfK4DFZa2G"
      },
      "outputs": [],
      "source": [
        "train_df = TabularDataset(train)\n",
        "test_df = TabularDataset(test)\n",
        "\n",
        "predictor = TabularPredictor(label = target, problem_type = 'regression', eval_metric = 'mse',\n",
        "                             path = './')\n",
        "\n",
        "predictor.fit(train_data = train_df, presets = 'best_quality',\n",
        "              auto_stack = True, fit_weighted_ensemble = True,\n",
        "              num_bag_folds = 10, num_bag_sets = 30, num_stack_levels = 3,\n",
        "              num_gpus = 1, num_cpus = 24, verbosity = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMmpFYTDZazc"
      },
      "outputs": [],
      "source": [
        "# Feature Importance 확인\n",
        "feature_importance = predictor.feature_importance(train_df)\n",
        "feature_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5NYnI65ZaxG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo-do1h9Zau5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik-Ai83RZasy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EFs_JBmZaqg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm3pQfY0ZaoV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rYXeTiaZamB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03562d27eb8542ab9cb810277e5a4516": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "047bdea5222a48c2a6293b074678f0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553100ff610c4109b7d2751aac93b011",
            "placeholder": "​",
            "style": "IPY_MODEL_03562d27eb8542ab9cb810277e5a4516",
            "value": " 7/7 [00:42&lt;00:00,  4.93s/it]"
          }
        },
        "09f49d04d88347cd9297eeeafcd00687": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a5727a9a3ba4bb68e0ce46c09c13b53",
            "max": 81,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23d950e677744ab29c59b889ef8bff43",
            "value": 55
          }
        },
        "0dc626ae7491472eb692789e56f7139c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "11455b43a98042719ffacb77912baf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62809e3e46604107bcd447fafa81557a",
              "IPY_MODEL_f4552d587b2d4bca8e4c1753d1684dda",
              "IPY_MODEL_047bdea5222a48c2a6293b074678f0b5"
            ],
            "layout": "IPY_MODEL_0dc626ae7491472eb692789e56f7139c"
          }
        },
        "23d950e677744ab29c59b889ef8bff43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24d70321d3f84f97a878e3bd5bd7457c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3074de101c614e9c8fb576120b2e6d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3ad2dd8db943c288b40fb8bb29e86d",
            "placeholder": "​",
            "style": "IPY_MODEL_76652bcde8db4ea28d85315e75c011c5",
            "value": "Processing: 100%"
          }
        },
        "40257c54402c4ab3867a45ddffe4a349": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8a65f37b409454c823f5bfdf02c81fb",
            "placeholder": "​",
            "style": "IPY_MODEL_4a60fe64a3cb45059b10dd4e238079ef",
            "value": " 81/81 [01:03&lt;00:00,  1.48it/s]"
          }
        },
        "4a5e380649c54c71a461da0b3c2e8d53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a60fe64a3cb45059b10dd4e238079ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5078f5c8d5694c48b11902a0c66cc8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93f191ca756a40d28d0f8bcec8976631",
              "IPY_MODEL_cba07bcd89aa44549c476a68de3c6d89"
            ],
            "layout": "IPY_MODEL_dd6309930d0944ce92166d7e4e5d8065"
          }
        },
        "553100ff610c4109b7d2751aac93b011": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5575764a9fd24be2bb84037b95b04670": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a18baee9dc7b49848a385956da445cd6",
              "IPY_MODEL_09f49d04d88347cd9297eeeafcd00687",
              "IPY_MODEL_75b2dfd6950b443898b84faa030ac8d3"
            ],
            "layout": "IPY_MODEL_dc9bf07414964a7b8abb9a9fd952918a"
          }
        },
        "62809e3e46604107bcd447fafa81557a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb1e94f3cb3b4b58bcb3d6abc9867616",
            "placeholder": "​",
            "style": "IPY_MODEL_24d70321d3f84f97a878e3bd5bd7457c",
            "value": "Processing: 100%"
          }
        },
        "66610ccb34a4432a8a43bb2e0c0eb836": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc7f5a337674a7db85551679861853a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ToggleButtonsStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_width": "",
            "description_width": "",
            "font_weight": ""
          }
        },
        "757943bf78704515a2f2f3ce04ea2861": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b2dfd6950b443898b84faa030ac8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_757943bf78704515a2f2f3ce04ea2861",
            "placeholder": "​",
            "style": "IPY_MODEL_ecd9d017be5e4524a11f6aa6383e6b68",
            "value": " 55/81 [37:56&lt;39:52, 92.00s/it]"
          }
        },
        "76652bcde8db4ea28d85315e75c011c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "784e575c15a74be1bec4801f65110ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3074de101c614e9c8fb576120b2e6d67",
              "IPY_MODEL_c707f96d495d434486ffc56179a5ecd8",
              "IPY_MODEL_40257c54402c4ab3867a45ddffe4a349"
            ],
            "layout": "IPY_MODEL_ff6fb52136e24583947dafa62fd1590b"
          }
        },
        "7a5727a9a3ba4bb68e0ce46c09c13b53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913fde915feb46169bde3c290428d22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9340748afdd942e2a84fc2bd1163572f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93f191ca756a40d28d0f8bcec8976631": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ToggleButtonsModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsModel",
            "_options_labels": [
              "Pipeline Plot",
              "Hyperparameters",
              "Residuals",
              "Prediction Error",
              "Cooks Distance",
              "Feature Selection",
              "Learning Curve",
              "Manifold Learning",
              "Validation Curve",
              "Feature Importance",
              "Feature Importance (All)",
              "Decision Tree",
              "Interactive Residuals"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonsView",
            "button_style": "",
            "description": "Plot Type:",
            "description_tooltip": null,
            "disabled": false,
            "icons": [
              ""
            ],
            "index": 0,
            "layout": "IPY_MODEL_ef2c416e9b9841ee837e1e3e45ebe4fb",
            "style": "IPY_MODEL_6cc7f5a337674a7db85551679861853a",
            "tooltips": []
          }
        },
        "a18baee9dc7b49848a385956da445cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66610ccb34a4432a8a43bb2e0c0eb836",
            "placeholder": "​",
            "style": "IPY_MODEL_ed68143f295442fb859dd4ad02713f86",
            "value": "Processing:  68%"
          }
        },
        "b8a65f37b409454c823f5bfdf02c81fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1bb185690bc435596d26c56ed17aa1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c707f96d495d434486ffc56179a5ecd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1bb185690bc435596d26c56ed17aa1b",
            "max": 81,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9340748afdd942e2a84fc2bd1163572f",
            "value": 81
          }
        },
        "c89b99542d1d44a3ad69dd9ec3355b76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cba07bcd89aa44549c476a68de3c6d89": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_c89b99542d1d44a3ad69dd9ec3355b76",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "image/png": "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\n",
                  "text/plain": "<Figure size 3700x600 with 1 Axes>"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "dc9bf07414964a7b8abb9a9fd952918a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd6309930d0944ce92166d7e4e5d8065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3ad2dd8db943c288b40fb8bb29e86d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb1e94f3cb3b4b58bcb3d6abc9867616": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd9d017be5e4524a11f6aa6383e6b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed68143f295442fb859dd4ad02713f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef2c416e9b9841ee837e1e3e45ebe4fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4552d587b2d4bca8e4c1753d1684dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a5e380649c54c71a461da0b3c2e8d53",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_913fde915feb46169bde3c290428d22a",
            "value": 7
          }
        },
        "ff6fb52136e24583947dafa62fd1590b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
